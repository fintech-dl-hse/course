# Материалы курса Глубинное обучение

* И прогон курса в [2022 году](https://github.com/fintech-dl-hse/course/tree/2022)
* [Разборы семинаров 2022 года](https://youtube.com/playlist?list=PLCNrwCOlxMPxUnJNtthxVdL3eYAj0Lp1Q)

Курс основан на материалах других курсов:
* [Курс Алексея Озерина]( https://github.com/m12sl/dl-hse-2021)
* [Материалы с курса бакалавриата](https://github.com/aosokin/dl_cshse_ami/tree/master/2021-fall/homeworks_small)

### Планируется

* ~13 лекций и семинаров
* ~5 домашек

Материалы будут выкладываться в течение курса.

**Обратная связь.** пожалуйста, заполняйте формы обратной связи. Чтобы мотивация была более понятной, в конце формы обратной связи есть **мем**). Желательно заполнять открытые вопросы --- в них можете высказать все, что угодно)

**Сложность курса.** Понятно, что на курсе есть люди с разными бэкграундами. Если вам что-то не понятно, не стесняйтесь задавать вопрос. Или наоборот, если кажется что слишком просто, приходите в личку, придумаем интересную задачку :)

## Как задавать вопросы?

* не стесняться, не бывает глупых вопросов
* в общий чатик --- так есть вероятность, что вам может помочь кто-то из одногруппников быстрее, чем преподаватель и на преподавателей меньше нагрузка
* на лекциях или семах
* в личку


## Как построены семинары?

* Работа над ошибками по обратной связи. Если че-то не нравится на семах, пишите в формочки обратной связи, будем думать
* Повторение, что прошли на прошлом семе
* Новый материал
* Блиц по новому материалу
* Обзор домашки, если она есть

## Домашки

|   | Домашка        | Количество баллов | Дата выдачи |
|---|----------------|-------------------|-------------------|
| 1 | Activations + Weight Init | 1 + 1  | 23.01.23 (2 занятие)         |
| 2 | Dropout + (Optimization?) | 1 + (1?)              | 31.01.23 (3 занятие)         |
| 3 | Batchnorm + PyTorch basics | 1 + 2                 | 05.02.23 (4 занятие)         |
| 4 | CV             | 4                 |                   |
| 5 | NLP            | 4                 |                   |



**Списывание (!):** За списывание зануляются все работы. Если используете код из открытых источников, пожалуйста указывайте ссылки.

**Сдача:** Домашки будут сдаваться в github classroom. Чтобы получить инвайт, заполните, пожалуйста [**форму**](https://docs.google.com/forms/d/e/1FAIpQLSd7kDmnWYppJm0r7nik7QuAEwsFG-dFSaKp_htkBewxLPMEfQ/viewform?usp=sf_link)

В репозиториях с домашками не стоит трогать файлы тестов или файлы с github-action workflow.
В домашках настроил автоматическое оценивание. Временем сдачи домашки будет считаться
время, когда прошли пайплайны (то есть не время коммита, а время пуша + время на прогон тестов).

Кроме автоматического оценивания, конечно, я буду смотреть само содержание ноутбуков, давать фидбэк.
За неоптимальные решения или за неправильные решения баллы могут снижаться.
То есть оценка, которую вы получили в пайплайнах не конечная

**Штрафы:** За просрочку за каждый день будет сниматься по `10%` от оценки, но суммарно штраф не может быть более `30%`. Жестких дедлайнов нет. Если сдаешь через 3 дня домашку, штраф `30%`. Если сдаешь через месяц, штраф тоже `30%`

## Формула

<img src="https://render.githubusercontent.com/render/math?math=O_%7Bhw%7D%20%3D%20%5Csum_i%20O_%7Bhw_i%7D" height=30>
<img src="https://render.githubusercontent.com/render/math?math=O_%7Btotal%7D%20%3D%200.7%20*%20O_%7Bhw%7D%20%2B%200.3%20*%20O_%7Bexam%7D" height=30>

Автомат можно получить, если `O_{hw} >= 6.0`. В случае автомата итоговая оценка будет нормированной `O_{hw}`: `O_{total} = 10/14(?) * O_{hw}`

## Экзамен

Письменный формат: вопросы по теории + практические задачи. В прошлом году у всех были автоматы.


## Примерный план

1. Введение в глубинное обучение. Алгоритм обратного распространения ошибки.
2. Функции активации. Инициализация весов. Loss-функции, тренировочный цикл.
3. Оптимизация нейросетей. Дропаут.
4. Свёрточные нейросети. AlexNet, VGG, Inception, ResNet. Нормализация по батчам.
5. CV. Практические советы по обучению нейросетей: best practises.
6. Автокодировщики. Генеративныe нейронные сети.
7. Введение в обработку естественного языка. Word2Vec, RNN.
8. Эмбеддинги. Рекуррентные нейронные сети. Seq2seq. Механизм внимания.
9. Transformer.
10. Transfer learning в NLP. BERTology.
11. Из NLP в CV: Vision Transformers, CLIP.
12. Self Supervised.

## Полезные материалы

* [Курс Алексея Озерина]( https://github.com/m12sl/dl-hse-2021)
* [Материалы с курса бакалавриата](https://github.com/aosokin/dl_cshse_ami/tree/master/2021-fall)
* [Курс ШАДа](https://github.com/yandexdataschool/Practical_DL)
* [Курс Стендфорда про CV with DL](https://cs231n.github.io/) --- есть не все темы, которые будут на нашем курсе, но материалы очень классные, используются и в лекциях, и в семинарах первой половины нашего курса.
* [DLSchool](https://www.dlschool.org/) --- много классных домашек и проект в конце курса, там есть и про NLP, и про CV, на некоторых прогонах затрагивали и работу со звуком (на ютубе можно найти записи прогонов прошлых лет, на степики старые прогоны курса тоже можно найти)
* [Курс Стендфорда про NLP with DL](http://web.stanford.edu/class/cs224n/) --- один из лучших курсов про NLP
* [Lena Voita](https://lena-voita.github.io) --- классный блог и курс по NLP
* [Jay Alammar](https://jalammar.github.io/), [Sebastian Ruder](https://ruder.io/) --- еще популярные блоги про NLP
* [distill.pub](https://distill.pub/) --- журнал с красивыми визуализациями
* [paperswithcode](https://paperswithcode.com/) --- сравнение разных архетектур/задач
* [How To Read Papers](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf)

**Гуглите:** эти и многие другие материалы легко находятся, если вы пытаетесь разобраться в какой-то теме.

**Читайте документацию:** в [Pytorch Docs](https://pytorch.org/docs/stable/index.html), [Pytorch Tutorials](https://pytorch.org/tutorials/) можно найти и описание методов, и формулы, и ссылки на статьи.

**Читайте статьи:** большинство концептов, которые мы проходим в этом курсе, были опубликованы в статьях, которые доступны на [arxiv](https://arxiv.org/). Где следить за самыми современными методами: конференции NeurIPS, ICML, ICLR, CVPR, ACL, блоги крупных компаний [Google AI](https://ai.googleblog.com/), [DeepMind](https://deepmind.com/blog), [OpenAI](https://openai.com/blog/), [Meta AI](https://ai.facebook.com/blog/).
