# Материалы курса Глубинное обучение

Курс будет основан на материалах других курсов:
* [Курс Алексея Озерина]( https://github.com/m12sl/dl-hse-2021)
* [Материалы с курса бакалавриата](https://github.com/aosokin/dl_cshse_ami/tree/master/2021-fall/homeworks_small)

### Планируется

* 12 лекций и семинаров
* 5 домашек

Материалы будут выкладываться в течение курса.

**Обратная связь.** пожалуйста, заполняйте формы обратной связи. Чтобы мотивация была более понятной, в конце формы обратной связи есть **мем**). Желательно заполнять открытые вопросы --- в них можете высказать все, что угодно)

**Сложность курса.** Понятно, что на курсе будут люди с разными бэкграундами. Если вам что-то не понятно, не стесняйтесь задавать вопрос. Или наоборот, если кажется что слишком просто, приходите в личку, придумаем интересную задачку :)

## Как задавать вопросы?

* не стесняться, не бывает глупых вопросов
* в общий чатик --- так есть вероятность, что вам может помочь кто-то из одногруппников быстрее, чем преподаватель
* на лекциях или семах
* в личку

## Занятия

Домашки будут сдаваться в github classroom. Чтобы получить инвайт, заполните, пожалуйста, [форму](https://docs.google.com/forms/d/e/1FAIpQLScE3EKAA5Yo8IkWDumVdnVtleb3551ujli9wFpZMK_MINseKA/viewform?usp=sf_link)
### 1 неделя

Алгоритм обратного распространения ошибки.

* [Лекция](./lectures/DL22_lecture1_intro.pdf)
* [Семинар](./seminars/01_seminar_solved.ipynb)
* Бонусная домашка на 0 баллов (инвайт запинен в телеграме)
* [Обратная связь](https://docs.google.com/forms/d/e/1FAIpQLSerebTHr9eLTNgOgSHcFe9fOXzPgUgrgGcOD0wTo_1CxM2Piw/viewform?usp=sf_link)

### 2 неделя

Алгоритм обратного распространения ошибки.

* [Лекция](./lectures/DL22_lecture2_activations.pdf)
* [Семинар](./seminars/02_seminar_solved.ipynb)
* Домашка (2 балла) --- пока что не опубликована
* [Обратная связь](https://forms.gle/6ErNobuuKn5LGJfr7)


## Домашки

|   | Домашка        | Количество баллов |
|---|----------------|-------------------|
| 0 | Meme Classification | 0                 |
| 1 | PyTorch basics | 2                 |
| 2 | NN training    | 2                 |
| 3 | NN debug       | 2                 |
| 4 | CV             | 4                 |
| 5 | NLP            | 4                 |

**Списывание (!):** За списывание зануляются все работы. Если используете код из открытых источников, пожалуйста указывайте ссылки.

**Сдача:** Домашки будут сдаваться в github classroom. Чтобы получить инвайт, заполните, пожалуйста [**форму**](https://docs.google.com/forms/d/e/1FAIpQLScE3EKAA5Yo8IkWDumVdnVtleb3551ujli9wFpZMK_MINseKA/viewform?usp=sf_link)

В репозиториях с домашками не стоит трогать файлы тестов или файлы с github-action workflow.
В домашках настроил автоматическое оценивание. Временем сдачи домашки будет считаться
время, когда прошли пайплайны (то есть не время коммита, а время пуша + время на прогон тестов).

Кроме автоматического оценивания, конечно, я буду смотреть само содержание ноутбуков, давать фидбэк.
За неоптимальные решения или за неправильные решения баллы могут снижаться.
То есть оценка, которую вы получили в пайплайнах не конечная

**Штрафы:** За просрочку за каждый день будет сниматься по `10%` от оценки, но суммарно штраф не может быть более `30%`.

## Формула

<img src="https://render.githubusercontent.com/render/math?math=O_%7Bhw%7D%20%3D%20%5Csum_i%20O_%7Bhw_i%7D" height=30>
<img src="https://render.githubusercontent.com/render/math?math=O_%7Btotal%7D%20%3D%200.7%20*%20O_%7Bhw%7D%20%2B%200.3%20*%20O_%7Bexam%7D" height=30>

Автомат можно получить, если `O_{hw} >= 6.0`. В случае автомата итоговая оценка будет нормированной `O_{hw}`: `O_{total} = 10/12 * O_{hw}`

То есть для минимального автомата идеально сделать первые 3 домашки. Тогда `O_{total} = (2 + 2 + 2) * 10 / 12 = 5`

## Экзамен

Письменный формат: вопросы по теории + практические задачи.

## Основные темы

1. Введение в глубинное обучение. Алгоритм обратного распространения ошибки.
2. Функции активации, инициализация весов. Loss-функции, тренировочный цикл.
3. Оптимизация нейросетей. Дропаут и нормализация по батчам.
4. Практические советы по обучению нейросетей: best practises.
5. Свёрточные нейросети. AlexNet, VGG, Inception, ResNet.
6. Автокодировщики. Генеративныe нейронные сети.
7. Введение в обработку естественного языка. Эмбеддинги. Рекуррентные нейронные сети.
8. Seq2seq. Механизм внимания. Transformer.
9. Transfer learning в NLP. BERTology.
10. Из NLP в CV: Vision Transformers, CLIP.


## Полезные материалы

* [Курс Алексея Озерина]( https://github.com/m12sl/dl-hse-2021)
* [Материалы с курса бакалавриата](https://github.com/aosokin/dl_cshse_ami/tree/master/2021-fall/homeworks_small)
* [Курс стендфорда](https://cs231n.github.io/) ---  есть не все темы, которые будут на нашем курсе, но материалы очень классные. Из этого курса мы тоже переисползьуем материалы и в лекциях, и в семинарах
* [DLSchool](https://www.dlschool.org/) --- много классных домашек и проект в конце курса, там есть и про NLP, и про CV, на некоторых прогонах затрагивали и работу со звуком (на ютубе можно найти записи прогонов прошлых лет, на степики старые прогоны курса тоже можно найти)
* [distill.pub](https://distill.pub/) --- блог с красивыми визуализациями разных штук из DL
* [Lena Voita](https://lena-voita.github.io/) --- классный блог по NLP
* [Jay Alammar](https://jalammar.github.io/) --- еще один популярный блог со статьями по NLP
* [Pytorch Docs](https://pytorch.org/docs/stable/index.html)

На саммом деле, эти блоги обычно гуглятся, если вы пытаетесь разобраться в какой-то теме
