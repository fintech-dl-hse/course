# Материалы курса Глубинное обучение

Курс будет основан на материалах других курсов:
* [Курс Алексея Озерина]( https://github.com/m12sl/dl-hse-2021)
* [Материалы с курса бакалавриата](https://github.com/aosokin/dl_cshse_ami/tree/master/2021-fall/homeworks_small)

### Планируется

* 12 лекций и семинаров
* 5 домашек

Материалы будут выкладываться в течение курса.

**Обратная связь.** пожалуйста, заполняйте формы обратной связи. Чтобы мотивация была более понятной, в конце формы обратной связи есть **мем**). Желательно заполнять открытые вопросы --- в них можете высказать все, что угодно)

**Сложность курса.** Понятно, что на курсе будут люди с разными бэкграундами. Если вам что-то не понятно, не стесняйтесь задавать вопрос. Или наоборот, если кажется что слишком просто, приходите в личку, придумаем интересную задачку :)

## Как задавать вопросы?

* не стесняться, не бывает глупых вопросов
* в общий чатик --- так есть вероятность, что вам может помочь кто-то из одногруппников быстрее, чем преподаватель
* на лекциях или семах
* в личку

## Занятия

Домашки будут сдаваться в github classroom. Чтобы получить инвайт, заполните, пожалуйста, [форму](https://docs.google.com/forms/d/e/1FAIpQLScE3EKAA5Yo8IkWDumVdnVtleb3551ujli9wFpZMK_MINseKA/viewform?usp=sf_link)
### 1 неделя

Алгоритм обратного распространения ошибки.

* Лекция
* [Семинар](./seminars/01_seminar.ipynb)
* [Бонусная домашка на 0 баллов](./homeworks/HW-00.md)
* [Обратная связь](https://docs.google.com/forms/d/e/1FAIpQLSerebTHr9eLTNgOgSHcFe9fOXzPgUgrgGcOD0wTo_1CxM2Piw/viewform?usp=sf_link)


## Домашки

|   | Домашка        | Количество баллов |
|---|----------------|-------------------|
| 1 | PyTorch basics | 2                 |
| 2 | NN training    | 2                 |
| 3 | NN debug       | 2                 |
| 4 | CV             | 4                 |
| 5 | NLP            | 4                 |

**Списывание (!):** За списывание зануляются все работы. Если используете код из открытых источников, пожалуйста указывайте ссылки.

**Сдача:** Домашки будут сдаваться в github classroom. Чтобы получить инвайт, заполните, пожалуйста [**форму**](https://docs.google.com/forms/d/e/1FAIpQLScE3EKAA5Yo8IkWDumVdnVtleb3551ujli9wFpZMK_MINseKA/viewform?usp=sf_link)

В репозиториях с домашками не стоит трогать файлы тестов или файлы с github-action workflow.
В домашках настроил автоматическое оценивание. Временем сдачи домашки будет считаться
время, когда прошли пайплайны (то есть не время коммита, а время пуша + время на прогон тестов).

Кроме автоматического оценивания, конечно, я буду смотреть само содержание ноутбуков, давать фидбэк.
За неоптимальные решения или за неправильные решения баллы могут снижаться.
То есть оценка, которую вы получили в пайплайнах не конечная

**Штрафы:** За просрочку за каждый день будет сниматься по `10%` от оценки, но суммарно штраф не может быть более `30%`.

## Формула

<img src="https://render.githubusercontent.com/render/math?math=O_%7Bhw%7D%20%3D%20%5Csum_i%20O_%7Bhw_i%7D" height=30>
<img src="https://render.githubusercontent.com/render/math?math=O_%7Btotal%7D%20%3D%200.7%20*%20%5Cfrac%2010%2012%20O_%7Bhw%7D%20%2B%200.3%20*%20O_%7Bexam%7D" height=30>

Автомат можно получить, если `O_{hw} >= 6.0`. В случае автомата итоговая оценка будет нормированной `O_{hw}`: `O_{total} = 10/12 * O_{hw}`

То есть для минимального автомата идеально сделать первые 3 домашки. Тогда `O_{total} = (2 + 2 + 2) * 10 / 12 = 5`

## Экзамен

Если не получили автомат или хотите повысить балл, можно написать экзамен.

Письменно задачки + теормин (тоже письменно или можно устно), ближе к экзамену будет более подробная информация.


## Основные темы

1. Введение в глубинное обучение. Алгоритм обратного распространения ошибки.
2. Функции активации, инициализация весов. Loss-функции, тренировочный цикл.
3. Оптимизация нейросетей. Дропаут и нормализация по батчам.
4. best practises (как обучать нейросети)
5. Свёрточные нейросети. AlexNet, VGG, Inception, ResNet. Обзор задач компьютерного зрения.
6. Автокодировщики. Генеративныe нейронные сети.
7.  Введение в обработку естественного языка. Эмбеддинги. Рекуррентные нейронные сети.
8. Seq2seq. Механизм внимания. Transformer
9. Transfer learning в NLP. BERT.
