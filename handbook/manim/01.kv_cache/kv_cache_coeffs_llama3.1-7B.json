{
  "formula": "size_bytes = a * n_tokens + b",
  "a_bytes_per_token": 131072,
  "b_bytes": 0,
  "meta": {
    "model": "unsloth/Meta-Llama-3.1-8B",
    "dtype": "float16",
    "hidden_size": 4096,
    "num_layers": 32,
    "num_attention_heads": 32,
    "num_key_value_heads": 8,
    "head_dim": 128,
    "counts": [
      10000,
      100000,
      1000000
    ]
  }
}