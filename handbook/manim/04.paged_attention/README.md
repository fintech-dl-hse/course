**Paged attention**

Хорошо, мы научились делать батчинг. Но как во время генерации эффективно хранить KV-Cache?

Мы хотим, чтобы:
* При генерации нового токена не нужно было каждый раз делать torch.cat , создавать новый тензор, аллоцировать новую память (так делает HF  DynamicCache - но это неэффективно!)
* Память для разных запросов, обрабатывающихся параллельно была непрерывной

Выделяем память блоками, заполняем эти блоки. Блоки для одного запроса хорошо бы хранить рядом.

А где хранится KV-Cache? В самом простом варианте - на NFS.
Но есть и более оптимальные варианты (deepseek 3FS, nvidia NIXL)