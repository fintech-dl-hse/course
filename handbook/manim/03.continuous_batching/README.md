**Continuous batching** - —ç—Ç–æ –∫–æ–≥–¥–∞ `input_ids` —É –Ω–∞—Å —Ö–Ω–∞—Ä—è—Ç—Å—è –Ω–µ –≤ –≤–∏–¥–µ –¥–≤—É–º–µ—Ä–Ω–æ–≥–æ `[ bs, max_seq_len ]` —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º, –∞ –≤ –≤–∏–¥–µ –æ–¥–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ `[  seq_len_1 + seq_len_2 + seq_len_3 ... ]` –∏ —Å–æ–≤—Å–µ–º –Ω–µ—Ç –ø–∞–¥–¥–∏–Ω–≥–∞ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –µ—â–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä —Å –¥–ª–∏–Ω–∞–º–∏ —Å—ç–º–ø–ª–æ–≤ `[ seq_len_1, seq_len_2, seq_len_3 ]`, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å, –≥–¥–µ –≥—Ä–∞–Ω–∏—Ü—ã –∞—Ç–µ–Ω—à–Ω–∞ –Ω—É–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å.

üôâ **–ü—Ä–æ–±–ª–µ–º—ã –±—ã—Ç—á–∏–Ω–≥–∞ —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º:**
* –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—ç–º–ø–ª–æ–≤ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω–Ω—ã: –µ—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ä–µ–∞—Ü–∏—é –¥–ª—è –¥–≤—É—Ö —Å—ç–º–ø–ª–æ–≤: –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–≥–æ, –ø–∞–º—è—Ç–∏ –±—É–¥–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –¥–ª—è –¥–≤—É—Ö –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö
* –î–æ—Ä–æ–≥–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –±–∞—Ç—á–∞ —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º: –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–≥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω–Ω—ã, –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è –º–æ–≥—É—Ç –∑–∞–∫–æ–Ω—á–∏—Ç—å—Å—è
* –ü–∞–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω—ã –∑–∞–Ω–∏–º–∞—é—Ç –ª–∏—à–Ω—é—é –ø–∞–º—è—Ç—å –∏ —É–º–µ–Ω—å—à–∞—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å –∫—ç—à–µ–º –Ω–∞ GPU

üí™ **–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:**
* –ú–æ–∂–µ—Ç –∏–º–µ—Ç—å —Å–º—ã—Å–ª, –µ—Å–ª–∏ –¥–µ–ª–∞–µ–º SFT –Ω–∞ –¥–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: –≤ –±–∞—Ç—á–µ —Å—ç–º–ø–ª—ã ,–±—É–¥—É—Ç –∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ, –∏ –æ–±—ã—á–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ

ü§ñ **–í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞:**
* –í–æ –≤—Ä–µ–º—è decode —ç—Ç–∞–ø–∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω–æ

‚ùì **–ö–∞–∫ –µ—â–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É?**
–ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ –¥–ª–∏–Ω–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –Ω–æ —ç—Ç–æ –º–µ–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ –∏ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –Ω–æ–¥—ã —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏ –±—É–¥—É—Ç –∑–∞–º–µ—Ç–Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –≥–µ–Ω–µ—Ä–∏—Ç—å —Ç–æ–∫–µ–Ω—ã

**PS** –í –∫–æ–¥–µ HF Transformers, –∫—Å—Ç–∞—Ç–∏, —Å–¥–µ–ª–∞–Ω–æ –∫–æ—Å—Ç—ã–ª—å–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–∞–¥–æ [–ø–µ—Ä–µ–≥–æ–Ω—è—Ç—å](https://github.com/huggingface/transformers/blob/bb45d3631ec7026db04a77d33a52b31766372160/src/transformers/modeling_flash_attention_utils.py#L189) —Ç–µ–Ω–∑–æ—Ä —ç–º–±—ç–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –≤–∏–¥–∞ –±–∞—Ç—á —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º –≤–æ flatten –≤–∏–¥, –∏ –æ–±—Ä–∞—Ç–Ω–æ –∫–∞–∂–¥—ã–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è flash attention. –í [SDPA¬†–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏](https://github.com/huggingface/transformers/blob/main/src/transformers/integrations/sdpa_attention.py) —Ç–∞–∫–∏—Ö –∫–æ—Å—Ç—ã–ª–µ–π –Ω–µ—Ç - –æ–Ω —É–º–µ–µ—Ç –∏ —Å –ø–∞–∂–µ–Ω—ã–º–∏ —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ SDPA –Ω–∞–æ–±–æ—Ä–æ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Ç–∏–≤–Ω–æ continuous batching.