{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP –Ω–∞ PyTorch –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "## –ü–ª–∞–Ω —Å–µ–º–∏–Ω–∞—Ä–∞\n",
    "\n",
    "### –ß–∞—Å—Ç—å I: PyTorch MLP\n",
    "* –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch (–±–∞–∑–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã, broadcasting)\n",
    "* –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (make_moons)\n",
    "* –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ MLP –Ω–∞ PyTorch\n",
    "* –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "* –†–æ–ª—å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π\n",
    "* –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SVM\n",
    "* –ë–∞—Ç—á–∏–Ω–≥ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\n",
    "\n",
    "### –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation\n",
    "* –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?\n",
    "* Forward –∏ backward pass\n",
    "* Chain rule –∏ backpropagation\n",
    "* –ü—Ä–∏–º–µ—Ä—ã autograd –≤ PyTorch\n",
    "* –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ autograd\n",
    "\n",
    "### –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ß–∞—Å—Ç—å I: PyTorch MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch\n",
    "\n",
    "PyTorch - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Meta (Facebook).\n",
    "\n",
    "**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**\n",
    "* –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π API (–ø–æ—Ö–æ–∂ –Ω–∞ NumPy)\n",
    "* –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π computational graph\n",
    "* –£–¥–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è GPU\n",
    "* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "### –ê–Ω–∞–ª–æ–≥–∏—è —Å NumPy\n",
    "\n",
    "PyTorch tensors —Ä–∞–±–æ—Ç–∞—é—Ç –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# NumPy\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"NumPy array:\", np_array)\n",
    "print(\"Shape:\", np_array.shape)\n",
    "print(\"Mean:\", np_array.mean())\n",
    "\n",
    "print()\n",
    "\n",
    "# PyTorch (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ!)\n",
    "torch_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"PyTorch tensor:\", torch_tensor)\n",
    "print(\"Shape:\", torch_tensor.shape)\n",
    "print(\"Mean:\", torch_tensor.float().mean())  # PyTorch —Ç—Ä–µ–±—É–µ—Ç float –¥–ª—è mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤\n",
    "a = torch.zeros(3, 4)        # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –Ω—É–ª–µ–π\n",
    "b = torch.ones(3, 4)         # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –µ–¥–∏–Ω–∏—Ü\n",
    "c = torch.rand(3, 4)         # –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ [0, 1)\n",
    "d = torch.randn(3, 4)        # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N(0, 1)\n",
    "\n",
    "print(\"Zeros:\\n\", a)\n",
    "print(\"\\nOnes:\\n\", b)\n",
    "print(\"\\nRandom uniform:\\n\", c)\n",
    "print(\"\\nRandom normal:\\n\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"x + y =\", x + y)\n",
    "print(\"x * y =\", x * y)\n",
    "print(\"x @ y =\", x @ y)  # –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (dot product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting –≤ PyTorch\n",
    "\n",
    "**Broadcasting** - –º–µ—Ö–∞–Ω–∏–∑–º, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤.\n",
    "\n",
    "PyTorch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ \"—Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç\" —Ç–µ–Ω–∑–æ—Ä—ã –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞–ª–∏ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "**–ü—Ä–∞–≤–∏–ª–∞ broadcasting:**\n",
    "1. –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä—ã –∏–º–µ—é—Ç —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π, —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞ —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–π –¥–æ–ø–æ–ª–Ω—è–µ—Ç—Å—è –µ–¥–∏–Ω–∏—Ü–∞–º–∏ —Å–ª–µ–≤–∞\n",
    "2. –†–∞–∑–º–µ—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏, –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–≤–Ω—ã –∏–ª–∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö —Ä–∞–≤–µ–Ω 1\n",
    "3. –¢–µ–Ω–∑–æ—Ä—ã —Ä–∞—Å—à–∏—Ä—è—é—Ç—Å—è –ø–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º —Ä–∞–∑–º–µ—Ä–æ–º 1\n",
    "\n",
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ: [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä 1: –í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä\n",
    "x = torch.tensor([1.0, 2.0, 3.0])  # shape: (3,)\n",
    "scalar = 10.0                       # shape: ()\n",
    "\n",
    "result = x + scalar\n",
    "print(\"–í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä:\")\n",
    "print(f\"  {x.tolist()} + {scalar} = {result.tolist()}\")\n",
    "print(f\"  Shapes: {x.shape} + () = {result.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä 2: –ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä\n",
    "matrix = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                        [4.0, 5.0, 6.0]])  # shape: (2, 3)\n",
    "vector = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,)\n",
    "\n",
    "result = matrix + vector\n",
    "print(\"–ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä:\")\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "print(\"Vector:\", vector)\n",
    "print(\"Result:\\n\", result)\n",
    "print(f\"Shapes: {matrix.shape} + {vector.shape} = {result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä 3: Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã\n",
    "a = torch.tensor([[1.0],\n",
    "                  [2.0],\n",
    "                  [3.0]])  # shape: (3, 1)\n",
    "\n",
    "b = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,) ‚Üí –±—É–¥–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ (1, 3)\n",
    "\n",
    "result = a + b\n",
    "print(\"Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã:\")\n",
    "print(\"a (3, 1):\\n\", a)\n",
    "print(\"b (3,):\", b)\n",
    "print(\"Result (3, 3):\\n\", result)\n",
    "print(f\"Shapes: {a.shape} + {b.shape} ‚Üí {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch vs NumPy: –∫–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è\n",
    "\n",
    "| –ê—Å–ø–µ–∫—Ç | NumPy | PyTorch |\n",
    "|--------|-------|---------|\n",
    "| –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | `ndarray` | `Tensor` |\n",
    "| GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.cuda()`, `.to('cuda')`) |\n",
    "| Autograd | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.backward()`) |\n",
    "| –°–æ–∑–¥–∞–Ω–∏–µ | `np.array([1,2,3])` | `torch.tensor([1,2,3])` |\n",
    "| –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ | `np.random.rand(3,4)` | `torch.rand(3,4)` |\n",
    "| Broadcasting | ‚úÖ –î–∞ | ‚úÖ –î–∞ (—Ç–µ –∂–µ –ø—Ä–∞–≤–∏–ª–∞) |\n",
    "\n",
    "**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PyTorch –≤–º–µ—Å—Ç–æ NumPy:**\n",
    "* –ù—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (autograd!)\n",
    "* –ù—É–∂–Ω—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU\n",
    "* –†–∞–±–æ—Ç–∞–µ—Ç–µ —Å –≥–ª—É–±–æ–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNZjDEpYtwyY"
   },
   "source": [
    "#  –î–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "KYSS6l5gw_1s",
    "outputId": "09d529ef-d57e-4de1-ed11-bc643d7423a0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy_q7pzptyre"
   },
   "source": [
    "# Torch MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OetRh60Dvhxa"
   },
   "source": [
    "## –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoNNGooNzOHG",
    "outputId": "3bb3ed04-61b4-4d9a-9c8b-5dc72106dccc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# initialize a model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, activation_cls=nn.Sigmoid):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer  = nn.Linear(2, 100)\n",
    "        self.hidden_layer = nn.Linear(100, 100)\n",
    "        self.output_layer = nn.Linear(100, 1)\n",
    "        self.activation   = activation_cls()\n",
    "\n",
    "        return\n",
    "\n",
    "    def forward(self, x_coordinates):\n",
    "        # x_coordinates ~ [ batch_size, 2 ]\n",
    "\n",
    "        latents = self.activation(self.input_layer(x_coordinates)) # [ batch_size, 100 ]\n",
    "        latents = self.activation(self.hidden_layer(latents))      # [ batch_size, 100 ]\n",
    "        scores = self.output_layer(latents)                        # [ batch_size, 1 ]\n",
    "        scores = scores[:, 0]                                      # [ batch_size ]\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "print(model)\n",
    "print(\"number of parameters\", sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rj4Cb3Y0u7D4",
    "outputId": "4407dcf0-0f3a-418a-a4be-8179bc527750"
   },
   "outputs": [],
   "source": [
    "print(\"Parameters shapes:\")\n",
    "print([p.shape for p in model.hidden_layer.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLjcbIWAuyZO",
    "outputId": "f1f6f710-65bd-46bc-b521-f69ec8276f70"
   },
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pga4AR9vpfp"
   },
   "source": [
    "## –í—ã—á–∏—Å–ª—è–µ–º –ª–æ—Å—Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVFgqO15w5rf",
    "outputId": "fa99bd36-8dd4-4dcc-eed5-c57a1f25417e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# loss function\n",
    "def loss(model, Xbatch, ybatch):\n",
    "\n",
    "    Xbatch = torch.tensor(Xbatch).float() # [ batch_size, 2 ]\n",
    "\n",
    "    # ybatch.max() == 1, ybatch.min() == -1\n",
    "    ybatch = torch.tensor(ybatch).float().unsqueeze(-1) # [ batch_size, 1 ]\n",
    "\n",
    "    # forward the model to get scores\n",
    "    model_prediction = model.forward(Xbatch) # [ batch_size, 1 ]\n",
    "\n",
    "    # svm \"max-margin\" loss\n",
    "    losses = F.relu(1 - ybatch * model_prediction) # [ batch_size, 1 ]\n",
    "    loss = losses.mean()\n",
    "\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p).sum() for p in model.parameters())\n",
    "    total_loss = loss + reg_loss\n",
    "\n",
    "    # also get accuracy\n",
    "    accuracy = ((ybatch > 0) == (model_prediction > 0)).float().mean()\n",
    "    return total_loss, accuracy\n",
    "\n",
    "total_loss, acc = loss(model, X, y)\n",
    "print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPAdy2Qyx_1d",
    "outputId": "5b35cdfc-e192-41f1-a8f0-9744ed8aefed"
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "\n",
    "def train(model, learning_rate=0.1):\n",
    "\n",
    "    Xbatch, ybatch = make_moons(n_samples=100, noise=0.1, random_state=1)\n",
    "    ybatch = ybatch * 2 - 1 # make y be -1 or 1\n",
    "\n",
    "    for k in range(300):\n",
    "\n",
    "        model.zero_grad() # –æ–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞\n",
    "\n",
    "        # forward\n",
    "        total_loss, acc = loss(model, Xbatch, ybatch)\n",
    "\n",
    "        # backward\n",
    "        total_loss.backward() # –≤—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "        # (model.linear_in.weight.grad)\n",
    "\n",
    "        # —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "        # update (sgd)\n",
    "        for p in model.parameters():\n",
    "            p.data = p.data - learning_rate * p.grad\n",
    "\n",
    "        if k % 50 == 0:\n",
    "            print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "train(model, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Yw0BJub0yCPZ",
    "outputId": "5fdd05f8-a475-4579-b009-c14e9de96a5d"
   },
   "outputs": [],
   "source": [
    "def visualize_model_prediction(model):\n",
    "\n",
    "    h = 0.25\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                        np.arange(y_min, y_max, h))\n",
    "    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    if isinstance(model, nn.Module):\n",
    "        with torch.no_grad():\n",
    "            Xbatch = torch.tensor(Xmesh).float()\n",
    "\n",
    "            scores = model.forward(Xbatch)\n",
    "            Z = scores.numpy()\n",
    "\n",
    "    else:\n",
    "        scores = clf.decision_function(Xmesh)\n",
    "        Z = scores\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "visualize_model_prediction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4if_V-0TuJnC"
   },
   "source": [
    "## –í–∫–ª–∞–¥ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "c-YftStquSF2",
    "outputId": "bd46e38a-2d19-41b7-b850-e9cec0f223d0"
   },
   "outputs": [],
   "source": [
    "model = MLP(activation_cls=nn.ReLU)\n",
    "\n",
    "train(model, learning_rate=0.1)\n",
    "visualize_model_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "x7oYRla5uPcV",
    "outputId": "e7d57cca-25a1-41ca-b612-15342e05eb4c"
   },
   "outputs": [],
   "source": [
    "# nn.Identity(x) == x\n",
    "model = MLP(activation_cls=nn.Identity)\n",
    "\n",
    "train(model, learning_rate=0.1)\n",
    "visualize_model_prediction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAKEWamSuKNz"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLTFqLnWkB0j"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Z33DbEWZvaHA",
    "outputId": "6482ab15-1bf1-4c8f-91be-649d98d4335c"
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X, y)\n",
    "visualize_model_prediction(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "fEx1B43CvV_7",
    "outputId": "64bd4949-06d6-4a43-9425-0803c001cc6e"
   },
   "outputs": [],
   "source": [
    "# –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è SVM\n",
    "# https://www.youtube.com/watch?v=OdlNM96sHio\n",
    "\n",
    "clf = SVC(random_state=0, C=1.0, kernel='poly', degree=3)\n",
    "clf.fit(X, y)\n",
    "visualize_model_prediction(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "f6VARd2JvFYp",
    "outputId": "093aa9bd-12b8-4cc5-b84f-db12ba47bf9c"
   },
   "outputs": [],
   "source": [
    "clf = SVC(random_state=0, C=1.0, kernel='rbf')\n",
    "clf.fit(X, y)\n",
    "visualize_model_prediction(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpwJ9Xpgrllp"
   },
   "source": [
    "# –ë–∞—Ç—á–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è / –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLo7j6ldrpHn",
    "outputId": "3b331474-a981-484e-c4b6-7a918670b22b"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    Xbatch = torch.rand([1000, 2])\n",
    "    model.forward(Xbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rpfZmXnsD1S",
    "outputId": "81227bc6-6e3a-4915-fde0-bb77719a4b9f"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    Xbatch = torch.rand([1000, 2])\n",
    "    for i in range(Xbatch.shape[0]):\n",
    "        model.forward(Xbatch[i:i+1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ß–∞—Å—Ç—å II: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?\n",
    "\n",
    "–ù–∞ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ PyTorch –∫–∞–∫ \"—á–µ—Ä–Ω—ã–π —è—â–∏–∫\". –ú—ã –≤—ã–∑—ã–≤–∞–ª–∏ `loss.backward()` –∏ –º–∞–≥–∏—á–µ—Å–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ù–æ –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞—á–µ–º –º—ã –ø–∏–ª–∏–º –∞–≤—Ç–æ–≥—Ä–∞–¥? ü§ñ\n",
    "\n",
    "–ß—Ç–æ–±—ã –Ω–µ —Å—á–∏—Ç–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é!\n",
    "\n",
    "## –ß—Ç–æ –º—ã –∑–∞–ø–æ–º–Ω–∏–ª–∏ –Ω–∞ –ª–µ–∫—Ü–∏–∏? ü§∑\n",
    "\n",
    "* –Ω–µ–π—Ä–æ—Å–µ—Ç—å -- —ç—Ç–æ —Å–ª–æ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏), –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –∫–∞–∫ –∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ—Å—Ç—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n",
    "* –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞\n",
    "\n",
    "–ß—Ç–æ–±—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –Ω–∞–º –Ω—É–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∞–≤—Ç–æ–≥—Ä–∞–¥–æ–º? ü™Ñ\n",
    "\n",
    "–û—Ç –∞–≤—Ç–æ–≥—Ä–∞–¥–∞ –Ω–∞–º –Ω—É–∂–Ω–æ 2 –≤–µ—â–∏: **forward** –∏ **backward pass**.\n",
    "\n",
    "### **forward pass**\n",
    "–ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –∏–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ —Å–µ—Ç–∏: –ø–æ–¥–∞–µ–º –≤—Ö–æ–¥, –ø—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏, –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.\n",
    "\n",
    "### **backward pass**\n",
    "–ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã: –Ω–∞—á–∏–Ω–∞–µ–º —Å loss —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∏–¥–µ–º –Ω–∞–∑–∞–¥ –ø–æ —Å–µ—Ç–∏, –≤—ã—á–∏—Å–ª—è—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å –ø–æ–º–æ—â—å—é chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation + Chain rule = ‚ù§Ô∏è\n",
    "\n",
    "**Chain rule (–ø—Ä–∞–≤–∏–ª–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)**:\n",
    "\n",
    "–ï—Å–ª–∏ $F = f(g(x))$, —Ç–æ $\\frac{dF}{dx} = \\frac{dF}{dg} \\cdot \\frac{dg}{dx}$\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä:\n",
    "\\begin{align*}\n",
    "F &= (a + b) c  \\\\\n",
    "q &= a + b  \\\\\n",
    "F &= q c\n",
    "\\end{align*}\n",
    "\n",
    "–¢–æ–≥–¥–∞:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial a} &= \\frac{\\partial F}{\\partial q} \\cdot \\frac{\\partial q}{\\partial a} = c \\cdot 1 = c \\\\\n",
    "\\frac{\\partial F}{\\partial b} &= \\frac{\\partial F}{\\partial q} \\cdot \\frac{\\partial q}{\\partial b} = c \\cdot 1 = c \\\\\n",
    "\\frac{\\partial F}{\\partial c} &= q\n",
    "\\end{align*}\n",
    "\n",
    "**Backpropagation** - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ chain rule –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ú–∞—Ç—Ä–∏—á–Ω–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏ –º—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏–º–µ–µ–º –¥–µ–ª–æ —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏ –º–∞—Ç—Ä–∏—Ü–∞–º–∏. –ß—Ç–æ–±—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã, –Ω–∞–º –Ω—É–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "## –û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è\n",
    "\n",
    "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è:\n",
    "\n",
    "- **–°–∫–∞–ª—è—Ä—ã**: $a, b, c$ (–æ–±—ã—á–Ω—ã–µ —á–∏—Å–ª–∞)\n",
    "- **–í–µ–∫—Ç–æ—Ä—ã**: $\\mathbf{x}, \\mathbf{y}, \\mathbf{w}$ (–∂–∏—Ä–Ω—ã–µ —Å—Ç—Ä–æ—á–Ω—ã–µ –±—É–∫–≤—ã)\n",
    "  - $\\mathbf{x} \\in \\mathbb{R}^n$ ‚Äî –≤–µ–∫—Ç–æ—Ä-—Å—Ç–æ–ª–±–µ—Ü —Ä–∞–∑–º–µ—Ä–∞ $n$\n",
    "- **–ú–∞—Ç—Ä–∏—Ü—ã**: $W, X, A$ (–∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã)\n",
    "  - $W \\in \\mathbb{R}^{m \\times n}$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ $m \\times n$\n",
    "- **–¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ**: $\\mathbf{x}^T, W^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–∏–ø—ã –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö\n",
    "\n",
    "–í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ –ø–æ —á–µ–º—É –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º, –ø–æ–ª—É—á–∞–µ–º —Ä–∞–∑–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã:\n",
    "\n",
    "| –ß–∏—Å–ª–∏—Ç–µ–ª—å | –ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å | –†–µ–∑—É–ª—å—Ç–∞—Ç | –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å | –ù–∞–∑–≤–∞–Ω–∏–µ |\n",
    "|-----------|-------------|-----------|-------------|----------|\n",
    "| –°–∫–∞–ª—è—Ä $y$ | –í–µ–∫—Ç–æ—Ä $\\mathbf{x} \\in \\mathbb{R}^n$ | –í–µ–∫—Ç–æ—Ä | $n \\times 1$ | –ì—Ä–∞–¥–∏–µ–Ω—Ç |\n",
    "| –í–µ–∫—Ç–æ—Ä $\\mathbf{y} \\in \\mathbb{R}^m$ | –°–∫–∞–ª—è—Ä $x$ | –í–µ–∫—Ç–æ—Ä | $m \\times 1$ | –¢–∞–Ω–≥–µ–Ω—Å |\n",
    "| –í–µ–∫—Ç–æ—Ä $\\mathbf{y} \\in \\mathbb{R}^m$ | –í–µ–∫—Ç–æ—Ä $\\mathbf{x} \\in \\mathbb{R}^n$ | –ú–∞—Ç—Ä–∏—Ü–∞ | $m \\times n$ | –Ø–∫–æ–±–∏–∞–Ω |\n",
    "| –°–∫–∞–ª—è—Ä $y$ | –ú–∞—Ç—Ä–∏—Ü–∞ $W \\in \\mathbb{R}^{m \\times n}$ | –ú–∞—Ç—Ä–∏—Ü–∞ | $m \\times n$ | –ì—Ä–∞–¥–∏–µ–Ω—Ç |\n",
    "\n",
    "**–í–∞–∂–Ω–æ**: –í –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö —á–∞—â–µ –≤—Å–µ–≥–æ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è **—Å–∫–∞–ª—è—Ä–∞** (—Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å) –ø–æ **–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º** (–≤–µ–∫—Ç–æ—Ä–∞–º –∏–ª–∏ –º–∞—Ç—Ä–∏—Ü–∞–º)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "### 1. –õ–∏–Ω–µ–π–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "\n",
    "**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ª–∏–Ω–µ–π–Ω–æ–π —Ñ–æ—Ä–º—ã:**\n",
    "$$\\frac{\\partial (\\mathbf{a}^T \\mathbf{x})}{\\partial \\mathbf{x}} = \\mathbf{a}$$\n",
    "\n",
    "–≥–¥–µ $\\mathbf{a}$ ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä, $\\mathbf{x}$ ‚Äî –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è.\n",
    "\n",
    "**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π —Ñ–æ—Ä–º—ã:**\n",
    "$$\\frac{\\partial (\\mathbf{x}^T W \\mathbf{x})}{\\partial \\mathbf{x}} = (W + W^T) \\mathbf{x}$$\n",
    "\n",
    "–ï—Å–ª–∏ $W$ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è ($W = W^T$), —Ç–æ:\n",
    "$$\\frac{\\partial (\\mathbf{x}^T W \\mathbf{x})}{\\partial \\mathbf{x}} = 2W\\mathbf{x}$$\n",
    "\n",
    "**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –Ω–æ—Ä–º—ã:**\n",
    "$$\\frac{\\partial \\|\\mathbf{x}\\|^2}{\\partial \\mathbf{x}} = \\frac{\\partial (\\mathbf{x}^T \\mathbf{x})}{\\partial \\mathbf{x}} = 2\\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. –ú–∞—Ç—Ä–∏—á–Ω–æ-–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ\n",
    "\n",
    "**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –≤–µ–∫—Ç–æ—Ä—É:**\n",
    "$$\\frac{\\partial (W\\mathbf{x})}{\\partial \\mathbf{x}} = W^T$$\n",
    "\n",
    "**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –º–∞—Ç—Ä–∏—Ü–µ:**\n",
    "$$\\frac{\\partial (\\mathbf{a}^T W \\mathbf{x})}{\\partial W} = \\mathbf{a} \\mathbf{x}^T$$\n",
    "\n",
    "–≥–¥–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ $m \\times n$ (–≤–Ω–µ—à–Ω–µ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤).\n",
    "\n",
    "### 3. Chain Rule –¥–ª—è –º–∞—Ç—Ä–∏—Ü\n",
    "\n",
    "–ï—Å–ª–∏ $y = f(\\mathbf{z})$ –∏ $\\mathbf{z} = g(\\mathbf{x})$, —Ç–æ:\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial \\mathbf{x}} = \\frac{\\partial y}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}$$\n",
    "\n",
    "–≥–¥–µ $\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}}$ ‚Äî —ç—Ç–æ –º–∞—Ç—Ä–∏—Ü–∞ –Ø–∫–æ–±–∏ —Ä–∞–∑–º–µ—Ä–∞ $|\\mathbf{z}| \\times |\\mathbf{x}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π\n",
    "\n",
    "### –ü—Ä–∏–º–µ—Ä 1: –õ–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π: $\\mathbf{z} = W\\mathbf{x} + \\mathbf{b}$\n",
    "\n",
    "**–î–∞–Ω–æ**: –≥—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å –ø–æ –≤—ã—Ö–æ–¥—É $\\frac{\\partial L}{\\partial \\mathbf{z}}$\n",
    "\n",
    "**–ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏**:\n",
    "- $\\frac{\\partial L}{\\partial W}$ ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –≤–µ—Å–∞–º\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{x}}$ ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –≤—Ö–æ–¥—É (–¥–ª—è backprop –¥–∞–ª—å—à–µ)\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{b}}$ ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ bias\n",
    "\n",
    "**–†–µ—à–µ–Ω–∏–µ**:\n",
    "\n",
    "1. –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –≤–µ—Å–∞–º:\n",
    "$$\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\mathbf{x}^T$$\n",
    "\n",
    "2. –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –≤—Ö–æ–¥—É:\n",
    "$$\\frac{\\partial L}{\\partial \\mathbf{x}} = W^T \\cdot \\frac{\\partial L}{\\partial \\mathbf{z}}$$\n",
    "\n",
    "3. –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ bias:\n",
    "$$\\frac{\\partial L}{\\partial \\mathbf{b}} = \\frac{\\partial L}{\\partial \\mathbf{z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä: –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –≤ PyTorch\n",
    "import torch\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "x = torch.randn(5, requires_grad=True)  # –≤—Ö–æ–¥: –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ 5\n",
    "W = torch.randn(3, 5, requires_grad=True)  # –≤–µ—Å–∞: –º–∞—Ç—Ä–∏—Ü–∞ 3x5\n",
    "b = torch.randn(3, requires_grad=True)  # bias: –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ 3\n",
    "\n",
    "# Forward pass\n",
    "z = W @ x + b  # z = Wx + b\n",
    "loss = z.sum()  # –ø—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (—Å—É–º–º–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "print(\"–ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ W:\")\n",
    "print(f\"  Shape: {W.grad.shape}\")\n",
    "print(f\"  –í—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫: dL/dz * x^T\")\n",
    "print()\n",
    "print(\"–ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ x:\")\n",
    "print(f\"  Shape: {x.grad.shape}\")\n",
    "print(f\"  –í—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫: W^T * dL/dz\")\n",
    "print()\n",
    "print(\"–ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ b:\")\n",
    "print(f\"  Shape: {b.grad.shape}\")\n",
    "print(f\"  –†–∞–≤–µ–Ω dL/dz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä 2: Mean Squared Error (MSE)\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: $L = \\frac{1}{n} \\|\\mathbf{y}_{pred} - \\mathbf{y}_{true}\\|^2 = \\frac{1}{n} \\sum_{i=1}^n (y_{pred}^{(i)} - y_{true}^{(i)})^2$\n",
    "\n",
    "**–ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º:**\n",
    "$$\\frac{\\partial L}{\\partial \\mathbf{y}_{pred}} = \\frac{2}{n}(\\mathbf{y}_{pred} - \\mathbf{y}_{true})$$\n",
    "\n",
    "–≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –≤ —Å—Ç–æ—Ä–æ–Ω—É —É–≤–µ–ª–∏—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º—ã –¥–≤–∏–∂–µ–º—Å—è –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É (gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç MSE\n",
    "y_pred = torch.randn(10, requires_grad=True)\n",
    "y_true = torch.randn(10)\n",
    "\n",
    "# MSE loss\n",
    "loss = ((y_pred - y_true) ** 2).mean()\n",
    "loss.backward()\n",
    "\n",
    "print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\", y_pred.data[:5])\n",
    "print(\"–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\", y_true[:5])\n",
    "print(\"–ì—Ä–∞–¥–∏–µ–Ω—Ç:\", y_pred.grad[:5])\n",
    "print()\n",
    "print(\"–§–æ—Ä–º—É–ª–∞: dL/dy_pred = 2/n * (y_pred - y_true)\")\n",
    "manual_grad = 2 * (y_pred.data - y_true) / len(y_pred)\n",
    "print(\"–†—É—á–Ω–æ–π —Ä–∞—Å—á–µ—Ç:\", manual_grad[:5])\n",
    "print(\"–°–æ–≤–ø–∞–¥–∞–µ—Ç —Å PyTorch:\", torch.allclose(y_pred.grad, manual_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ?\n",
    "\n",
    "1. **–ü–æ–Ω–∏–º–∞–Ω–∏–µ backpropagation**: –í—Å–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–æ —ç—Ç–∏–º –ø—Ä–∞–≤–∏–ª–∞–º\n",
    "2. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –ó–Ω–∞–Ω–∏–µ —Ñ–æ—Ä–º—É–ª –ø–æ–º–æ–≥–∞–µ—Ç –ø–∏—Å–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–¥\n",
    "3. **–û—Ç–ª–∞–¥–∫–∞**: –ú–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤—Ä—É—á–Ω—É—é\n",
    "4. **–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–∏—Ö —Å–ª–æ–µ–≤**: –ü—Ä–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ custom layers –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å, –∫–∞–∫ –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "\n",
    "## –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã\n",
    "\n",
    "- [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/) ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ç—É—Ç–æ—Ä–∏–∞–ª\n",
    "- [Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) ‚Äî —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ñ–æ—Ä–º—É–ª\n",
    "- [CS231n: Backpropagation](https://cs231n.github.io/optimization-2/) ‚Äî –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ backprop —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "- [PyTorch Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) ‚Äî –∫–∞–∫ PyTorch –≤—ã—á–∏—Å–ª—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç autograd –≤ PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SER5uaCUX5Ny"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–ª–∏—è–µ—Ç —Å–ª–æ–∂–µ–Ω–∏–µ?\n",
    "\n",
    "\\begin{align*}\n",
    "c &= a + b \\\\\n",
    "\\frac {\\partial c} {\\partial a} &= 1 \\\\\n",
    "\\frac {\\partial c} {\\partial b} &= 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–ª–∏—è–µ—Ç —É–º–Ω–æ–∂–µ–Ω–∏–µ?\n",
    "\n",
    "\\begin{align*}\n",
    "c &= a \\cdot b \\\\\n",
    "\\frac {\\partial c} {\\partial a} &= b \\\\\n",
    "\\frac {\\partial c} {\\partial b} &= a\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YItDgsCrm8cN",
    "outputId": "a0ad83de-6b9b-4c21-d3a5-86fabdc21b1f"
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor([10.])\n",
    "a.requires_grad = True\n",
    "\n",
    "b = torch.Tensor([10.])\n",
    "b.requires_grad = True\n",
    "\n",
    "—Å = a * b\n",
    "—Å.backward()\n",
    "\n",
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú—ã –≥–æ—Ç–æ–≤—ã —Å–¥–µ–ª–∞—Ç—å —Å–≤–æ–π –∞–≤—Ç–æ–≥—Ä–∞–¥!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU (Rectified Linear Unit)\n",
    "\n",
    "–í —Å–µ–º–∏–Ω–∞—Ä–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ReLU –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è ReLU:\n",
    "\n",
    "$$\n",
    "\\frac{d \\text{ReLU}}{dx} = \\begin{cases} 1, & x > 0 \\\\ 0, & x \\leq 0 \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python magic methods\n",
    "\n",
    "Python –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —á–µ—Ä–µ–∑ magic methods:\n",
    "\n",
    "```python\n",
    "Value(1) + Value(2)\n",
    "# –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤\n",
    "Value(1).__add__(Value(2))\n",
    "```\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ, —á—Ç–æ–±—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ç—Ä–æ–∏—Ç—å computational graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closures (–∑–∞–º—ã–∫–∞–Ω–∏—è)\n",
    "\n",
    "–ó–∞–º—ã–∫–∞–Ω–∏–µ - —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è \"–∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç\" –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–π –æ–±–ª–∞—Å—Ç–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏.\n",
    "\n",
    "```python\n",
    "def make_adder(x):\n",
    "    def adder(y):\n",
    "        return x + y  # x \"–∑–∞–ø–æ–º–Ω–∏–ª–∏\" –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    return adder\n",
    "\n",
    "add_5 = make_adder(5)\n",
    "print(add_5(10))  # 15\n",
    "```\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–º—ã–∫–∞–Ω–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö–ª–∞—Å—Å Value - –Ω–∞—à –∞–≤—Ç–æ–≥—Ä–∞–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è.\"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad  # d(a+b)/da = 1\n",
    "            other.grad += out.grad  # d(a+b)/db = 1\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad  # d(a*b)/da = b\n",
    "            other.grad += self.data * out.grad  # d(a*b)/db = a\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(0 if self.data < 0 else self.data, (self,), 'ReLU')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (out.data > 0) * out.grad  # –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è ReLU\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"–ó–∞–ø—É—Å–∫–∞–µ—Ç backpropagation –æ—Ç —ç—Ç–æ–≥–æ —É–∑–ª–∞.\"\"\"\n",
    "        # –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "\n",
    "        build_topo(self)\n",
    "\n",
    "        # –ò–¥–µ–º –æ—Ç –≤—ã—Ö–æ–¥–∞ –∫ –≤—Ö–æ–¥—É –∏ –≤—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–≥–æ autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä: –≤—ã—á–∏—Å–ª–∏–º f(x, y) = (x + y) * x –∏ –µ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "x = Value(2.0)\n",
    "y = Value(3.0)\n",
    "\n",
    "z = x + y  # z = 5\n",
    "f = z * x  # f = 10\n",
    "\n",
    "print(f\"f = {f.data}\")\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "f.backward()\n",
    "\n",
    "print(f\"df/dx = {x.grad}\")  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: df/dx = z + x = 5 + 2 = 7\n",
    "print(f\"df/dy = {y.grad}\")  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: df/dy = x = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã\n",
    "\n",
    "## –ß–∞—Å—Ç—å I: PyTorch –∏ MLP\n",
    "\n",
    "1. –í —á–µ–º –≥–ª–∞–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ PyTorch –æ—Ç NumPy?\n",
    "\n",
    "2. –ß—Ç–æ —Ç–∞–∫–æ–µ broadcasting? –ü—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä.\n",
    "\n",
    "3. –ö–∞–∫ –ª—É–Ω—ã –º–æ–∂–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è?\n",
    "\n",
    "4. –ß–µ–º –Ω–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MLP –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç LinearSVC?\n",
    "\n",
    "5. –ö–∞–∫ `learning_rate` –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è? –ß—Ç–æ –±—É–¥–µ—Ç —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º lr=1e-8? –° –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–º lr=1e3?\n",
    "\n",
    "6. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—Å–µ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –∏–∑ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏?\n",
    "\n",
    "7. –ß—Ç–æ —Ç–∞–∫–æ–µ –±–∞—Ç—á? –ü–æ—á–µ–º—É –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –±–∞—Ç—á—É—é—Ç—Å—è?\n",
    "\n",
    "8. –ß–µ–º —Ç–µ–Ω–∑–æ—Ä –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç torch –ø–∞—Ä–∞–º–µ—Ç—Ä–∞?\n",
    "\n",
    "## –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation\n",
    "\n",
    "1. –ó–∞—á–µ–º –Ω—É–∂–Ω—ã —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö?\n",
    "\n",
    "2. –ó–∞—á–µ–º –Ω—É–∂–µ–Ω autograd? –ü–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é?\n",
    "\n",
    "3. –ö–æ–≥–¥–∞ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã - –≤–æ –≤—Ä–µ–º—è forward –∏–ª–∏ backward pass?\n",
    "\n",
    "4. –ö–∞–∫–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–º –Ω—É–∂–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –∑–∞—á–µ–º?\n",
    "\n",
    "5. –ö–∞–∫ computational graph, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≤–æ –≤—Ä–µ–º—è forward pass, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ backward pass?\n",
    "\n",
    "6. –ö–∞–∫ —Å–ª–æ–∂–µ–Ω–∏–µ –∏ —É–º–Ω–æ–∂–µ–Ω–∏–µ –≤–ª–∏—è—é—Ç –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã?\n",
    "\n",
    "7. –ß—Ç–æ —Ç–∞–∫–æ–µ closure (–∑–∞–º—ã–∫–∞–Ω–∏–µ) –≤ Python?\n",
    "\n",
    "8. –ö–∞–∫–æ–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —à–∞–≥–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏?\n",
    "   - a) forward ‚Üí backward ‚Üí zero_grad ‚Üí optimizer.step\n",
    "   - b) zero_grad ‚Üí forward ‚Üí backward ‚Üí optimizer.step\n",
    "   - c) backward ‚Üí forward ‚Üí zero_grad ‚Üí optimizer.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
    "\n",
    "* [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "* [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
    "* [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)\n",
    "* [Backpropagation Calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8) - –æ—Ç–ª–∏—á–Ω–æ–µ –≤–∏–¥–µ–æ –æ—Ç 3Blue1Brown\n",
    "* [micrograd](https://github.com/karpathy/micrograd) - –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π autograd engine –æ—Ç Andrej Karpathy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
