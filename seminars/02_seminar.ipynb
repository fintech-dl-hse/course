{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика обучения моделей\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2021/blob/master/02-pytorch/seminar.ipynb)\n",
    "\n",
    "\n",
    "План семинара:\n",
    "\n",
    "- [ ] попробовать писать логи tensorboard\n",
    "- [ ] научиться сохранять/доставать чекпоинты\n",
    "- [ ] разобраться с Dataset API\n",
    "- [ ] написать базовый Trainer - класс с тренировочным циклом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логирование\n",
    "\n",
    "\n",
    "Популярным вариантом для хранения логов является tensorboard: это формат хранения (protobuf, как json только бинарный) + готовый просмотрщик.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/tensorboard) -- это pip-installable web-приложение.\n",
    "\n",
    "```\n",
    "tensorboard --logdirs=./some-folder/with/events-files\n",
    "# зайти на http://localhost:6006\n",
    "```\n",
    "<img src=\"./img/tb.png\"/>\n",
    "\n",
    "При желании, можно написать python-код для парсинга логов и делать что-то с ними руками.\n",
    "\n",
    "Чтобы писать логи в pytorch есть класс `torch.utils.tensorboard.SummaryWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./check-this/\")\n",
    "\n",
    "fake_loss = 1 / np.arange(1, 100)\n",
    "for global_step, point in enumerate(fake_loss):\n",
    "    writer.add_scalar(\"lossy\", point, global_step=global_step)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем TensorBoard\n",
    "\n",
    "В случае локального запуска (или на своем сервере) потребуется поставить tensorboard\n",
    "```\n",
    "pip install tensorboard\n",
    "\n",
    "tensorboard --logdir=./check-this\n",
    "# зайти на http://localhost:6006\n",
    "```\n",
    "\n",
    "Для работы в colab есть специальное расширение. Запустите следующие ячейки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./check-this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение-загрузка тензоров и моделек\n",
    "\n",
    "Нам часто бывает необходимо сохранить/загрузить веса модели в файл на диске. \n",
    "Распространенное название для этого -- checkpoint. \n",
    "\n",
    "У торчевых моделей (наследников torch.nn.Module) и оптимизаторов (наследников torch.optim.Optimizer) есть методы для получения и загрузки состояний:\n",
    "\n",
    "`.state_dict()` возвращает словарь (или почти словарь) с весами\n",
    "\n",
    "`.load_state_dict(some_dict)` загружает веса из словаря в модельку\n",
    "\n",
    "Для сохранения/загрузки словарей с тензорами в файлы есть простые функции `torch.save(some_dict, path)` и `torch.load(path)`. Сравните с использованием pickle или json!\n",
    "\n",
    "**NB: В DL термином checkpointing называют так же метод бекпропа, позволяющий экономить память ценой дополнительных вычислений (https://pytorch.org/docs/stable/checkpoint.html#torch-utils-checkpoint).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_model = nn.Sequential(nn.Linear(10, 10))\n",
    "print(some_model.state_dict())\n",
    "\n",
    "opt = optim.Adam(some_model.parameters())\n",
    "print(opt.state_dict())\n",
    "\n",
    "\n",
    "torch.save({\"model_stuff\": some_model.state_dict(), \"opt_stuff\": opt.state_dict()}, \"./that.is.it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"./that.is.it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset API\n",
    "\n",
    "Подготовка данных легко может стать бутылочным горлышком, когда на подготовку очередного батча уходит больше времени, чем на forward+backward проходы по сети.\n",
    "Проблема усложняется особенностями python: чтобы использовать несколько ядер CPU для подготовки данных надо постараться.\n",
    "\n",
    "В Pytorch работа с данными строится на двух классах из [torch.utils.data](https://pytorch.org/docs/stable/data.html): `Dataset` и `DataLoader`:\n",
    "\n",
    "- `Dataset` отвечает за подготовку одного примера\n",
    "- `DataLoader` отвечает за выбор примеров, склейку их в один батч и распараллеливание на CPU, поддерживает итерирование.\n",
    "\n",
    "\n",
    "Для решения задачи обычно пишут кастомные Dataset-классы, для этого нужно написать всего две функции:\n",
    "- `.__len__(self)` возвращает количество примеров в датасете;\n",
    "- `.__getitem__(self, item)` возвращает item-ный по счету пример из датасета.\n",
    "\n",
    "Задачи DataLoader достаточно сложно аккуратно реализовать и лучше использовать готовый. Он довольно гибкий, все основные моменты кастомизируются заданием функций:\n",
    "```\n",
    "torch.utils.data.DataLoader(\n",
    "    dataset,            # собственно экземпляр класса Dataset, из которого надо доставать примеры\n",
    "    batch_size=1,       # количество примеров в батче\n",
    "    drop_last=False,    # нужно ли при итерировании выбрасывать неполные батчи? (такое бывает, если число примеров не делится нацело на batch_size\n",
    "    shuffle=False,      # перемешивать ли примеры\n",
    "    sampler=None,       # чтобы перемешивать примеры кастомно\n",
    "    batch_sampler=None, # чтобы использовать кастомный отбор примеров в батч\n",
    "    num_workers=0,      # на сколько процессов запараллелить подготовку данных\n",
    "    collate_fn=None,    # функция, которая будет склеивать примеры в батчи\n",
    "    # остальные аргументы более технические, сейчас можно не рассматривать\n",
    "    pin_memory=False,   \n",
    "    timeout=0, \n",
    "    worker_init_fn=None, \n",
    "    multiprocessing_context=None, \n",
    "    generator=None)\n",
    "```\n",
    "\n",
    "Напишите два датасета для работы с FashionMnist: один готовит данные как вектора, другой как картинки\n",
    "\n",
    "\n",
    "**NB: FashionMNIST возвращает картинки в формате PIL.Image.Image, чтобы сделать из него понятный np.array, просто вызовите np.array(PIL_IMAGE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "class VectorSet:\n",
    "    def __init__(self, train=True):\n",
    "        self.data = FashionMNIST(\"./tmp\", train=train, download=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        <your code>\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # сделайте вектор с float32 числами\n",
    "        <your code>\n",
    "        return dict(\n",
    "            sample=...,\n",
    "            label=...,\n",
    "        )\n",
    "\n",
    "vs = VectorSet()\n",
    "print(vs[0])\n",
    "        \n",
    "class ImageSet:\n",
    "    def __init__(self, train=True):\n",
    "        self.data = FashionMNIST(\"./tmp\", train=train, download=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        <your code>\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # сделайте одноканальную картинку [1, 28, 28] с float32\n",
    "        <your code>\n",
    "        return dict(\n",
    "            sample=...,\n",
    "            label=...,\n",
    "        )\n",
    "    \n",
    "ms = ImageSet()\n",
    "print(ms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверьте итерирование, именно его мы используем в train-loop'е\n",
    "vl = DataLoader(vs, batch_size=4)\n",
    "for batch in vl:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замечания по Dataset/Dataloader\n",
    "\n",
    "1. Dataset может возвращать что угодно (туплы, словари, whatever) с отдельными числами или массивами (numpy, torch.tensor).\n",
    "Удобно возвращать словари с читабельными ключами, тогда будет проще разделять логику по компонентам.\n",
    "\n",
    "2. Имеет смысл поглядеть в [стандартный collate_fn](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/_utils/collate.py#L42): он умеет клеить в батчи и конвертировать в тензора самые разнообразные данные. Это может работать во многих случаях, но неожиданно падать в других. В частности, не сможет поклеить примеры разной длины.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classy Trainer\n",
    "\n",
    "Пишем класс для тренировки и логгирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_dataset, val_dataset, batch_size=128):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = self.model.to(self.device)\n",
    "        \n",
    "        self.global_step = 0\n",
    "        self.writer = SummaryWriter(\"./tmp/\")\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        model = self.model\n",
    "        optimizer = self.optimizer\n",
    "        \n",
    "        train_loader = DataLoader(self.train_dataset, shuffle=True, pin_memory=True, batch_size=self.batch_size)\n",
    "        val_loader = DataLoader(self.val_dataset, shuffle=False, pin_memory=True, batch_size=self.batch_size)\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for batch in tqdm(train_loader):\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                loss, details = model.compute_all(batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                for k, v in details.items():\n",
    "                    self.writer.add_scalar(k, v, global_step=self.global_step)\n",
    "                self.global_step += 1\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            val_losses = []\n",
    "            for batch in tqdm(val_loader):\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                loss, details = model.compute_all(batch)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "            val_loss = np.mean(val_losses)        \n",
    "            if val_loss < best_loss:\n",
    "                self.save_checkpoint(\"./best_checkpoint.pth\")\n",
    "                best_loss = val_loss\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorSet()\n",
    "print(vs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inner = nn.Sequential(nn.Linear(784, 100), nn.ReLU(), nn.Linear(100, 10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.inner(x)\n",
    "    \n",
    "    def compute_all(self, batch):  # удобно сделать функцию, в которой вычисляется лосс по пришедшему батчу\n",
    "        x = batch['sample']\n",
    "        y = batch['label']\n",
    "        logits = self.inner(x)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(axis=1) == y).float().mean().cpu().numpy()\n",
    "        metrics = dict(acc=acc)\n",
    "        return loss, metrics\n",
    "\n",
    "# проверяйте работоспособность сразу\n",
    "model = VeryModel()\n",
    "opt = optim.SGD(model.parameters(), lr=1e-2)\n",
    "trainset = VectorSet(train=True)\n",
    "valset = VectorSet(train=False)\n",
    "\n",
    "trainer = Trainer(model, opt, trainset, valset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрите логи локально или через tensorboard-ext в зависимости от того, как вы запустили тетрадку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}