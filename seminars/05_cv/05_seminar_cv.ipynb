{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –°–µ–º–∏–Ω–∞—Ä 5: Computer Vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q efficientnet_pytorch ultralytics pytorch-lightning kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß—Ç–æ —Ç–∞–∫–æ–µ `transfer learning`, `fine-tuning`?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–°–ø–æ—Å–æ–± –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –¥—Ä—É–≥–æ–π –∑–∞–¥–∞—á–µ.</br>\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ü–æ—á–µ–º—É –¥–µ–ª–∞—é—Ç `transfer learning`, `fine-tuning`? –ü–æ—á–µ–º—É —Å –Ω—É–ª—è –Ω–µ —É—á–∞—Ç?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–°–µ—Ç–∏ –±—ã—Å—Ç—Ä–µ–µ –¥–æ–æ–±—É—á–∏—Ç—å, —á–µ–º –æ–±—É—á–∏—Ç—å —Å –Ω—É–ª—è. –ò–Ω–æ–≥–¥–∞ —Å –Ω—É–ª—è —Å–ª–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –º–∞–ª–µ–Ω—å–∫–∏–π. –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –±–æ–ª—å—à–æ–π, —Ç–æ –≤—Å–µ —Ä–∞–≤–Ω–æ —Ö–æ—Ä–æ—à–æ --- –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –±—É–¥–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –º–µ–Ω—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è.</br>\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–í –æ–±—â–µ–º-—Ç–æ, `fine-tuning` --- —ç—Ç–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ `transfer learning`.</br>\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ö–∞–∫ –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤–µ—Å–∞ —Å–µ—Ç–∏? –ö–∞–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–º–æ—Ä–æ–∑–∫–∏ –º–æ–∂–µ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "```python\n",
        "# –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤–µ—Å–∞ –¥–ª—è backbone'–∞ —Å–µ—Ç–∏\n",
        "for p in resnet.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –Ω–∞—à –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
        "for p in resnet.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "```\n",
        "\n",
        "https://cs231n.github.io/transfer-learning/</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –í –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—Ç—å —Å–ª–æ–π `BatchNorm` –≤–Ω—É—Ç—Ä–∏ Residual –±–ª–æ–∫–æ–≤?\n",
        "\n",
        "```python\n",
        "nn.Conv2d(...) -> nn.BatchNorm2d() -> nn.ReLU()\n",
        "```\n",
        "\n",
        "```python\n",
        "nn.BatchNorm2d() -> nn.ReLU() -> nn.Conv2d(...)\n",
        "```\n",
        "\n",
        "```python\n",
        "nn.Conv2d(...) -> nn.ReLU() -> nn.BatchNorm2d()\n",
        "```\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "1. ‚úÖ –ü–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî —ç—Ç–æ –±–∞–∑–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é</br>\n",
        "2. üëå –í—Ç–æ—Ä–æ–π –¥–æ–ø—É—Å—Ç–∏–º –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–ª–æ–µ–≤</br>\n",
        "3. ‚ùå BatchNorm –ø—ã—Ç–∞–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —É–∂–µ –∏—Å–∫–∞–∂–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —Ç–µ—Ä—è–µ—Ç—Å—è –º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ BN –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º–∏</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ö–∞–∫–æ–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ —É –æ–¥–Ω–æ–π —è—á–µ–π–∫–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π —Å–µ—Ç–∏, —Å–æ—Å—Ç–æ—è—â–µ–π –∏–∑ –¥–≤—É—Ö –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —Å–≤–µ—Ä—Ç–æ–∫ 3√ó3 (`stride=1`)?\n",
        "\n",
        "–î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏: –∫–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ¬´–≤–ª–æ–∂–∏–ª–∏¬ª —Å–≤–æ–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ–¥–∏–Ω –ø–∏–∫—Å–µ–ª—å –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–û—Ç–≤–µ—Ç: 5√ó5=25. –†–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ –æ–¥–Ω–æ–≥–æ –ø–∏–∫—Å–µ–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ 3√ó3. –ö–≤–∞–¥—Ä–∞—Ç–∏–∫ 3√ó3 —ç—Ç–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–æ–º—É ¬´–ø–∏–∫—Å–µ–ª—é¬ª –≤—Ç–æ—Ä–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ –∏ –∫–≤–∞–¥—Ä–∞—Ç–∏–∫—É 5√ó5 –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ó–∞—á–µ–º –º—ã —Ö–æ—Ç–∏–º —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ –Ω–∞ –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏—Ö —Å–ª–æ—è—Ö?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–í –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º –∏–¥—ë—Ç Linear –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ñ–∏—á–∞-–º–∞–ø–µ. Linear –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø–∏–∫—Å–µ–ª–µ–π –∏ –∏—Ö ¬´—Å–æ—Å–µ–¥—Å—Ç–≤–æ¬ª. –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ –º–æ–≥—É—Ç –Ω–µ—Å—Ç–∏ —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é; —á–µ–º –±–æ–ª—å—à–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ, —Ç–µ–º –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Ñ–∏–ª—å—Ç—Ä–µ.</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–¥–∞—á–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/cv_tasks.png\" width=600 />\n",
        "\n",
        "[**–ò—Å—Ç–æ—á–Ω–∏–∫**](https://cs231n.stanford.edu/slides/2024/lecture_9.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ResNet\n",
        "\n",
        "**–ö–ª—é—á–µ–≤–∞—è —Ñ–∏—à–∫–∞:** skip-connection (residual block)\n",
        "\n",
        "**–¶–µ–ª—å:** –û–±—É—á–∏—Ç—å –≥–ª—É–±–æ–∫—É—é —Å–µ—Ç—å. –†–µ–∑–∏–¥—É–∞–ª—ã –ø–æ–º–æ–≥–∞—é—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º –ø—Ä–æ—Ç–µ–∫–∞—Ç—å –Ω–∞ –≥–ª—É–±–æ–∫–∏–µ —Å–ª–æ–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/resnet.png\" width=600 />\n",
        "\n",
        "**–õ–µ–≥–µ–Ω–¥–∞**:\n",
        "–ó–∞–∫—Ä–∞—à–µ–Ω–Ω—ã–µ –∫–≤–∞–¥—Ä–∞—Ç—ã ‚Äî —ç—Ç–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –í—ã—Å–æ—Ç–∞ –∫–≤–∞–¥—Ä–∞—Ç–∞ ‚Äî –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –®–∏—Ä–∏–Ω–∞ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "# 2015\n",
        "resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet.fc = nn.Linear(512, 10) # Randomly initialized! Must be trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExampleResidualModel(nn.Module):\n",
        "    \"\"\"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä residual –±–ª–æ–∫–∞: –≤—ã—Ö–æ–¥ = activation(conv(x)) + x.\"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        conved = self.model(x)\n",
        "        return self.activation(conved) + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —è–∫–æ—Ä—å:** –Ω–∏–∂–µ –∏–¥—ë—Ç –±–ª–æ–∫ –ø—Ä–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä (EfficientNet, Depthwise, ConvNext). –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ ¬´–ø–æ—â—É–ø–∞—Ç—å¬ª –º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ ‚Äî –ø–µ—Ä–µ–π–¥–∏—Ç–µ –∫ —Ä–∞–∑–¥–µ–ª—É **¬´–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤¬ª** –∏ –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞–ø—É—Å—Ç–∏—Ç–µ YOLO –Ω–∞ —Å–≤–æ—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏; –∑–∞—Ç–µ–º –≤–µ—Ä–Ω–∏—Ç–µ—Å—å —Å—é–¥–∞ ‚Äî —Ç–µ–æ—Ä–∏—è –±—É–¥–µ—Ç –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å—Å—è –∫–∞–∫ ¬´–∫–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω—ã —Ç–∞–∫–∏–µ –º–æ–¥–µ–ª–∏¬ª."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EfficientNet\n",
        "\n",
        "**–¶–µ–ª—å:** –º–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å —Ö–æ—Ä–æ—à–∏–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º.\n",
        "\n",
        "**NAS** (Neural Architecture Search) ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ—Ç–∏. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Ç—å –≤—Ä—É—á–Ω—É—é, –∞–ª–≥–æ—Ä–∏—Ç–º –ø–µ—Ä–µ–±–∏—Ä–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã –±–ª–æ–∫–æ–≤, —Å–≤—è–∑–µ–π –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—è –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏. –≠—Ç–æ –¥–æ—Ä–æ–≥–æ –ø–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ø–æ–¥–æ–±—Ä–∞–Ω–Ω–∞—è –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É.\n",
        "\n",
        "**Compound Scaling** ‚Äî —Å–æ–≤–º–µ—Å—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã, —à–∏—Ä–∏–Ω—ã (–∫–∞–Ω–∞–ª–æ–≤) –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤—Ö–æ–¥–∞; –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ FLOPS –∏ –∫–∞—á–µ—Å—Ç–≤—É. –í –±–ª–æ–∫–∞—Ö: –∞–∫—Ç–∏–≤–∞—Ü–∏—è **Swish** $f(x)=x\\sigma(x)$ –∏ **depthwise-—Å–≤–µ—Ä—Ç–∫–∏** (–Ω–∏–∂–µ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/efficient_net_metrics.png\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*(–ì—Ä–∞—Ñ–∏–∫ Swish –∏ –¥–µ—Ç–∞–ª–∏ ‚Äî —Å–º. [Wikipedia](https://en.wikipedia.org/wiki/Swish_function).)*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### [Depthwise Convolution](https://paperswithcode.com/method/depthwise-convolution)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Depthwise convolution:** –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É –≤—Ö–æ–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Å–≤–æ–π —Ñ–∏–ª—å—Ç—Ä, –∫–∞–Ω–∞–ª—ã –Ω–µ —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è. –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–µ–Ω—å—à–µ, —á–µ–º —É –æ–±—ã—á–Ω–æ–π —Å–≤–µ—Ä—Ç–∫–∏ (—Å–º. —è—á–µ–π–∫–∏ —Å `groups=` –Ω–∏–∂–µ).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/depthwise_conv_doc.png\" width=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# depthwise: groups = in_channels = out_channels ‚Üí –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –Ω–∞ –∫–∞–Ω–∞–ª\n",
        "nn.Conv2d(10, 10, kernel_size=3, groups=10)  # 10 √ó (1√ó1√ó3√ó3 + 1) = 100 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "sum(p.numel() for p in nn.Conv2d(10, 10, kernel_size=3, groups=10).parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: –æ–±—ã—á–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞ 10‚Üí10, 3√ó3 ‚Äî 910 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "sum(p.numel() for p in nn.Conv2d(10, 10, kernel_size=3, groups=1).parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "efficientnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvNeXt\n",
        "\n",
        "**–¶–µ–ª—å:** –º–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å —Ö–æ—Ä–æ—à–∏–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º. **–ò–¥–µ—è:** –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ (ViT) –≤ —á–∏—Å—Ç–æ —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é —Å–µ—Ç—å ‚Äî –±–µ–∑ –±–ª–æ–∫–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è.\n",
        "\n",
        "–ù–∏–∂–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Ñ–∏—à–∫–∏; –∫–æ–¥ –±–ª–æ–∫–∞ –∏ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ ‚Äî –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —è—á–µ–π–∫–∞—Ö.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### –§–∏—à–∫–∏ ConvNeXt\n",
        "\n",
        "- **Stem (patchify):** –ø–µ—Ä–≤—ã–π —Å–ª–æ–π ‚Äî —Å–≤–µ—Ä—Ç–∫–∞ 4√ó4 —Å–æ stride 4 (–∫–∞–∫ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—á–∏ –≤ ViT), —Å—Ä–∞–∑—É —É–º–µ–Ω—å—à–∞–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ.\n",
        "\n",
        "- **LayerNorm –≤–º–µ—Å—Ç–æ BatchNorm:** –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞–Ω–∞–ª–∞–º –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞; –∫–∞–∫ –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö, —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –ø—Ä–∏ –º–∞–ª–æ–º batch.\n",
        "\n",
        "- **–ë–æ–ª—å—à–æ–µ —è–¥—Ä–æ 7√ó7:** –≤ –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ ‚Äî depthwise-—Å–≤–µ—Ä—Ç–∫–∞ 7√ó7 (–∞ –Ω–µ 3√ó3), –±–æ–ª—å—à–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ, –ø–æ –¥—É—Ö—É –±–ª–∏–∂–µ –∫ ¬´–æ–∫–Ω—É¬ª –≤ ViT.\n",
        "\n",
        "- **Inverted bottleneck (MLP-–ø–æ–¥–æ–±–Ω—ã–π –±–ª–æ–∫):** –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–∫–∏ –∏–¥—É—Ç –¥–≤–∞ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è: —Å–Ω–∞—á–∞–ª–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤ 4√ó –∫–∞–Ω–∞–ª–æ–≤, –∑–∞—Ç–µ–º —Å–∂–∞—Ç–∏–µ –æ–±—Ä–∞—Ç–Ω–æ (–∫–∞–∫ FFN –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ). –í –∫–æ–¥–µ ‚Äî `Linear(dim ‚Üí 4*dim)` ‚Üí GELU ‚Üí `Linear(4*dim ‚Üí dim)`.\n",
        "\n",
        "- **GELU:** –∞–∫—Ç–∏–≤–∞—Ü–∏—è $x\\Phi(x)$ –≤–º–µ—Å—Ç–æ ReLU; –∫–∞–∫ –≤ BERT/ViT.\n",
        "\n",
        "- **Layer scale:** –æ–±—É—á–∞–µ–º—ã–π —Å–∫–∞–ª—è—Ä (–∏–ª–∏ –≤–µ–∫—Ç–æ—Ä –ø–æ –∫–∞–Ω–∞–ª–∞–º), –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π —É–º–Ω–æ–∂–∞—é—Ç –≤—ã—Ö–æ–¥ –±–ª–æ–∫–∞ –ø–µ—Ä–µ–¥ residual: —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π.\n",
        "\n",
        "- **Stochastic Depth (—Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∞—è –≥–ª—É–±–∏–Ω–∞):** —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $p$ –≤—ã—Ö–æ–¥ –±–ª–æ–∫–∞ –æ–±–Ω—É–ª—è–µ—Ç—Å—è (–≤–µ—Ç–∫–∞ ¬´–ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è¬ª), residual –æ—Å—Ç–∞—ë—Ç—Å—è. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $p$ —Ä–∞—Å—Ç—ë—Ç —Å –≥–ª—É–±–∏–Ω–æ–π —Å–ª–æ—è. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = torchvision.models.convnext_base(weights='ConvNeXt_Base_Weights.DEFAULT')\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stochastic Depth\n",
        "\n",
        "**Stochastic Depth** ‚Äî –ø—Ä–∏—ë–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö residual-—Å–µ—Ç–µ–π: –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $p$ –≤—ã—Ö–æ–¥ –±–ª–æ–∫–∞ –æ–±–Ω—É–ª—è–µ—Ç—Å—è –∏ –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ residual-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $p$ –æ–±—ã—á–Ω–æ —Ä–∞—Å—Ç—ë—Ç —Å –≥–ª—É–±–∏–Ω–æ–π —Å–ª–æ—è (–±–ª–∏–∂–µ –∫ –≤—ã—Ö–æ–¥—É ‚Äî —á–∞—â–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º). –≠—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∏ –¥–µ–π—Å—Ç–≤—É–µ—Ç –∫–∞–∫ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (–ø–æ—Ö–æ–∂–µ –Ω–∞ dropout, –Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ü–µ–ª—ã—Ö –±–ª–æ–∫–æ–≤).\n",
        "\n",
        "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ torchvision: [`torchvision.ops.StochasticDepth`](https://pytorch.org/vision/main/_modules/torchvision/ops/stochastic_depth.html#StochasticDepth)\n",
        "\n",
        "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è: [Deep Networks with Stochastic Depth (2016)](https://arxiv.org/abs/1603.09382)\n",
        "\n",
        "<image src=\"./static/stochastic_depth.png\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è\n",
        "\n",
        "<img src=\"static/sem_seg.png\" width=400 />\n",
        "\n",
        "[–ò—Å—Ç–æ—á–Ω–∏–∫](https://thegradient.pub/semantic-segmentation/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = torch.randn(1, 3, 32, 32)  # [ bs, channels, w, h ]\n",
        "target = torch.randint(0, 5, (1, 32, 32))  # [ bs, w, h ] class indices\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 256, kernel_size=3, padding=1),\n",
        "    nn.Conv2d(256, 5, kernel_size=3, padding=1),\n",
        ")\n",
        "\n",
        "predictions = model(image)  # [ bs, n_classes, H, W ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/unet.png\" width=600 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß—Ç–æ –æ–±–æ–∑–Ω–∞—á–µ–Ω–æ —Å–∏–Ω–∏–º–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞–º–∏ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ?\n",
        "\n",
        "<!-- –ê–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ—è—Ö UNet -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º Unet –∏ ResNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/milesial/Pytorch-UNet/\n",
        "\n",
        "\"\"\"Parts of the U-Net model.\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"–î–≤–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–∞ (Conv2d ‚Üí BN ‚Üí ReLU).\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, mid_channels: int | None = None) -> None:\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"–ü–æ–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è: MaxPool ‚Üí DoubleConv.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è: Upsample ‚Üí –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è —Å–æ skip-connection ‚Üí DoubleConv.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "\n",
        "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    \"\"\"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞ 1√ó1 –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω—É–∂–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Å–æ–≤.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"U-Net: encoder (down) ‚Üí bottleneck ‚Üí decoder (up) —Å–æ skip-connections.\"\"\"\n",
        "\n",
        "    def __init__(self, n_channels: int, n_classes: int) -> None:\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "\n",
        "        self.up1 = Up(1024, 512)\n",
        "        self.up2 = Up(512, 256)\n",
        "        self.up3 = Up(256, 128)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ UNet –∏ ResNet: forward pass + —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "unet = UNet(n_channels=3, n_classes=5)\n",
        "resnet_cmp = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "resnet_cmp.fc = nn.Linear(512, 5)\n",
        "\n",
        "dummy = torch.randn(1, 3, 128, 128)\n",
        "\n",
        "# UNet: –≤—Ö–æ–¥ –∏ –≤—ã—Ö–æ–¥ ‚Äî –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ\n",
        "unet_out = unet(dummy)\n",
        "print(f\"UNet:   –≤—Ö–æ–¥ {tuple(dummy.shape)} ‚Üí –≤—ã—Ö–æ–¥ {tuple(unet_out.shape)}\")\n",
        "\n",
        "# ResNet: –≤—ã—Ö–æ–¥ ‚Äî –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "resnet_out = resnet_cmp(dummy)\n",
        "print(f\"ResNet: –≤—Ö–æ–¥ {tuple(dummy.shape)} ‚Üí –≤—ã—Ö–æ–¥ {tuple(resnet_out.shape)}\")\n",
        "\n",
        "def count_params(model: nn.Module) -> int:\n",
        "    \"\"\"–ü–æ–¥—Å—á—ë—Ç –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nUNet   –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {count_params(unet):,}\")\n",
        "print(f\"ResNet –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {count_params(resnet_cmp):,}\")\n",
        "print(f\"\\nResNet ‚Äî –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä [bs, n_classes] –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É\")\n",
        "print(f\"UNet   ‚Äî —Å–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä: –∫–∞—Ä—Ç–∞ [bs, n_classes, H, W] ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –° –∫–∞–∫–∏–º –ª–æ—Å—Å–æ–º –¥–æ–ª–∂–µ–Ω –æ–±—É—á–∞—Ç—å—Å—è Unet?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ú–æ–∂–Ω–æ –ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å unet –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### YOLOv5\n",
        "\n",
        "PS –°–∞–º–∞—è —Å–≤–µ–∂–∞—è –≤–µ—Ä—Å–∏—è YOLO ‚Äî 11. –ù–æ –º—ã –Ω–µ —Å–º–æ–∂–µ–º –µ—ë –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å, —Ç.–∫. —Ç–∞–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–ª–æ–∫ –≤–Ω–∏–º–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –º—ã –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏–ª–∏.\n",
        "\n",
        "- **Backbone** ‚Äî CSPDarknet (**C**ross **S**tage **P**artial Network) ‚Äî –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. ¬´Cross Stage Partial¬ª –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ —á–∞—Å—Ç—å –∫–∞–Ω–∞–ª–æ–≤ –æ–±—Ö–æ–¥–∏—Ç —Ç—è–∂—ë–ª—ã–µ —Å–≤–µ—Ä—Ç–∫–∏ –∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ—Ç—Å—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º, —á—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ —É–ª—É—á—à–∞–µ—Ç –ø–æ—Ç–æ–∫ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤.\n",
        "- **Neck** ‚Äî PANet (Path Aggregation Network) ‚Äî –º–æ–¥—É–ª—å, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–æ–≤ (–º–µ–ª–∫–∏–µ –∏ –∫—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã). –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ FPN (Feature Pyramid Network), –Ω–æ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º bottom-up –ø—É—Ç—ë–º –¥–ª—è –ª—É—á—à–µ–π –ø–µ—Ä–µ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–µ–∂–¥—É —É—Ä–æ–≤–Ω—è–º–∏.\n",
        "- **Head** ‚Äî BBox Prediction, Classes Prediction\n",
        "- **Postprocessing** ‚Äî Non-Maximum Suppression (NMS)\n",
        "\n",
        "#### Non-Maximum Suppression (NMS)\n",
        "\n",
        "–î–µ—Ç–µ–∫—Ç–æ—Ä –≤—ã–¥–∞—ë—Ç —Ç—ã—Å—è—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π bounding box'–æ–≤, –º–Ω–æ–≥–∏–µ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –æ–±—ä–µ–∫—Ç–∞. NMS —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã:\n",
        "\n",
        "1. –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ bbox'—ã –ø–æ confidence (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)\n",
        "2. –ë–µ—Ä—ë–º bbox —Å –Ω–∞–∏–≤—ã—Å—à–µ–π confidence ‚Äî –æ–Ω –æ—Å—Ç–∞—ë—Ç—Å—è\n",
        "3. –£–¥–∞–ª—è–µ–º –≤—Å–µ bbox'—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–æ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è —Å –Ω–∏–º (IoU > –ø–æ—Ä–æ–≥, –æ–±—ã—á–Ω–æ 0.5)\n",
        "4. –ü–æ–≤—Ç–æ—Ä—è–µ–º –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è bbox'–æ–≤\n",
        "\n",
        "---\n",
        "\n",
        "[–°—Ç–∞—Ç—å—è Datasecrets - –ò—Å—Ç–æ—Ä–∏—è YOLO ‚Äì —Å–∞–º–æ–π –∏–∑–≤–µ—Å—Ç–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è](https://datasecrets.ru/articles/20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/yolov5.png\" width=400 />\n",
        "\n",
        "[–ò—Å—Ç–æ—á–Ω–∏–∫](https://www.researchgate.net/figure/The-network-architecture-of-YOLOv5-1-Backbone-CSPDarknet-for-feature-extraction-2_fig1_358553872)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://djl.ai/examples/src/test/resources/dog_bike_car.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (YOLOv5s - —Å–∞–º–∞—è –ª—ë–≥–∫–∞—è –≤–µ—Ä—Å–∏—è)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Model config\n",
        "# https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "model.to(device)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "image_path = 'dog_bike_car.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "results = model(image)\n",
        "\n",
        "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "results.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detection_model = model.model.model\n",
        "\n",
        "type(detection_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkout model config\n",
        "# https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detection_model.save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, m in enumerate(detection_model.model):\n",
        "    print(i, \"\\t\", m.f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "image_t = ToTensor()(image)\n",
        "image_t = image_t.unsqueeze(0).to(device)\n",
        "image_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from forward once in Base Model\n",
        "# https://github.com/ultralytics/yolov5/blob/5cdad8922c83b0ed49a0173cd1a8b0739acbb336/models/yolo.py#L161\n",
        "\n",
        "def forward_once(detection_model, x):\n",
        "    y, dt = [], []  # outputs\n",
        "    for m in detection_model.model:\n",
        "        if m.f != -1:  # if not from previous layer\n",
        "            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
        "\n",
        "        x = m(x)  # run\n",
        "        y.append(x if m.i in detection_model.save else None)  # save output\n",
        "\n",
        "    return x\n",
        "\n",
        "forward_result = forward_once(detection_model, image_t)\n",
        "forward_result = forward_result[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "forward_result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# forward_result ~ [ bs, bbox_num, bbox_params + object confidence + class_probability ]\n",
        "\n",
        "# bbox_params + object confidence = 5 params\n",
        "# class_probability = 80 params\n",
        "\n",
        "# bbox_params = [ cx, cy, w, h ]\n",
        "\n",
        "most_confident_bboxes = forward_result[forward_result[..., 4] > 0.75]\n",
        "most_confident_bboxes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "most_confident_bboxes[:, :4].round()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "\n",
        "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è **—Å–ª—É—á–∞–π–Ω–æ** –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –ó–∞—á–µ–º:\n",
        "\n",
        "- **–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –¥–∞–Ω–Ω—ã—Ö** ‚Äî –º–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞—Ü–∏–π –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –æ–±—ä–µ–∫—Ç–∞\n",
        "- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è** ‚Äî —É–º–µ–Ω—å—à–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —Ç.–∫. –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏\n",
        "- **–ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å** ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –±—ã—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ–π –∫ —Å–¥–≤–∏–≥–∞–º, –ø–æ–≤–æ—Ä–æ—Ç–∞–º, –∏–∑–º–µ–Ω–µ–Ω–∏—è–º —è—Ä–∫–æ—Å—Ç–∏\n",
        "\n",
        "–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π:\n",
        "\n",
        "| –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è | –ß—Ç–æ –¥–µ–ª–∞–µ—Ç | –ö–æ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–∞ |\n",
        "|---|---|---|\n",
        "| `RandomHorizontalFlip` | –ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ | –ü–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ (–∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞, —Ü–∏—Ñ—Ä) |\n",
        "| `RandomResizedCrop` | –°–ª—É—á–∞–π–Ω—ã–π –∫—Ä–æ–ø + –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ | –ú–∞—Å—à—Ç–∞–±–Ω–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å |\n",
        "| `ColorJitter` | –°–ª—É—á–∞–π–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —è—Ä–∫–æ—Å—Ç–∏, –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ | –ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –æ—Å–≤–µ—â–µ–Ω–∏—é |\n",
        "| `RandomRotation` | –°–ª—É—á–∞–π–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç | –†–æ—Ç–∞—Ü–∏–æ–Ω–Ω–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å |\n",
        "| `RandomAffine` | –ê—Ñ—Ñ–∏–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (—Å–¥–≤–∏–≥, –º–∞—Å—à—Ç–∞–±, –ø–æ–≤–æ—Ä–æ—Ç) | –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å |\n",
        "| `GaussianBlur` | –†–∞–∑–º—ã—Ç–∏–µ –ø–æ –ì–∞—É—Å—Å—É | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –∫–∞—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è |\n",
        "| `Normalize` | –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–µ–¥–Ω–∏–º –∏ std (–æ–±—ã—á–Ω–æ ImageNet) | **–í—Å–µ–≥–¥–∞** –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ pretrained –º–æ–¥–µ–ª–µ–π |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import v2\n",
        "from PIL import Image\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∏–º —Ä–µ–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∏–ª–∏ —Å–æ–∑–¥–∞–¥–∏–º —Å–ª—É—á–∞–π–Ω–æ–µ, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç)\n",
        "try:\n",
        "    sample_img = Image.open('dog_bike_car.jpg').resize((224, 224))\n",
        "except FileNotFoundError:\n",
        "    sample_img = Image.fromarray(\n",
        "        torch.randint(0, 256, (224, 224, 3), dtype=torch.uint8).numpy()\n",
        "    )\n",
        "\n",
        "# –ù–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
        "augmentations = {\n",
        "    \"Original\": v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    \"HFlip\": v2.Compose([v2.ToImage(), v2.RandomHorizontalFlip(p=1.0), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    \"ColorJitter\": v2.Compose([v2.ToImage(), v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    \"Rotation\": v2.Compose([v2.ToImage(), v2.RandomRotation(degrees=30), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    \"RandomCrop\": v2.Compose([v2.ToImage(), v2.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0)), v2.ToDtype(torch.float32, scale=True)]),\n",
        "    \"GaussBlur\": v2.Compose([v2.ToImage(), v2.GaussianBlur(kernel_size=11, sigma=5.0), v2.ToDtype(torch.float32, scale=True)]),\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, len(augmentations), figsize=(18, 3))\n",
        "for ax, (name, transform) in zip(axes, augmentations.items()):\n",
        "    img_t = transform(sample_img)\n",
        "    ax.imshow(img_t.permute(1, 2, 0).clamp(0, 1))\n",
        "    ax.set_title(name)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"–ü—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å\n",
        "\n",
        "–ú—ã —Ä–∞–∑–æ–±—Ä–∞–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (ResNet, EfficientNet, ConvNeXt), –∑–∞–¥–∞—á–∏ CV (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, –¥–µ—Ç–µ–∫—Ü–∏—è), –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –º–µ—Ç–æ–¥—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ (CAM). –¢–µ–ø–µ—Ä—å —Å–æ–±–µ—Ä—ë–º –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –¥–∞–Ω–Ω—ã–µ ‚Üí –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Üí –º–æ–¥–µ–ª—å ‚Üí –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é PyTorch Lightning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://www.pytorchlightning.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How to use the Kaggle API from Colab\n",
        "# https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kaggle competitions download -c flower-photos-classification -q\n",
        "# !mv flower_photos.zip flower-photos-classification.zip\n",
        "!unzip -fq flower-photos-classification.zip -d flower-photos-classification\n",
        "!rm -rf flower_photos\n",
        "!tar -zxf flower-photos-classification/flower_photos.tgz --directory flower-photos-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -l flower-photos-classification/\n",
        "!ls -l flower-photos-classification/flower_photos/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "from IPython.display import FileLink\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torchvision\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imread('flower-photos-classification/flower_photos/daisy/105806915_a9c13e2106_n.jpg').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -l flower-photos-classification/flower_photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [128, 128]\n",
        "\n",
        "\n",
        "class FlowerDataModule(pl.LightningDataModule):\n",
        "    \"\"\"DataModule –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Ü–≤–µ—Ç–æ–≤: train/val/test split + –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size: int = 50, valid_ratio: float = 0.05) -> None:\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.valid_ratio = valid_ratio\n",
        "\n",
        "    def setup(self, stage: str | None = None) -> None:\n",
        "        test_transforms = [\n",
        "            torchvision.transforms.Resize([128, 128]),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "        ]\n",
        "\n",
        "        train_transforms = deepcopy(test_transforms)\n",
        "        train_transforms.append(torchvision.transforms.RandomAffine(degrees=10, scale=(0.9, 1.1)))\n",
        "\n",
        "        test_transforms = torchvision.transforms.Compose(test_transforms)\n",
        "        train_transforms = torchvision.transforms.Compose(train_transforms)\n",
        "\n",
        "        all_train_data = torchvision.datasets.ImageFolder(\n",
        "            'flower-photos-classification/flower_photos/',\n",
        "            transform=train_transforms,\n",
        "        )\n",
        "\n",
        "        valid_len = int(self.valid_ratio * len(all_train_data))\n",
        "        train_len = len(all_train_data) - valid_len\n",
        "        train_data, valid_data = torch.utils.data.random_split(all_train_data, (train_len, valid_len))\n",
        "        self.train = train_data\n",
        "        self.valid = valid_data\n",
        "\n",
        "        test_dir = 'flower-photos-classification/test/'\n",
        "        if not os.path.exists(test_dir):\n",
        "            os.mkdir(test_dir)\n",
        "            test_dir_with_label = test_dir + 'fake_label'\n",
        "            os.mkdir(test_dir_with_label)\n",
        "\n",
        "            test_answers = pd.read_csv(\"flower-photos-classification/sample_submission.csv\")\n",
        "            for src in test_answers['Id']:\n",
        "                fname = os.path.basename(src)\n",
        "                copyfile(os.path.join(\"flower-photos-classification/\", src), os.path.join(test_dir_with_label, fname))\n",
        "\n",
        "        self.test = torchvision.datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.train, shuffle=True, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.valid, shuffle=False, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.test, shuffle=False, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cdm = FlowerDataModule(batch_size=10)\n",
        "cdm.setup()\n",
        "print(cdm.train.dataset.class_to_idx)\n",
        "class_index_to_label = [\n",
        "    \"DAISY\",\n",
        "    \"DANDELION\",\n",
        "    \"ROSE\",\n",
        "    \"SUNFLOWER\",\n",
        "    \"TULIP\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FlowerClf(pl.LightningModule):\n",
        "    \"\"\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ü–≤–µ—Ç–æ–≤ –Ω–∞ –±–∞–∑–µ EfficientNet —Å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–π —Ä–∞–∑–º–æ—Ä–æ–∑–∫–æ–π —Å–ª–æ—ë–≤.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        labels_cnt: int = 5,\n",
        "        lr: float = 3e-4,\n",
        "        train_fc_only_steps: int = 100,\n",
        "        train_tail_only_steps: int = 2000,\n",
        "        train_with_half_blocks_steps: int = 3000,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.labels_cnt = labels_cnt\n",
        "        self.lr = lr\n",
        "        self.train_fc_only_steps = train_fc_only_steps\n",
        "        self.train_tail_only_steps = train_tail_only_steps\n",
        "        self.train_with_half_blocks_steps = train_with_half_blocks_steps\n",
        "        self._setup_model()\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.test_predictions: list[torch.Tensor] = []\n",
        "\n",
        "    def _setup_model(self) -> None:\n",
        "        self.model = EfficientNet.from_pretrained('efficientnet-b6')\n",
        "        orig_model_fc = self.model._fc\n",
        "        self.model._fc = nn.Linear(orig_model_fc.in_features, self.labels_cnt)\n",
        "\n",
        "    def freeze(self, module: nn.Module) -> None:\n",
        "        for p in module.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def unfreeze(self, module: nn.Module) -> None:\n",
        "        for p in module.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    def gradual_unfreeze(self) -> None:\n",
        "        \"\"\"–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è —Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞: —Å–Ω–∞—á–∞–ª–∞ —Ç–æ–ª—å–∫–æ fc, –ø–æ—Ç–æ–º —Ö–≤–æ—Å—Ç, –ø–æ—Ç–æ–º –≤—Å—ë.\"\"\"\n",
        "        if self.trainer.global_step < self.train_fc_only_steps:\n",
        "            self.freeze(self.model)\n",
        "            self.unfreeze(self.model._fc)\n",
        "        elif self.trainer.global_step < self.train_tail_only_steps:\n",
        "            self.unfreeze(self.model)\n",
        "            self.freeze(self.model._conv_stem)\n",
        "            self.freeze(self.model._bn0)\n",
        "            self.freeze(self.model._blocks)\n",
        "        elif self.trainer.global_step < self.train_with_half_blocks_steps:\n",
        "            self.unfreeze(self.model)\n",
        "            self.freeze(self.model._conv_stem)\n",
        "            self.freeze(self.model._bn0)\n",
        "            for mod in self.model._blocks[:22]:\n",
        "                self.freeze(mod)\n",
        "        else:\n",
        "            self.unfreeze(self.model)\n",
        "\n",
        "    def compute_loss(self, batch: tuple, track_accuracy: bool = False) -> torch.Tensor:\n",
        "        images, labels = batch\n",
        "        class_probas = self.model(images)\n",
        "        loss = self.criterion(class_probas, labels.view(-1))\n",
        "\n",
        "        if track_accuracy:\n",
        "            _, predicted_labels = class_probas.max(dim=-1)\n",
        "            accuracy = (predicted_labels == labels).sum() / labels.numel()\n",
        "            self.log('accuracy', accuracy.item())\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
        "        self.gradual_unfreeze()\n",
        "        loss = self.compute_loss(batch)\n",
        "        self.log('loss', loss.item())\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
        "        loss = self.compute_loss(batch, track_accuracy=True)\n",
        "        self.log('valid_loss', loss.item())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch: tuple, batch_idx: int) -> None:\n",
        "        images, _ = batch\n",
        "        class_probas = self.model(images)\n",
        "        _, predicted_labels = class_probas.max(dim=-1)\n",
        "        self.test_predictions.append(predicted_labels)\n",
        "\n",
        "    def on_test_epoch_end(self) -> None:\n",
        "        all_preds = torch.cat(self.test_predictions, dim=0)\n",
        "        predicted_labels = all_preds.cpu().detach().numpy()\n",
        "        self.test_predictions.clear()\n",
        "\n",
        "        test_answers = pd.read_csv(\"flower-photos-classification/sample_submission.csv\")\n",
        "        category_prediction = pd.DataFrame({\n",
        "            \"Id\": test_answers['Id'],\n",
        "            \"Category\": [class_index_to_label[x] for x in predicted_labels.tolist()],\n",
        "        })\n",
        "        csv_file = f'flower-photos-classification/mysubmission_v{self.trainer.logger.version}.csv'\n",
        "        category_prediction.to_csv(csv_file, index=False)\n",
        "        self.csv_file_link = FileLink(csv_file)\n",
        "        print(\"csv_file_link:\", self.csv_file_link)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        lr_schedulers = {\n",
        "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=10),\n",
        "            'monitor': 'loss',\n",
        "        }\n",
        "        return [opt], lr_schedulers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p ./lightning_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cdm = FlowerDataModule(batch_size=10)\n",
        "cplm = FlowerClf(lr=0.00001)\n",
        "\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    min_delta=0.01,\n",
        "    patience=2,\n",
        "    verbose=True,\n",
        ")\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, callbacks=[early_stop_callback], max_epochs=3)\n",
        "\n",
        "trainer.fit(cplm, cdm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./lightning_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ù–∞—Å–ª–µ–¥—É–µ–º—Å—è –æ—Ç FlowerClf, –º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ backbone\n",
        "class FlowerClfResNet(FlowerClf):\n",
        "    \"\"\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ü–≤–µ—Ç–æ–≤ –Ω–∞ –±–∞–∑–µ ResNet50 (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å EfficientNet).\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def _setup_model(self) -> None:\n",
        "        self.model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        orig_model_fc = self.model.fc\n",
        "        self.model.fc = nn.Linear(orig_model_fc.in_features, self.labels_cnt)\n",
        "\n",
        "    def gradual_unfreeze(self) -> None:\n",
        "        if self.trainer.global_step < self.train_fc_only_steps:\n",
        "            self.freeze(self.model)\n",
        "            self.unfreeze(self.model.fc)\n",
        "        else:\n",
        "            self.unfreeze(self.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flower_clf_resnet = FlowerClfResNet(lr=0.0001)\n",
        "\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, callbacks=[early_stop_callback], max_epochs=3, logger=tb_logger)\n",
        "trainer.fit(flower_clf_resnet, cdm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_lightning import loggers as pl_loggers\n",
        "\n",
        "tb_logger = pl_loggers.TensorBoardLogger(\"./lightning_logs/\", version=\"resnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ LR\n",
        "\n",
        "–ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ —Å–µ—Ç–∫–∞ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–∞, –Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = pl.Trainer()\n",
        "\n",
        "trainer.tune(flower_clf_resnet, cdm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ gradient_clip_val (–≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å):\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu',\n",
        "    devices=1,\n",
        "    callbacks=[early_stop_callback],\n",
        "    max_epochs=3,\n",
        "    gradient_clip_val=1.0,  # clip –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–î–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ LR —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç.–Ω. Learning Rate Range Test, —á–∞—Å—Ç–æ –ø—Ä–æ—Ü–µ–¥—É—Ä—É –Ω–∞–∑—ã–≤–∞—é—Ç –ø—Ä–æ—Å—Ç–æ find_lr. –ü–æ–¥ –∫–∞–ø–æ—Ç–æ–º –ø—Ä–æ—Ö–æ–¥ –ø–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π —ç–ø–æ—Ö–µ —Å lr, –∏–∑–º–µ–Ω—è–µ–º—ã–º –Ω–∞ –∫–∞–∂–¥–æ–º –±–∞—Ç—á–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ:\n",
        "\n",
        "$$\n",
        "\\mathrm{it} = \\frac{\\mathrm{step}}{\\mathrm{total steps}}\\\\\n",
        "\\mathrm{lr} = \\exp\\left\\{\n",
        "    (1 - t ) \\log a + t \\log b\n",
        "\\right\\}\n",
        "$$\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–º–µ–Ω—è—Ç—å LR –¥–ª—è –≤—Å–µ—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –º–æ–∂–Ω–æ –ø—Ä–æ–π—Ç–∏—Å—å –ø–æ –Ω–∏–º —Ü–∏–∫–ª–æ–º:\n",
        "\n",
        "```python\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr\n",
        "```\n",
        "\n",
        "\n",
        "<img src=\"https://www.jeremyjordan.me/content/images/2018/02/lr_finder.png\" width=400/>\n",
        "\n",
        "_–∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ –±–ª–æ–≥–∞ [Jeremy Jordan](https://www.jeremyjordan.me/nn-learning-rate/)_\n",
        "\n",
        "\n",
        "–ò–¥–µ—è –ø—Ä–∏–µ–º–∞ –ø—Ä–æ—Å—Ç–∞—è: –ø–æ–∫–∞ LR –º–µ–Ω—å—à–µ –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ –≤–µ—Å–∞ –ø—Ä–æ—Å—Ç–æ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è (–≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ –∏–∑-–∑–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π).\n",
        "–ü—Ä–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–º LR –º—ã —à–∞–≥–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ –∏ —É—Ö–æ–¥–∏–º –æ—Ç —Ç–æ—á–∫–∏ —ç–∫—Å—Ç—Ä–µ–º—É–º–∞.\n",
        "\n",
        "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π LR –ª–µ–∂–∏—Ç –≥–¥–µ-—Ç–æ –º–µ–∂–¥—É –Ω–∏–º–∏. –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è LR –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å –¥–æ–ª–∂–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º –Ω–∞–π—Ç–∏ —Ö–æ—Ä–æ—à—É—é —Ç–æ—á–∫—É.\n",
        "\n",
        "\n",
        "\n",
        "[–°—Ç–∞—Ç—å—è, –≤ –∫–æ—Ç–æ—Ä–æ–π —ç—Ç—É —Ç–µ—Ö–Ω–∏–∫—É –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –∏ –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏](https://arxiv.org/pdf/1506.01186.pdf).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hooks: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–∏–º–µ—Ä: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ backward-—Ö—É–∫\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Å–µ—Ç—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
        "\n",
        "demo_net = nn.Sequential(\n",
        "    nn.Linear(10, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 5),\n",
        ")\n",
        "\n",
        "grad_norms: dict[str, list[float]] = {}\n",
        "\n",
        "def log_grad_norm_hook_fn(module: nn.Module, grad_input: tuple, grad_output: tuple) -> None:\n",
        "    \"\"\"–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç L2-–Ω–æ—Ä–º—É –≤—ã—Ö–æ–¥–Ω—ã—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —Å–ª–æ—è.\"\"\"\n",
        "    name = module.__class__.__name__\n",
        "    grad_norm = grad_output[0].norm(2).item()\n",
        "    grad_norms.setdefault(name, []).append(grad_norm)\n",
        "\n",
        "for name, layer in demo_net.named_modules():\n",
        "    if isinstance(layer, (nn.Linear, nn.ReLU)):\n",
        "        layer.register_full_backward_hook(log_grad_norm_hook_fn)\n",
        "\n",
        "# –û–¥–∏–Ω forward + backward –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
        "x = torch.randn(4, 10)\n",
        "loss = demo_net(x).sum()\n",
        "loss.backward()\n",
        "\n",
        "for layer_name, norms in grad_norms.items():\n",
        "    print(f\"{layer_name}: grad_norm = {norms[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùóÔ∏è‚ùóÔ∏è‚ùóÔ∏è **–í–∞–∂–Ω–æ!** –ù–µ —Ä–∞–±–æ—Ç–∞—é—Ç –µ—Å–ª–∏ —è–≤–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å `model.forward`, –∞ –Ω–µ —á–µ—Ä–µ–∑ `__call__` `model()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ó–∞—á–µ–º –Ω—É–∂–Ω—ã —Ö—É–∫–∏? –ú–æ–∂–µ—Ç, –º–æ–∂–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–æ—Å—Ç–æ –∏–∑ `mode(inputs)` –≤—Å–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –ë–ª–∏—Ü"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ü–æ—á–µ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "<img src=\"static/vanishing_gradients.png\" width=400 />\n",
        "\n",
        "–°–ª–∞–π–¥ –∏–∑ –ª–µ–∫—Ü–∏–∏ –¢–∞–Ω–∏ –ì–∞–π–Ω—Ü–µ–≤–æ–π dlschool\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ö–∞–∫–∏–µ –µ—Å—Ç—å –º–µ—Ç–æ–¥—ã –±–æ—Ä—å–±—ã —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "- residual block\n",
        "- —Ç—Ä–µ–π–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö —Å–µ—Ç–∏ (—ç—Ç–æ —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥, –Ω–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ –≤ –Ω–∞—à–µ –≤—Ä–µ–º—è)\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ó–∞—á–µ–º –Ω—É–∂–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `groups=?` –≤ `nn.Conv2d`?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–ü–æ–∑–≤–æ–ª—è–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏, —Å –ø–æ–º–æ—â—å—é –Ω–µ–≥–æ –º–æ–∂–Ω–æ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö —è–¥–µ—Ä. –ù–æ –∑–∞ —Å—á—ë—Ç —É–º–µ–Ω—å—à–µ–Ω–∏—è –Ω–µ –≤—Å–µ out_channels —Ç–µ–ø–µ—Ä—å –∏–º–µ—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –æ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö in_channels.\n",
        "\n",
        "–ï—Å–ª–∏ `groups=1`, —Ç–æ —ç—Ç–æ –æ–±—ã—á–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞, –≥–¥–µ –≤—Å–µ in_channels —Å–≤–æ—Ä–∞—á–∏–≤–∞—é—Ç—Å—è –≤–æ –≤—Å–µ `out_channels`.\n",
        "\n",
        "–ï—Å–ª–∏ `groups=in_channels=out_channels=N`, —Ç–æ —Ç–∞–∫–∞—è —Å–≤–µ—Ä—Ç–∫–∞ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é `N` —Å–≤–µ—Ä—Ç–æ–∫ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç Class Activation Map (CAM)? –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "CAM –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—ã–ª–∏ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞. –≠—Ç–æ —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ –≤–µ—Å–∞–º –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è –∏ feature maps –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è.</br></br>\n",
        "–ó–∞—á–µ–º: –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å ‚Äî —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å ¬´—Å–º–æ—Ç—Ä–∏—Ç¬ª –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ (–æ–±—ä–µ–∫—Ç, –∞ –Ω–µ —Ñ–æ–Ω); –æ—Ç–ª–∞–¥–∫–∞ ‚Äî –Ω–∞—Ö–æ–¥–∏–º –æ—à–∏–±–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –º–æ–¥–µ–ª–∏.</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Non-Maximum Suppression (NMS) –≤ –∑–∞–¥–∞—á–µ –¥–µ—Ç–µ–∫—Ü–∏–∏?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–î–µ—Ç–µ–∫—Ç–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ç—ã—Å—è—á–∏ bounding box'–æ–≤, –º–Ω–æ–≥–∏–µ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. NMS –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π bbox –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞, —É–¥–∞–ª—è—è –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º IoU (Intersection over Union).</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ó–∞—á–µ–º –Ω—É–∂–Ω—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏? –ö–∞–∫–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ–ª—å–∑—è –ø—Ä–∏–º–µ–Ω—è—Ç—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–µ–π—Å—Ç–≤—É—é—Ç –∫–∞–∫ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –±—ã—Ç—å –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ–π –∫ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º (—è—Ä–∫–æ—Å—Ç—å, –º–∞—Å—à—Ç–∞–±, —Å–¥–≤–∏–≥).</br></br>\n",
        "–î–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä **–Ω–µ–ª—å–∑—è** –ø—Ä–∏–º–µ–Ω—è—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ (`HorizontalFlip`) ‚Äî —Ü–∏—Ñ—Ä—ã 6 –∏ 9 —Å—Ç–∞–Ω—É—Ç –Ω–µ—Ä–∞–∑–ª–∏—á–∏–º—ã. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, —Å–∏–ª—å–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã (>15¬∞) –æ–ø–∞—Å–Ω—ã: 6 –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –ø–æ—Ö–æ–∂–µ–π –Ω–∞ 9, –∞ 1 –Ω–∞ 7.</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞—á–∞–ª–∏ –≤–∑—Ä—ã–≤–∞—Ç—å—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã, –ø–æ—è–≤–∏–ª–∏—Å—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ –≤ –≤–µ—Å–∞—Ö –º–æ–¥–µ–ª—å–∫–∏?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–î–µ–±–∞–∂–∏—Ç—å. –ú–æ–∂–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–æ—Ä–º—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è —Å–µ—Ç–∏.\n",
        "\n",
        "–ú–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å forward/backward —Ö—É–∫–∏, –ø—Ä–æ–≤–µ—Ä—è—Ç—å –≤ –Ω–∏—Ö, –Ω–∞ –∫–∞–∫–æ–º –∏–º–µ–Ω–Ω–æ —Å–ª–æ–µ –Ω–∞—á–∞–ª–∏ –ø–æ—è–≤–ª—è—Ç—å—Å—è –ø–ª–æ—Ö–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã.\n",
        "\n",
        "–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è `torch.autograd.detect_anomaly`:\n",
        "```\n",
        "torch.autograd.detect_anomaly()\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß–µ–º –≤—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –≤—ã—Ö–æ–¥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞ –≤—Å—ë –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ?\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary><strong>–û—Ç–≤–µ—Ç</strong></summary>\n",
        "\n",
        "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤—ã–¥–∞—ë—Ç –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä –ª–æ–≥–∏—Ç–æ–≤/–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º –Ω–∞ –≤—Å—ë –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É). –ü—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å –≤—ã–¥–∞—ë—Ç –∫–∞—Ä—Ç—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º –¥–ª—è **–∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è** (–∏–ª–∏ –∫–∞–∂–¥–æ–π –æ–±–ª–∞—Å—Ç–∏): —Ç–æ –µ—Å—Ç—å –≤—ã—Ö–æ–¥ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å [batch, n_classes, H, W] (–∏–ª–∏ [batch, H, W] —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤). –ü–æ —Å—É—Ç–∏, –≤ –∫–∞–∂–¥–æ–π –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π —Ç–æ—á–∫–µ –¥–µ–ª–∞–µ—Ç—Å—è ¬´—Å–≤–æ–π¬ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä.</br>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------\n",
        "\n",
        "## –î–æ–º–∞—à–∫–∏\n",
        "\n",
        "### –í–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–º–∞—à–∫–∞–º?\n",
        "\n",
        "- **–ß—Ç–æ —Å–¥–∞–≤–∞—Ç—å:** –∫–æ–¥ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ GitHub Classroom (—Å–º. —Å—Å—ã–ª–∫—É –≤ README –∫—É—Ä—Å–∞).\n",
        "- **–ù–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:** –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–≤—Ç–æ–≥—Ä–µ–π–¥–µ—Ä –∏ —Ñ–æ—Ä–º–∞—Ç —Å–¥–∞—á–∏ –¥–æ –¥–µ–¥–ª–∞–π–Ω–∞; –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É ‚Äî —à—Ç—Ä–∞—Ñ –¥–æ 30%.\n",
        "- **–¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏:** –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, –∑–∞–±—ã—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –ù–∞ —ç—Ç—É –Ω–µ–¥–µ–ª—é: üéÅ letters (–±–æ–Ω—É—Å–Ω–∞—è)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### hw-letters (–±–æ–Ω—É—Å–Ω–∞—è)\n",
        "\n",
        "–ò–∑ —Ñ–∏–¥–±—ç–∫–∞ –ø–æ –¥–æ–º–∞—à–∫–µ –≤ –ø—Ä–æ—à–ª–æ–º –≥–æ–¥—É, —ç—Ç–∞ –¥–æ–º–∞—à–∫–∞ –±—ã–ª–∞ –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–∞—è –∏ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–Ω—è–ª–∞ (35‚Äì72 —á–∞—Å–∞), –Ω–æ —Ç–µ–º –ª—é–¥—è–º, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–≤–∏–ª–∏ —Ñ–∏–¥–±—ç–∫, –æ–Ω–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å.\n",
        "\n",
        "–ö —Ä–µ—à–µ–Ω–∏—é –∑–∞–¥–∞—á–∏ –Ω–∞–¥–æ –ø–æ–¥–æ–π—Ç–∏ —Ç–≤–æ—Ä—á–µ—Å–∫–∏.\n",
        "\n",
        "**–ß—Ç–æ —Å–¥–∞–≤–∞—Ç—å:** —Ä–µ—à–µ–Ω–∏–µ –≤ GitHub Classroom (—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–æ–º–∞—à–∫–∏).\n",
        "\n",
        "**–ù–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:** –Ω–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª–æ–≥–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ—Å—Ç–æ–≥–æ baseline (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –±–∞–∑–æ–≤—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏), –∑–∞—Ç–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä—É–π—Ç–µ; –≥—Ä–∞–º–æ—Ç–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–∞–π–ø–ª–∞–π–Ω –¥–∞–Ω–Ω—ã—Ö —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
        "\n",
        "**–¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏:** –Ω–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ (–±—É–∫–≤—ã/—Å–ª–æ–≤–∞), –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è.\n",
        "\n",
        "**–°–ª–æ–∂–Ω–æ—Å—Ç—å –¥–æ–º–∞—à–∫–∏:**\n",
        "- –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π –æ–±—ä—ë–º –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–¥–æ –≥—Ä–∞–º–æ—Ç–Ω–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"static/letters_demo.png\" width=400 />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YxPuSAPpnds5"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "audio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
