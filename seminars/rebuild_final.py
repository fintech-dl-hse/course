#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –Ω–æ—É—Ç–±—É–∫–∞ —Å –ø—Ä–∞–≤–∫–∞–º–∏:
1. –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch –≤ –Ω–∞—á–∞–ª–µ Part I
2. –í—Å–µ –±–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –≤ –∫–æ–Ω—Ü–µ
3. –ë–µ–∑ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
"""

import json
from pathlib import Path

def load_notebook(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_notebook(notebook, path):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=1)

def create_markdown_cell(text):
    lines = text.strip().split('\n')
    source = [line + '\n' for line in lines[:-1]]
    if lines:
        source.append(lines[-1])
    return {
        "cell_type": "markdown",
        "source": source,
        "metadata": {}
    }

def create_code_cell(code):
    lines = code.strip().split('\n')
    source = [line + '\n' for line in lines[:-1]]
    if lines:
        source.append(lines[-1])
    return {
        "cell_type": "code",
        "execution_count": None,
        "source": source,
        "outputs": [],
        "metadata": {}
    }

def rebuild_final():
    """Rebuild notebook with all requirements."""

    print("üìñ Loading source notebooks...")
    nb1 = load_notebook("old_01_seminar_torch_mlp.ipynb")
    nb2 = load_notebook("old_02_seminar_autograd.ipynb")

    print("üî® Building final notebook...")

    nb = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {"provenance": [], "toc_visible": True},
            "kernelspec": {"name": "python3", "display_name": "Python 3"},
            "language_info": {"name": "python"}
        },
        "cells": []
    }

    cells = []

    # ===== –í–í–ï–î–ï–ù–ò–ï =====
    cells.append(create_markdown_cell("""# –°–µ–º–∏–Ω–∞—Ä 1: MLP –Ω–∞ PyTorch –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

## –ü–ª–∞–Ω —Å–µ–º–∏–Ω–∞—Ä–∞

### –ß–∞—Å—Ç—å I: PyTorch MLP
* –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch (–±–∞–∑–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã, broadcasting)
* –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (make_moons)
* –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ MLP –Ω–∞ PyTorch
* –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–±—É—á–µ–Ω–∏–µ
* –†–æ–ª—å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π
* –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SVM
* –ë–∞—Ç—á–∏–Ω–≥ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

### –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation
* –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?
* Forward –∏ backward pass
* Chain rule –∏ backpropagation
* –ü—Ä–∏–º–µ—Ä—ã autograd –≤ PyTorch
* –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ autograd

### –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã
* –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞"""))

    cells.append(create_markdown_cell("---\n\n# –ß–∞—Å—Ç—å I: PyTorch MLP"))

    # ===== –ó–ù–ê–ö–û–ú–°–¢–í–û –° PYTORCH =====
    print("  Adding PyTorch basics...")
    cells.append(create_markdown_cell("""## –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch

PyTorch - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Meta (Facebook).

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
* –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π API (–ø–æ—Ö–æ–∂ –Ω–∞ NumPy)
* –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π computational graph
* –£–¥–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è GPU
* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ê–Ω–∞–ª–æ–≥–∏—è —Å NumPy

PyTorch tensors —Ä–∞–±–æ—Ç–∞—é—Ç –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ NumPy arrays:"""))

    cells.append(create_code_cell("""import torch
import numpy as np

# NumPy
np_array = np.array([1, 2, 3, 4, 5])
print("NumPy array:", np_array)
print("Shape:", np_array.shape)
print("Mean:", np_array.mean())

print()

# PyTorch (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ!)
torch_tensor = torch.tensor([1, 2, 3, 4, 5])
print("PyTorch tensor:", torch_tensor)
print("Shape:", torch_tensor.shape)
print("Mean:", torch_tensor.float().mean())  # PyTorch —Ç—Ä–µ–±—É–µ—Ç float –¥–ª—è mean()"""))

    cells.append(create_markdown_cell("""### –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏"""))

    cells.append(create_code_cell("""# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤
a = torch.zeros(3, 4)        # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –Ω—É–ª–µ–π
b = torch.ones(3, 4)         # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –µ–¥–∏–Ω–∏—Ü
c = torch.rand(3, 4)         # –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ [0, 1)
d = torch.randn(3, 4)        # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N(0, 1)

print("Zeros:\\n", a)
print("\\nOnes:\\n", b)
print("\\nRandom uniform:\\n", c)
print("\\nRandom normal:\\n", d)"""))

    cells.append(create_code_cell("""# –ê—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

print("x + y =", x + y)
print("x * y =", x * y)
print("x @ y =", x @ y)  # –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (dot product)"""))

    cells.append(create_markdown_cell("""### Broadcasting –≤ PyTorch

**Broadcasting** - –º–µ—Ö–∞–Ω–∏–∑–º, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤.

PyTorch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ "—Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç" —Ç–µ–Ω–∑–æ—Ä—ã –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞–ª–∏ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.

**–ü—Ä–∞–≤–∏–ª–∞ broadcasting:**
1. –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä—ã –∏–º–µ—é—Ç —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π, —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞ —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–π –¥–æ–ø–æ–ª–Ω—è–µ—Ç—Å—è –µ–¥–∏–Ω–∏—Ü–∞–º–∏ —Å–ª–µ–≤–∞
2. –†–∞–∑–º–µ—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏, –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–≤–Ω—ã –∏–ª–∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö —Ä–∞–≤–µ–Ω 1
3. –¢–µ–Ω–∑–æ—Ä—ã —Ä–∞—Å—à–∏—Ä—è—é—Ç—Å—è –ø–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º —Ä–∞–∑–º–µ—Ä–æ–º 1

–ü–æ–¥—Ä–æ–±–Ω–µ–µ: [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)"""))

    cells.append(create_code_cell("""# –ü—Ä–∏–º–µ—Ä 1: –í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä
x = torch.tensor([1.0, 2.0, 3.0])  # shape: (3,)
scalar = 10.0                       # shape: ()

result = x + scalar
print("–í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä:")
print(f"  {x.tolist()} + {scalar} = {result.tolist()}")
print(f"  Shapes: {x.shape} + () = {result.shape}")

print()

# –ü—Ä–∏–º–µ—Ä 2: –ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä
matrix = torch.tensor([[1.0, 2.0, 3.0],
                        [4.0, 5.0, 6.0]])  # shape: (2, 3)
vector = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,)

result = matrix + vector
print("–ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä:")
print("Matrix:\\n", matrix)
print("Vector:", vector)
print("Result:\\n", result)
print(f"Shapes: {matrix.shape} + {vector.shape} = {result.shape}")"""))

    cells.append(create_code_cell("""# –ü—Ä–∏–º–µ—Ä 3: Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã
a = torch.tensor([[1.0],
                  [2.0],
                  [3.0]])  # shape: (3, 1)

b = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,) ‚Üí –±—É–¥–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ (1, 3)

result = a + b
print("Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
print("a (3, 1):\\n", a)
print("b (3,):", b)
print("Result (3, 3):\\n", result)
print(f"Shapes: {a.shape} + {b.shape} ‚Üí {result.shape}")"""))

    cells.append(create_markdown_cell("""### PyTorch vs NumPy: –∫–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è

| –ê—Å–ø–µ–∫—Ç | NumPy | PyTorch |
|--------|-------|---------|
| –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | `ndarray` | `Tensor` |
| GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.cuda()`, `.to('cuda')`) |
| Autograd | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.backward()`) |
| –°–æ–∑–¥–∞–Ω–∏–µ | `np.array([1,2,3])` | `torch.tensor([1,2,3])` |
| –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ | `np.random.rand(3,4)` | `torch.rand(3,4)` |
| Broadcasting | ‚úÖ –î–∞ | ‚úÖ –î–∞ (—Ç–µ –∂–µ –ø—Ä–∞–≤–∏–ª–∞) |

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PyTorch –≤–º–µ—Å—Ç–æ NumPy:**
* –ù—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (autograd!)
* –ù—É–∂–Ω—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU
* –†–∞–±–æ—Ç–∞–µ—Ç–µ —Å –≥–ª—É–±–æ–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º"""))

    # ===== –û–°–¢–ê–õ–¨–ù–ê–Ø –ß–ê–°–¢–¨ I (–∏–∑ nb1, —è—á–µ–π–∫–∏ 1-22, –±–µ–∑ –±–ª–∏—Ü –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π) =====
    print("  Adding Part I content from nb1...")
    # –ë–µ—Ä–µ–º —è—á–µ–π–∫–∏ 1-22 (–¥–∞–Ω–Ω—ã–µ, MLP, –æ–±—É—á–µ–Ω–∏–µ, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
    cells.extend(nb1['cells'][1:23])

    # ===== –ü–ï–†–ï–•–û–î =====
    print("  Adding transition...")
    cells.append(create_markdown_cell("""---

# –ß–∞—Å—Ç—å II: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?

–ù–∞ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ PyTorch –∫–∞–∫ "—á–µ—Ä–Ω—ã–π —è—â–∏–∫". –ú—ã –≤—ã–∑—ã–≤–∞–ª–∏ `loss.backward()` –∏ –º–∞–≥–∏—á–µ—Å–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.

–ù–æ –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è!"""))

    # ===== –ß–ê–°–¢–¨ II (autograd –∏–∑ nb2) =====
    print("  Adding Part II...")

    cells.append(create_markdown_cell("""## –ó–∞—á–µ–º –º—ã –ø–∏–ª–∏–º –∞–≤—Ç–æ–≥—Ä–∞–¥? ü§ñ

–ß—Ç–æ–±—ã –Ω–µ —Å—á–∏—Ç–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é!

## –ß—Ç–æ –º—ã –∑–∞–ø–æ–º–Ω–∏–ª–∏ –Ω–∞ –ª–µ–∫—Ü–∏–∏? ü§∑

* –Ω–µ–π—Ä–æ—Å–µ—Ç—å -- —ç—Ç–æ —Å–ª–æ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏), –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –∫–∞–∫ –∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø—Ä–æ—Å—Ç—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
* –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞

–ß—Ç–æ–±—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –Ω–∞–º –Ω—É–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º."""))

    cells.append(create_markdown_cell("""## –ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∞–≤—Ç–æ–≥—Ä–∞–¥–æ–º? ü™Ñ

–û—Ç –∞–≤—Ç–æ–≥—Ä–∞–¥–∞ –Ω–∞–º –Ω—É–∂–Ω–æ 2 –≤–µ—â–∏: **forward** –∏ **backward pass**.

### **forward pass**
–ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –∏–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ —Å–µ—Ç–∏: –ø–æ–¥–∞–µ–º –≤—Ö–æ–¥, –ø—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏, –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.

### **backward pass**
–ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã: –Ω–∞—á–∏–Ω–∞–µ–º —Å loss —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∏–¥–µ–º –Ω–∞–∑–∞–¥ –ø–æ —Å–µ—Ç–∏, –≤—ã—á–∏—Å–ª—è—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å –ø–æ–º–æ—â—å—é chain rule."""))

    cells.append(create_markdown_cell("""# Backpropagation + Chain rule = ‚ù§Ô∏è

**Chain rule (–ø—Ä–∞–≤–∏–ª–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)**:

–ï—Å–ª–∏ $F = f(g(x))$, —Ç–æ $\\frac{dF}{dx} = \\frac{dF}{dg} \\cdot \\frac{dg}{dx}$

–ü—Ä–∏–º–µ—Ä:
\\begin{align*}
F &= (a + b) c  \\\\
q &= a + b  \\\\
F &= q c
\\end{align*}

–¢–æ–≥–¥–∞:
\\begin{align*}
\\frac{\\partial F}{\\partial a} &= \\frac{\\partial F}{\\partial q} \\cdot \\frac{\\partial q}{\\partial a} = c \\cdot 1 = c \\\\
\\frac{\\partial F}{\\partial b} &= \\frac{\\partial F}{\\partial q} \\cdot \\frac{\\partial q}{\\partial b} = c \\cdot 1 = c \\\\
\\frac{\\partial F}{\\partial c} &= q
\\end{align*}

**Backpropagation** - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ chain rule –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏!"""))

    cells.append(create_markdown_cell("# –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç autograd –≤ PyTorch"))

    # –ò—â–µ–º —è—á–µ–π–∫–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ nb2
    for i, cell in enumerate(nb2['cells']):
        if cell['cell_type'] == 'code':
            source_text = ''.join(cell.get('source', []))
            if '%matplotlib inline' in source_text and 'import torch' in source_text:
                cells.append(cell)
                break

    cells.append(create_markdown_cell("""### –ö–∞–∫ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–ª–∏—è–µ—Ç —Å–ª–æ–∂–µ–Ω–∏–µ?

\\begin{align*}
c &= a + b \\\\
\\frac {\\partial c} {\\partial a} &= 1 \\\\
\\frac {\\partial c} {\\partial b} &= 1
\\end{align*}"""))

    # –ù–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä —Å–ª–æ–∂–µ–Ω–∏—è
    for cell in nb2['cells']:
        if cell['cell_type'] == 'code':
            source_text = ''.join(cell.get('source', []))
            if 'a = torch.Tensor([10.])' in source_text and '—Å = a + b' in source_text:
                cells.append(cell)
                break

    cells.append(create_markdown_cell("""### –ö–∞–∫ –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–ª–∏—è–µ—Ç —É–º–Ω–æ–∂–µ–Ω–∏–µ?

\\begin{align*}
c &= a \\cdot b \\\\
\\frac {\\partial c} {\\partial a} &= b \\\\
\\frac {\\partial c} {\\partial b} &= a
\\end{align*}"""))

    # –ù–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä —É–º–Ω–æ–∂–µ–Ω–∏—è
    for cell in nb2['cells']:
        if cell['cell_type'] == 'code':
            source_text = ''.join(cell.get('source', []))
            if 'a = torch.Tensor([10.])' in source_text and '—Å = a * b' in source_text:
                cells.append(cell)
                break

    cells.append(create_markdown_cell("# –ú—ã –≥–æ—Ç–æ–≤—ã —Å–¥–µ–ª–∞—Ç—å —Å–≤–æ–π –∞–≤—Ç–æ–≥—Ä–∞–¥!"))

    cells.append(create_markdown_cell("""## ReLU (Rectified Linear Unit)

–í —Å–µ–º–∏–Ω–∞—Ä–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ReLU –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:

$$
\\text{ReLU}(x) = \\max(0, x)
$$

–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è ReLU:

$$
\\frac{d \\text{ReLU}}{dx} = \\begin{cases} 1, & x > 0 \\\\ 0, & x \\leq 0 \\end{cases}
$$"""))

    cells.append(create_markdown_cell("""### Python magic methods

Python –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —á–µ—Ä–µ–∑ magic methods:

```python
Value(1) + Value(2)
# –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤
Value(1).__add__(Value(2))
```

–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ, —á—Ç–æ–±—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—Ç—Ä–æ–∏—Ç—å computational graph!"""))

    cells.append(create_markdown_cell("""### Closures (–∑–∞–º—ã–∫–∞–Ω–∏—è)

–ó–∞–º—ã–∫–∞–Ω–∏–µ - —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è "–∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç" –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–π –æ–±–ª–∞—Å—Ç–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏.

```python
def make_adder(x):
    def adder(y):
        return x + y  # x "–∑–∞–ø–æ–º–Ω–∏–ª–∏" –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Ñ—É–Ω–∫—Ü–∏–∏
    return adder

add_5 = make_adder(5)
print(add_5(10))  # 15
```

–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–º—ã–∫–∞–Ω–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π!"""))

    cells.append(create_markdown_cell("## –ö–ª–∞—Å—Å Value - –Ω–∞—à –∞–≤—Ç–æ–≥—Ä–∞–¥"))

    cells.append(create_code_cell("""class Value:
    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è.\"\"\"

    def __init__(self, data, _children=(), _op=''):
        self.data = data
        self.grad = 0.0
        self._backward = lambda: None
        self._prev = set(_children)
        self._op = _op

    def __repr__(self):
        return f"Value(data={self.data}, grad={self.grad})"

    def __add__(self, other):
        other = other if isinstance(other, Value) else Value(other)
        out = Value(self.data + other.data, (self, other), '+')

        def _backward():
            self.grad += out.grad  # d(a+b)/da = 1
            other.grad += out.grad  # d(a+b)/db = 1
        out._backward = _backward

        return out

    def __mul__(self, other):
        other = other if isinstance(other, Value) else Value(other)
        out = Value(self.data * other.data, (self, other), '*')

        def _backward():
            self.grad += other.data * out.grad  # d(a*b)/da = b
            other.grad += self.data * out.grad  # d(a*b)/db = a
        out._backward = _backward

        return out

    def relu(self):
        out = Value(0 if self.data < 0 else self.data, (self,), 'ReLU')

        def _backward():
            self.grad += (out.data > 0) * out.grad  # –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è ReLU
        out._backward = _backward

        return out

    def backward(self):
        \"\"\"–ó–∞–ø—É—Å–∫–∞–µ—Ç backpropagation –æ—Ç —ç—Ç–æ–≥–æ —É–∑–ª–∞.\"\"\"
        # –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        topo = []
        visited = set()

        def build_topo(v):
            if v not in visited:
                visited.add(v)
                for child in v._prev:
                    build_topo(child)
                topo.append(v)

        build_topo(self)

        # –ò–¥–µ–º –æ—Ç –≤—ã—Ö–æ–¥–∞ –∫ –≤—Ö–æ–¥—É –∏ –≤—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        self.grad = 1.0
        for node in reversed(topo):
            node._backward()"""))

    cells.append(create_markdown_cell("### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–≥–æ autograd"))

    cells.append(create_code_cell("""# –ü—Ä–∏–º–µ—Ä: –≤—ã—á–∏—Å–ª–∏–º f(x, y) = (x + y) * x –∏ –µ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
x = Value(2.0)
y = Value(3.0)

z = x + y  # z = 5
f = z * x  # f = 10

print(f"f = {f.data}")

# –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
f.backward()

print(f"df/dx = {x.grad}")  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: df/dx = z + x = 5 + 2 = 7
print(f"df/dy = {y.grad}")  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: df/dy = x = 2"""))

    # ===== –ë–õ–ò–¶-–í–û–ü–†–û–°–´ (–í–°–ï –í –ö–û–ù–¶–ï!) =====
    print("  Adding all quiz questions at the end...")
    cells.append(create_markdown_cell("""---

# –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã

## –ß–∞—Å—Ç—å I: PyTorch –∏ MLP

1. –í —á–µ–º –≥–ª–∞–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ PyTorch –æ—Ç NumPy?

2. –ß—Ç–æ —Ç–∞–∫–æ–µ broadcasting? –ü—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä.

3. –ö–∞–∫ –ª—É–Ω—ã –º–æ–∂–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è?

4. –ß–µ–º –Ω–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MLP –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç LinearSVC?

5. –ö–∞–∫ `learning_rate` –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è? –ß—Ç–æ –±—É–¥–µ—Ç —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º lr=1e-8? –° –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–º lr=1e3?

6. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—Å–µ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –∏–∑ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏?

7. –ß—Ç–æ —Ç–∞–∫–æ–µ –±–∞—Ç—á? –ü–æ—á–µ–º—É –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –±–∞—Ç—á—É—é—Ç—Å—è?

8. –ß–µ–º —Ç–µ–Ω–∑–æ—Ä –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç torch –ø–∞—Ä–∞–º–µ—Ç—Ä–∞?

## –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation

1. –ó–∞—á–µ–º –Ω—É–∂–Ω—ã —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö?

2. –ó–∞—á–µ–º –Ω—É–∂–µ–Ω autograd? –ü–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é?

3. –ö–æ–≥–¥–∞ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã - –≤–æ –≤—Ä–µ–º—è forward –∏–ª–∏ backward pass?

4. –ö–∞–∫–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–º –Ω—É–∂–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –∑–∞—á–µ–º?

5. –ö–∞–∫ computational graph, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≤–æ –≤—Ä–µ–º—è forward pass, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ backward pass?

6. –ö–∞–∫ —Å–ª–æ–∂–µ–Ω–∏–µ –∏ —É–º–Ω–æ–∂–µ–Ω–∏–µ –≤–ª–∏—è—é—Ç –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã?

7. –ß—Ç–æ —Ç–∞–∫–æ–µ closure (–∑–∞–º—ã–∫–∞–Ω–∏–µ) –≤ Python?

8. –ö–∞–∫–æ–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —à–∞–≥–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏?
   - a) forward ‚Üí backward ‚Üí zero_grad ‚Üí optimizer.step
   - b) zero_grad ‚Üí forward ‚Üí backward ‚Üí optimizer.step
   - c) backward ‚Üí forward ‚Üí zero_grad ‚Üí optimizer.step"""))

    # ===== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ê–¢–ï–†–ò–ê–õ–´ =====
    cells.append(create_markdown_cell("""---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

* [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
* [PyTorch Tutorials](https://pytorch.org/tutorials/)
* [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)
* [Backpropagation Calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8) - –æ—Ç–ª–∏—á–Ω–æ–µ –≤–∏–¥–µ–æ –æ—Ç 3Blue1Brown
* [micrograd](https://github.com/karpathy/micrograd) - –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π autograd engine –æ—Ç Andrej Karpathy"""))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    nb['cells'] = cells

    print(f"\nüíæ Saving final notebook ({len(cells)} cells)...")
    save_notebook(nb, "01_seminar_mlp_autograd.ipynb")

    print("‚úÖ Done!")
    print(f"\nüìä Statistics:")
    print(f"   Total cells: {len(cells)}")
    print(f"   Code cells: {len([c for c in cells if c['cell_type'] == 'code'])}")
    print(f"   Markdown cells: {len([c for c in cells if c['cell_type'] == 'markdown'])}")

if __name__ == "__main__":
    rebuild_final()
