{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/fintech-dl-hse/course/blob/main/seminars/03_optimization_regularization/03_seminar_optimization_regularization.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IZMbtHRJlcr"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/fintech-dl-hse/course/blob/main/seminars/03_optimization_regularization/03_seminar_optimization_regularization.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWqYOc31yJl3"
      },
      "source": [
        "## –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oad21KeJyfd7"
      },
      "source": [
        "> –•–æ—Ç–µ–ª–æ—Å—å –±—ã –±–æ–ª—å—à–µ –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è –≤ –∫–æ–¥, –∫–∞–∫ —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–æ–¥–µ\n",
        "\n",
        "–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ, —Å–ø—Ä–∞—à–∏–≤–∞–π—Ç–µ üôèüèª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5SwQTb5Jlct"
      },
      "source": [
        "---\n",
        "\n",
        "## –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏\n",
        "\n",
        "* –ú–∞–ª–æ\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IwEiOt6qtNv"
      },
      "source": [
        "# Recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzx5uETPcaXR"
      },
      "source": [
        "### üßÆ –ú–æ—Ç–∏–≤–∞—Ü–∏—è\n",
        "\n",
        "–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å -- –±–æ–ª—å—à–∞—è —Ñ–æ—Ä–º—É–ª–∞ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏ (–≤–µ—Å–∞–º–∏).\n",
        "\n",
        "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–∞–º–∏ –≤—ã—É—á–∏–≤–∞—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–∂–Ω—ã –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–∞. –ù–µ –Ω–∞–¥–æ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —Ñ–∏—á–∞-–∏–Ω–∂–µ–Ω–∏—Ä–∏–Ω–≥–æ–º.\n",
        "\n",
        "### üìâ –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
        "\n",
        "–î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤–µ—Å–æ–≤ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏.\n",
        "\n",
        "### üìè –ù–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å\n",
        "\n",
        "–ï—Å–ª–∏ –∏–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —É–±—Ä–∞—Ç—å –≤—Å–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –æ–Ω–∞ –≤—ã—Ä–æ–¥–∏—Ç—Å—è –≤ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é. `ReLU` - –Ω–µ–ø–ª–æ—Ö–æ–π –±–µ–π–∑–ª–∞–π–Ω –¥–ª—è —Ñ-–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏.\n",
        "\n",
        "### üîÆ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "–í–µ—Å–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Ä–∞–Ω–¥–æ–º–Ω–æ, –Ω–æ —Ç–∞–∫, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏—é –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ.\n",
        "\n",
        "\n",
        "-----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOX4gYxbyOiC"
      },
      "source": [
        "# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpq_mcyyE7IL"
      },
      "source": [
        "# –ü–ª–∞–Ω –∑–∞–Ω—è—Ç–∏—è\n",
        "\n",
        "## –¶–µ–ª–∏\n",
        "- –ü–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (SGD / momentum / Adam) –∏ –∫–∞–∫–∏–µ —É –Ω–µ–≥–æ –∑–∞—Ç—Ä–∞—Ç—ã –ø–æ –ø–∞–º—è—Ç–∏.\n",
        "- –ü–æ–Ω–∏–º–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏: dropout, weight decay (Adam vs AdamW), label smoothing.\n",
        "- –£–º–µ—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è **LR scheduler** –∏ **warmup**\n",
        "- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ **TensorBoard**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBilW6e4Jlcu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBFgCdXDJlcu"
      },
      "source": [
        "# –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsMm7TSRtcyC"
      },
      "source": [
        "## –î–µ–ª–∞–µ–º —Ä–µ–≥—Ä–µ—Å—Å–∏—é\n",
        "\n",
        "**Mean Squared Error** ([–¥–æ–∫–∞ PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss))\n",
        "\n",
        "**MSE (Mean Squared Error)** ‚Äî —Ä–µ–≥—Ä–µ—Å—Å–∏—è:\n",
        "$$\\mathcal{L}_{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv9DPjQzuulg",
        "outputId": "993bb41a-0fc1-4644-b7f3-901dd951d768"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 2, requires_grad=True)\n",
        "target = torch.randn(3, 2)\n",
        "\n",
        "output = loss(input, target)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p-23DfYtixI"
      },
      "source": [
        "\n",
        "## –î–µ–ª–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é:\n",
        "\n",
        "**Cross Entropy** ([–¥–æ–∫–∞ PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html))\n",
        "\n",
        "**CE (Cross Entropy)** ‚Äî –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ($C$ –∫–ª–∞—Å—Å–æ–≤, $\\hat{y}_i$ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ $i$ –ø–æ—Å–ª–µ softmax):\n",
        "$$\\mathcal{L}_{CE} = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_8fmFBu0Xf",
        "outputId": "8e5fb3a3-9fbd-4af4-9d35-b7ee618ef770"
      },
      "outputs": [],
      "source": [
        "# Example of target with class indices\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "loss = nn.CrossEntropyLoss() # nn.Softmax + nn.NLLoss\n",
        "input = torch.randn(3, 5, requires_grad=True) # [ batch_size, class_probability ]\n",
        "\n",
        "# [ batch_size ] -- –º–µ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞, –∫–∞–∂–¥–∞—è –º–µ—Ç–∫–∞ -- —ç—Ç–æ —á–∏—Å–ª–æ –æ—Ç [0 –¥–æ 5)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "\n",
        "output = loss(input, target)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQJuYgfXJlcv"
      },
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –∑–∞—á–µ–º –¥–µ–ª–∞—Ç—å Softmax? –í–µ–¥—å –Ω–∞ –≤—ã—Ö–æ–¥–µ –º–æ–¥–µ–ª—å–∫–∏ –º—ã —É–∂–µ –ø–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏—Ç—ã?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLeN-egtuDVP"
      },
      "source": [
        "## –î–µ–ª–∞–µ–º —Ç–µ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:\n",
        "\n",
        "**Binary Cross Entropy** ([–¥–æ–∫–∞ PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html))\n",
        "\n",
        "**BCE (Binary Cross Entropy)** ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è. –ü–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º –±–∞—Ç—á–∞ ($N$ ‚Äî —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, $x_n$ ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, $y_n$ ‚Äî —Ü–µ–ª–µ–≤–æ–π –∫–ª–∞—Å—Å):\n",
        "$$\\ell(x, y) = L = (l_1, \\dots, l_N)^\\top, \\quad l_n = -w_n \\left[ y_n \\log x_n + (1 - y_n) \\log(1 - x_n) \\right]$$\n",
        "(–≤–µ—Å–∞ $w_n$ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–≤–Ω—ã 1). –ï—Å–ª–∏ `reduction` –Ω–µ `'none'`:\n",
        "$$\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{reduction} = \\text{`mean';} \\\\ \\operatorname{sum}(L), & \\text{reduction} = \\text{`sum'.} \\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxw8KvNvz4BJ"
      },
      "source": [
        "–ü—Ä–∏–º–µ—Ä–æ–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–¥–∞—á–∞ —Ç—ç–≥–æ—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–µ–∫–æ–≤: –æ–¥–∏–Ω —Ç—Ä–µ–∫ –º–æ–∂–µ—Ç –∏–º–µ–Ω—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∂–∞–Ω—Ä–æ–≤: `pop`, `rock`, `jazz`, `russian`, `1980s`..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieUEQ7mgtYoj",
        "outputId": "08fb312e-b0b7-423c-9304-26c6a8f1d2f0"
      },
      "outputs": [],
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "\n",
        "output = loss(sigmoid(input), target)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGlGFDdVJlcw"
      },
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å**: –ß–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2f5fnzcMiWe"
      },
      "source": [
        "# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCfuXt8dPgEi"
      },
      "source": [
        "### –ú–æ–¥–µ–ª—å–∫–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFTaORfOPfgI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DorGs1hpMk-k"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, dropout_p=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inner = nn.Sequential(nn.Linear(2, 16), # –∑–∞–≤–µ–¥–æ–º–æ –¥–æ–≤–æ–ª—å–Ω–æ –±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –æ—á–µ–≤–∏–¥–Ω–µ–µ –±—ã–ª —ç—Ñ—Ñ–µ–∫—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –¥—Ä–æ–ø–∞—É—Ç–∞\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(16, 16),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(16, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.inner(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q9PYN2rUkss"
      },
      "outputs": [],
      "source": [
        "# –í —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Å–µ–≥–¥–∞ –±—É–¥—É—Ç —Ä–∞–Ω–¥–æ–º–Ω—ã–º–∏!\n",
        "# –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∫–∏ –¥–æ–ª–∂–Ω—ã –±—Ä–∞—Ç—å—Å—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∞ –Ω–µ –∏–∑ —Ä–∞–Ω–¥–æ–º–∞\n",
        "def example_compute_random_gradients(model):\n",
        "    batch_size = 3\n",
        "    model_input = torch.rand([batch_size, 2])\n",
        "    target_batch_values = torch.randint(0, 1, [batch_size]) * 2 - 1 # -1/1 target values\n",
        "\n",
        "    model_prediction = model.forward(model_input)\n",
        "\n",
        "    loss = F.relu(1 - target_batch_values * model_prediction).mean()\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()  # compute loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIV9WlmwR8Pr"
      },
      "source": [
        "### Hands optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsJ5Gw2uUoK1"
      },
      "outputs": [],
      "source": [
        "model = MLP()\n",
        "example_compute_random_gradients(model)\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "# optimization step\n",
        "for p in model.parameters():\n",
        "    p.data = p.data - learning_rate * p.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OZoTIhATZ6_"
      },
      "source": [
        "### Pytorch Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh02k51tTaOB"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD, Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlEOr_vSTfMB"
      },
      "outputs": [],
      "source": [
        "model = MLP()\n",
        "sgd_optimizer = SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "example_compute_random_gradients(model)\n",
        "\n",
        "sgd_optimizer.step() # –∏—Ç–µ—Ä–∏—É–µ—Ç—Å—è –ø–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º –Ω–∞ —ç—Ç–∞–ø–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tYDmfPVxhF"
      },
      "outputs": [],
      "source": [
        "## –î—Ä—É–≥–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã\n",
        "from torch.optim import Adam\n",
        "\n",
        "adam_optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "example_compute_random_gradients(model)\n",
        "\n",
        "adam_optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLEALdunJlcx"
      },
      "source": [
        "## Adam: —Ñ–æ—Ä–º—É–ª—ã –∏ –∏–Ω—Ç—É–∏—Ü–∏—è\n",
        "\n",
        "–û–±–æ–∑–Ω–∞—á–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞ —à–∞–≥–µ $t$: $g_t = \\nabla_\\theta \\mathcal{L}(\\theta_t)$.\n",
        "\n",
        "**–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ (–º–æ–º–µ–Ω—Ç—ã):**\n",
        "- –ü–µ—Ä–≤—ã–π –º–æ–º–µ–Ω—Ç (—Å—Ä–µ–¥–Ω–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç):\n",
        "\n",
        "$$\n",
        "m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n",
        "$$\n",
        "\n",
        "- –í—Ç–æ—Ä–æ–π –º–æ–º–µ–Ω—Ç (—Å—Ä–µ–¥–Ω–∏–π –∫–≤–∞–¥—Ä–∞—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞):\n",
        "\n",
        "$$\n",
        "v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n",
        "$$\n",
        "\n",
        "**Bias correction** (–≤–∞–∂–Ω–æ –Ω–∞ –ø–µ—Ä–≤—ã—Ö —à–∞–≥–∞—Ö, –ø–æ—Ç–æ–º—É —á—Ç–æ $m_0=v_0=0$):\n",
        "\n",
        "$$\n",
        "\\hat m_t = \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat v_t = \\frac{v_t}{1-\\beta_2^t}\n",
        "$$\n",
        "\n",
        "**–®–∞–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:**\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\alpha \\frac{\\hat m_t}{\\sqrt{\\hat v_t} + \\varepsilon}\n",
        "$$\n",
        "\n",
        "–ò–Ω—Ç—É–∏—Ü–∏—è:\n",
        "- $\\hat m_t$ –ø–æ—Ö–æ–∂ –Ω–∞ momentum (–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à–∞–≥–∞)\n",
        "- $\\sqrt{\\hat v_t}$ –Ω–æ—Ä–º–∏—Ä—É–µ—Ç —à–∞–≥ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (–≥–¥–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã ¬´—à—É–º–Ω–µ–µ/–±–æ–ª—å—à–µ¬ª ‚Äî —Ç–∞–º —à–∞–≥ –º–µ–Ω—å—à–µ)\n",
        "- –ø–æ—ç—Ç–æ–º—É Adam —á–∞—Å—Ç–æ –±—ã—Å—Ç—Ä–µ–µ ¬´—Ä–∞–∑–≥–æ–Ω—è–µ—Ç—Å—è¬ª –∏ —É—Å—Ç–æ–π—á–∏–≤–µ–µ –∫ –ø–ª–æ—Ö–æ–º—É –º–∞—Å—à—Ç–∞–±—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤/—Å–ª–æ–µ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHiOXWzw0Zev"
      },
      "source": [
        "–ú–æ–∂–µ–º –≤—Å–ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ö—Ä–∞–Ω–∏—Ç —Å—Ç–∞—Ç–∏—Å–∏—Ç–∏–∫–∏ –ø–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–æ–º–µ–Ω—Ç—ã)!\n",
        "\n",
        "–î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–º–µ–Ω—Ç–æ–≤ —Ç–æ–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞–º—è—Ç—å –Ω–∞ –≤–∏–¥–µ–æ-–∫–∞—Ä—Ç–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPaJlzpm0sLq",
        "outputId": "9b0cae62-a630-4dcb-8f7a-74ecd53a5256"
      },
      "outputs": [],
      "source": [
        "adam_optimizer.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqm0oCT_1G62"
      },
      "source": [
        "–ö—Å—Ç–∞—Ç–∏! –ê –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "UNgakyHs1Kk9",
        "outputId": "2f62f965-6701-430e-9e73-957069c2d634"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "timeseries_len = 100\n",
        "\n",
        "outlier = torch.zeros(timeseries_len)\n",
        "outlier[55] = 3\n",
        "\n",
        "           # —Ä–∞–Ω–¥–æ–º–Ω—ã–π —à—É–º                   + –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å                       + –≤—ã–±—Ä–æ—Å\n",
        "raw_data = torch.rand([timeseries_len]) + torch.sqrt(torch.arange(timeseries_len)) + outlier\n",
        "raw_data = raw_data / 100\n",
        "\n",
        "beta_values = torch.tensor([ 0.5, 0.9, 0.99 ])\n",
        "\n",
        "mooving_avarages = torch.zeros([beta_values.shape[0], timeseries_len])\n",
        "mooving_avarages[:, 0] = raw_data[0]\n",
        "\n",
        "for i in range(1, timeseries_len):\n",
        "    mooving_avarages[:, i] = mooving_avarages[:, i-1] * beta_values + (1-beta_values) * raw_data[i]\n",
        "\n",
        "plt.plot(raw_data, label='raw')\n",
        "for beta_i, beta in enumerate(beta_values.numpy().tolist()):\n",
        "    plt.plot(mooving_avarages[beta_i, :], label=f\"beta {beta:.2f}\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Mooving average demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux5s223vJlcx"
      },
      "source": [
        "#### ‚ùì **–í–æ–ø—Ä–æ—Å:** –ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJgfRdm_Yjva"
      },
      "source": [
        "## Demo optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjbrZFMIKpYF",
        "outputId": "22f0627a-9b0c-43a7-ed33-91814c4323a1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppxqb_loKp1n",
        "outputId": "64f734f6-98ab-403b-8ad6-e89ca541347d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º MLP –∏–∑ —ç—Ç–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "mlp_adam = MLP()\n",
        "mlp_sgd = MLP()\n",
        "\n",
        "mlp_adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSFQoXP2KrSc",
        "outputId": "8ba7bb81-b567-4954-8464-216e6e244775"
      },
      "outputs": [],
      "source": [
        "# –°–∫–æ–ª—å–∫–æ –ø–∞–º—è—Ç–∏ —Å—ä–µ–¥–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞?\n",
        "# (–Ω–∞ GPU —ç—Ç–æ —Ç–æ–∂–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É Adam ¬´–¥–æ—Ä–æ–∂–µ¬ª –ø–æ –ø–∞–º—è—Ç–∏)\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def optimizer_state_size_bytes(optimizer: torch.optim.Optimizer) -> int:\n",
        "    total = 0\n",
        "    for state in optimizer.state.values():\n",
        "        if not isinstance(state, dict):\n",
        "            continue\n",
        "        for v in state.values():\n",
        "            if torch.is_tensor(v):\n",
        "                total += v.numel() * v.element_size()\n",
        "    return total\n",
        "\n",
        "\n",
        "def model_params_size_bytes(model: torch.nn.Module) -> int:\n",
        "    return sum(p.numel() * p.element_size() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def init_optimizer_state(optimizer: torch.optim.Optimizer, model: torch.nn.Module) -> None:\n",
        "    x = torch.randn(2048, 2)\n",
        "    y = torch.randn(2048, 1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(x)\n",
        "    loss = torch.nn.functional.mse_loss(pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "model_sgd = MLP()\n",
        "sgd = torch.optim.SGD(model_sgd.parameters(), lr=1e-2)\n",
        "init_optimizer_state(sgd, model_sgd)\n",
        "\n",
        "model_sgd_momentum = MLP()\n",
        "sgd_momentum = torch.optim.SGD(model_sgd_momentum.parameters(), lr=1e-2, momentum=0.9)\n",
        "init_optimizer_state(sgd_momentum, model_sgd_momentum)\n",
        "\n",
        "model_adam = MLP()\n",
        "adam = torch.optim.Adam(model_adam.parameters(), lr=1e-3)\n",
        "init_optimizer_state(adam, model_adam)\n",
        "\n",
        "print(\"MLP params:\", round(model_params_size_bytes(model_sgd) / 1024, 2), \"KB\")\n",
        "print(\"SGD state:\", round(optimizer_state_size_bytes(sgd) / 1024, 2), \"KB\")\n",
        "print(\"SGD+momentum state:\", round(optimizer_state_size_bytes(sgd_momentum) / 1024, 2), \"KB\")\n",
        "print(\"Adam state:\", round(optimizer_state_size_bytes(adam) / 1024, 2), \"KB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-x9nvT57a33"
      },
      "source": [
        "# –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "* Dropout\n",
        "* Weight Decay\n",
        "* Label Smoothing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuPfyZjCFnZm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50M59C-372Q-"
      },
      "source": [
        "## Dropout\n",
        "\n",
        "[Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
        "\n",
        "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –≤—Ö–æ–¥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $p$ –æ–±–Ω—É–ª—è–µ—Ç—Å—è, –∑–∞—Ç–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –Ω–∞ $1/(1-p)$ (—á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞—Ç. –æ–∂–∏–¥–∞–Ω–∏–µ):\n",
        "$$y_i = \\frac{x_i \\cdot m_i}{1 - p}, \\quad m_i \\sim \\operatorname{Bernoulli}(1-p)$$\n",
        "–í —Ä–µ–∂–∏–º–µ eval: $y = x$ (dropout –æ—Ç–∫–ª—é—á—ë–Ω)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwcG_Uqo71pJ",
        "outputId": "85cdacd3-9a6f-4153-9211-f1ebf4d07632"
      },
      "outputs": [],
      "source": [
        "dropout = nn.Dropout(p=0.5)\n",
        "dropout.eval()\n",
        "print(dropout.training) # –≤–∞–∂–Ω—ã–π —Ñ–ª–∞–∂–æ–∫ –¥–ª—è –¥—Ä–æ–ø–∞—É—Ç–∞ - —Ç–∫ –¥—Ä–æ–ø–∞—É—Ç –∏–º–µ–µ—Ç —Ä–∞–∑–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è –∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–µ—Ç–∏\n",
        "dropout.train()\n",
        "print(dropout.training)\n",
        "\n",
        "dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylDiLHIg7drq",
        "outputId": "f8e6c07b-e7ba-402b-f0e5-8656b0475097"
      },
      "outputs": [],
      "source": [
        "list(dropout.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V2NHUva75kQ",
        "outputId": "30a72312-7085-473a-b0ae-6e665f46bbff"
      },
      "outputs": [],
      "source": [
        "t = torch.rand([3, 5], dtype=torch.float32)\n",
        "\n",
        "print(\"t.mean()\", t.mean().item())\n",
        "\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQlakcIj7870",
        "outputId": "a6611063-f320-437a-f056-4a80e531ee93"
      },
      "outputs": [],
      "source": [
        "dropout.eval()\n",
        "t_dropouted = dropout(t)\n",
        "\n",
        "print(\"t_dropouted.mean()\", t_dropouted.mean().item())\n",
        "\n",
        "assert torch.allclose(t_dropouted, t), \"eval dropout module do nothing\"\n",
        "\n",
        "t_dropouted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRmd_H_8F7Xu",
        "outputId": "d0c5def4-5e7c-457d-fe5a-66bb45518f43"
      },
      "outputs": [],
      "source": [
        "dropout.train()\n",
        "t_dropouted = dropout(t)\n",
        "\n",
        "print(\"t_dropouted.mean()\", t_dropouted.mean().item())\n",
        "\n",
        "print(\"zeros count\", (t_dropouted == 0.0).sum().item(), \"of\", t_dropouted.numel())\n",
        "\n",
        "t_dropouted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA_V6VaY785P",
        "outputId": "4a68b034-ec29-46dc-a183-0858f40681ee"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "m = Model()\n",
        "m.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNbIbkCJ8Bc3",
        "outputId": "f265b6bd-2561-4962-f067-e3087791b386"
      },
      "outputs": [],
      "source": [
        "m = m.eval()\n",
        "m.dropout.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ckVdwhfTErd",
        "outputId": "133e5b9e-dfcd-45d0-be20-3b86c28438b9"
      },
      "outputs": [],
      "source": [
        "m = m.train()\n",
        "m.dropout.training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGhU53im7gyU"
      },
      "source": [
        "## LabelSmoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kodaeb0h7djS",
        "outputId": "e12874d5-3dc8-4e5f-a3fe-2d73248ecf91"
      },
      "outputs": [],
      "source": [
        "nn.CrossEntropyLoss(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Z5S5AfJlcz"
      },
      "source": [
        "<img src=\"https://github.com/fintech-dl-hse/course/raw/refs/heads/main/seminars/03_optimization_regularization/static/label_smoothing.png\" width=\"400\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgH0Ojeo8GNT"
      },
      "source": [
        "## WeightDecay\n",
        "\n",
        "* [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) (..., weight_decay=0.1)\n",
        "\n",
        "* [AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)\n",
        "\n",
        "Stack Overflow: [AdamW and Adam with weight decay](https://stackoverflow.com/questions/64621585/adamw-and-adam-with-weight-decay)\n",
        "\n",
        "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞:\n",
        "\n",
        "### Adam + weight_decay - —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∏–¥–µ—Ç **—á–µ—Ä–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã**\n",
        "```python\n",
        "final_loss = loss + wd * all_weights.pow(2).sum() / 2\n",
        "# backward ...\n",
        "# optimizer.step:\n",
        "w = w - lr * w.grad # grad contains regularisation\n",
        "```\n",
        "\n",
        "### AdamW - –ø—Ä—è–º–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤\n",
        "```python\n",
        "w = w - lr * w.grad - lr * wd * w\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1avSsaGJlc0"
      },
      "source": [
        "| –ê—Å–ø–µ–∫—Ç | Adam + weight_decay | AdamW |\n",
        "|--------|---------------------|-------|\n",
        "| **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å** | `L_final = L + Œª/2 Œ£w¬≤` | `L_final = L` |\n",
        "| **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤** | `w ‚Üê w - Œ±¬∑m/‚àö(v+Œµ)` | `w ‚Üê w - Œ±¬∑m/‚àö(v+Œµ) - Œ±¬∑Œª¬∑w` |\n",
        "| **–°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏** | **–†–∞–∑–ª–∏—á–∞–µ—Ç—Å—è** –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ | **–û–¥–∏–Ω–∞–∫–æ–≤–∞—è** –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ |\n",
        "| **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤** | Œª –ø–æ–ø–∞–¥–∞–µ—Ç –ø–æ–¥ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π lr | Œª –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ |\n",
        "| **–î–ª—è SGD** | ‚úÖ **–†–∞–∑–Ω–∏—Ü—ã –Ω–µ—Ç!** | ‚úÖ **–†–∞–∑–Ω–∏—Ü—ã –Ω–µ—Ç!** |\n",
        "| **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ** | –£—Å—Ç–∞—Ä–µ–≤—à–∏–π –ø–æ–¥—Ö–æ–¥ | –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLhC6QPGJlc1"
      },
      "source": [
        "<img src=\"https://github.com/fintech-dl-hse/course/raw/refs/heads/main/seminars/03_optimization_regularization/static/adam_vs_adamw.png\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkdFomB98JN0"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "dummy_module_params = nn.Linear(1, 1).parameters()\n",
        "adam = optim.Adam(dummy_module_params, weight_decay=0.01)\n",
        "\n",
        "dummy_module_params = nn.Linear(1, 1).parameters()\n",
        "adamw = optim.AdamW(dummy_module_params, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nny1e9nEY0lD"
      },
      "source": [
        "# –û–±–Ω–æ–≤–∏–º Trainer –∏ –Ω–∞—à—É –º–æ–¥–µ–ª—å\n",
        "\n",
        "\n",
        "* –î–æ–±–∞–≤–∏–º –ø–æ–¥–¥–µ—Ä–∂–∫—É lr_sheduler\n",
        "* –í –º–æ–¥–µ–ª—å–∫—É –¥–æ–±–∞–≤–∏–º –¥—Ä–æ–ø–∞—É—Ç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E19uZ4fY0lD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUe1j4rE1eIC",
        "outputId": "854065a9-735f-4d20-c070-d6bf9a540859"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "# –Ω–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ, –∫–æ–ø–∏–ø–∞—Å—Ç–∞ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–µ–º–∞\n",
        "class FMNISTImageSet:\n",
        "    def __init__(self, train=True, transform=None):\n",
        "        self.data = FashionMNIST(\"./tmp\", train=train, download=True)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # —Å–¥–µ–ª–∞–π—Ç–µ –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É [1, 28, 28] —Å float32\n",
        "        sample, label = self.data[item]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        else:\n",
        "            sample = np.array(sample, dtype=np.float32)[None:, ...] / 255\n",
        "\n",
        "\n",
        "        return dict(\n",
        "            sample=sample,\n",
        "            label=label,\n",
        "        )\n",
        "\n",
        "fmnist_train = FMNISTImageSet(train=True, transform=ToTensor())\n",
        "fmnist_val = FMNISTImageSet(train=False, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzfUeJBcCvv5",
        "outputId": "f37553a2-b93b-470c-e2f4-1301be39dc3c"
      },
      "outputs": [],
      "source": [
        "# –ù–æ–≤—ã–π –º–æ–¥—É–ª—å\n",
        "flatten_module = nn.Flatten(start_dim=1, end_dim=-1)\n",
        "flatten_module(torch.rand([ 64, 28, 28 ])).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfgpxogiCSzc"
      },
      "outputs": [],
      "source": [
        "# –ß—Ç–æ –¥–æ–±–∞–≤–∏–ª–æ—Å—å:\n",
        "# * `nn.Dropout`, –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä `dropout_p` - –Ω–æ–≤—ã–π —Å–ª–æ–π –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –≤ `__init__`\n",
        "# * `nn.Flatten` - –Ω–æ–≤—ã–π —Å–ª–æ–π –¥–ª—è —Å—Ö–ª–æ–ø—ã–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –Ω–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Ç–µ–Ω–∑–æ—Ä–∞—Ö\n",
        "# * `label_smoothing=0.0` - –Ω–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
        "\n",
        "class MLPModel(nn.Module):\n",
        "    \"\"\"\n",
        "    –†–µ–∞–ª–∏–∑–∞—Ü–∏—è MLP. –ü–æ—Ö–æ–∂–µ–µ –º—ã —É–∂–µ –≤–∏–¥–µ–ª–∏ –Ω–∞ 1 –∏ 2 —Å–µ–º–∏–Ω–∞—Ä–µ.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_p=0.5, activation=None, label_smoothing=0.0):\n",
        "        \"\"\"\n",
        "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "        :param activation: –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ReLU).\n",
        "        :param dropout_p: –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–Ω—É–ª—è–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∞–∫—Ç–∏–≤–∞—Ü–∏—è—Ö\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "        if activation is None:\n",
        "            activation = nn.ReLU()\n",
        "\n",
        "        self.inner = nn.Sequential(\n",
        "            # input ~ [ bs, 28, 28 ]\n",
        "            nn.Flatten(), # ~ [ bs, 28 * 28 ]\n",
        "            nn.Linear(784, 100),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            activation,\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "        # nn.Sequential –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–∏\n",
        "        # self.linear_1 = nn.Linear(784, 100)\n",
        "        # self.activation = nn.ReLU()\n",
        "        # self.linear_2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å.\n",
        "\n",
        "        :param x: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ~ [ bs, 784 ]\n",
        "        :return: –í—ã—Ö–æ–¥–Ω—ã–µ –ª–æ–≥–∏—Ç—ã –º–æ–¥–µ–ª–∏ ~ [ bs, 10 ]\n",
        "        \"\"\"\n",
        "        return self.inner(x)\n",
        "\n",
        "    def compute_all(self, batch):\n",
        "        \"\"\"\n",
        "        –í—ã—á–∏—Å–ª—è–µ—Ç –ª–æ—Å—Å –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –±–∞—Ç—á—É –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "        :param batch: –ë–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 'sample' (–≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ) –∏ 'label' (–º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤).\n",
        "        :return: –ó–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç—Ä–∏–∫.\n",
        "        \"\"\"\n",
        "\n",
        "        x = batch['sample']    # [ bs, 784 ]\n",
        "        y = batch['label']     # [ bs ] torch.LongTensor\n",
        "        logits = self.inner(x) # [ bs, 10 ]\n",
        "\n",
        "        loss = F.cross_entropy(logits, y, label_smoothing=self.label_smoothing)\n",
        "        acc = (logits.argmax(axis=1) == y).float().mean().cpu().numpy()\n",
        "        metrics = {\n",
        "            \"metrics/acc\": acc,\n",
        "            \"metrics/loss\": loss.detach().item(),\n",
        "        }\n",
        "        return loss, metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T1Aw3b3F-A1"
      },
      "source": [
        "## –ü—Ä–æ Trainer\n",
        "\n",
        "–ú—ã —É–∂–µ –ø–∏—Å–∞–ª–∏ –ø–æ—Ö–æ–∂–∏–π `Trainer` –Ω–∞ –ø—Ä–æ—à–ª–æ–º —Å–µ–º–∏–Ω–∞—Ä–µ. –ó–¥–µ—Å—å –æ–Ω —á—É—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω:\n",
        "- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ TrainerConfig - –∫–ª–∞—Å—Å, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–ø–∏—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è\n",
        "- –•—É–∫–∏: –≤—ã–±–∏—Ä–∞–µ–º, –∫–æ–≥–¥–∞ –¥–µ–ª–∞–µ–º `lr_scheduler.step()` (**per_batch** –∏–ª–∏ **per_epoch**)\n",
        "\n",
        "–í–∞–∂–Ω–æ: —Å–∞–º `Trainer` ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —É–¥–æ–±–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –Ω–∞–¥ —Ü–∏–∫–ª–æ–º –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –∫–æ–ø–∏–ø–∞—Å—Ç–∏—Ç—å –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVJbqb9wGLcv"
      },
      "outputs": [],
      "source": [
        "# TensorBoard (Colab)\n",
        "# –õ–æ–≥–∏ –±—É–¥—É—Ç –ø–∏—Å–∞—Ç—å—Å—è –≤ –ø–∞–ø–∫—É runs/03_seminar\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "LOG_DIR = \"runs/03_seminar\"\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\n",
        "# %tensorboard --logdir runs/03_seminar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN3160UCEZvn"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Iterable\n",
        "\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LRScheduler, ReduceLROnPlateau\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainerConfig:\n",
        "    log_dir: str = \"runs/03_seminar\"\n",
        "    batch_size: int = 128\n",
        "    lr_scheduler_type: str | None = None  # None | 'per_batch' | 'per_epoch'\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"–û–±–µ—Ä—Ç–∫–∞ –Ω–∞–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "    –î–µ—Ä–∂–∏—Ç –≤–º–µ—Å—Ç–µ:\n",
        "    - model\n",
        "    - optimizer\n",
        "    - train/val datasets + dataloaders\n",
        "    - (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) lr scheduler\n",
        "    - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ TensorBoard\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        optimizer: Optimizer,\n",
        "        train_dataset: Iterable,\n",
        "        val_dataset: Iterable,\n",
        "        *,\n",
        "        config: TrainerConfig | None = None,\n",
        "        lr_scheduler: LRScheduler | None = None,\n",
        "    ):\n",
        "        if config is None:\n",
        "            config = TrainerConfig()\n",
        "\n",
        "        if config.lr_scheduler_type not in [None, \"per_batch\", \"per_epoch\"]:\n",
        "            raise ValueError(\n",
        "                \"lr_scheduler_type must be one of: None, 'per_batch', 'per_epoch'. \"\n",
        "                f\"Not: {config.lr_scheduler_type}\"\n",
        "            )\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "\n",
        "        self.batch_size = config.batch_size\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        self.lr_scheduler_type = config.lr_scheduler_type\n",
        "\n",
        "        self.device: str | int = \"cpu\"\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.cuda.current_device()\n",
        "            self.model = self.model.to(self.device)\n",
        "\n",
        "        self.global_step = 0\n",
        "        self.writer = SummaryWriter(log_dir=config.log_dir)\n",
        "\n",
        "    def close(self) -> None:\n",
        "        self.writer.flush()\n",
        "        self.writer.close()\n",
        "\n",
        "    def log_scalars(self, log_data: dict[str, float], step: int | None = None) -> None:\n",
        "        if step is None:\n",
        "            step = self.global_step\n",
        "\n",
        "        for key, value in log_data.items():\n",
        "            self.writer.add_scalar(key, float(value), step)\n",
        "\n",
        "    def save_checkpoint(self, path: str) -> None:\n",
        "        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å.\"\"\"\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "    def train(self, num_epochs: int) -> None:\n",
        "        train_loader = DataLoader(\n",
        "            self.train_dataset,\n",
        "            shuffle=True,\n",
        "            pin_memory=True,\n",
        "            batch_size=self.batch_size,\n",
        "        )\n",
        "\n",
        "        # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å\n",
        "        val_loader = DataLoader(\n",
        "            self.val_dataset,\n",
        "            shuffle=False,\n",
        "            pin_memory=True,\n",
        "            batch_size=self.batch_size,\n",
        "        )\n",
        "\n",
        "        best_loss = float(\"inf\")\n",
        "\n",
        "        for epoch in tqdm(range(num_epochs)):\n",
        "            self.model.train()\n",
        "            for batch in train_loader:\n",
        "                self.training_step(batch)\n",
        "                self.post_train_batch()\n",
        "                self.global_step += 1\n",
        "\n",
        "            self.model.eval()\n",
        "\n",
        "            val_losses: list[float] = []\n",
        "            for batch in val_loader:\n",
        "                loss = self.validation_step(batch)\n",
        "                val_losses.append(float(loss.item()))\n",
        "\n",
        "            val_loss = float(np.mean(val_losses))\n",
        "            self.log_scalars({\"validation/loss\": val_loss}, step=epoch)\n",
        "\n",
        "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–∏–ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
        "            if val_loss < best_loss:\n",
        "                self.save_checkpoint(\"./best_checkpoint.pth\")\n",
        "                best_loss = val_loss\n",
        "\n",
        "            self.post_val_stage(val_loss)\n",
        "\n",
        "        self.close()\n",
        "\n",
        "    def training_step(self, batch) -> None:\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "        loss, details = self.model.compute_all(batch)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è\n",
        "        log_metrics = {f\"train/{k}\": float(v) for k, v in details.items()}\n",
        "        log_metrics[\"train/loss\"] = float(loss.item())\n",
        "        self.log_scalars(log_metrics)\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "        loss, _details = self.model.compute_all(batch)\n",
        "        return loss\n",
        "\n",
        "    def post_train_batch(self) -> None:\n",
        "        # called after every train batch\n",
        "        if self.lr_scheduler is None or self.lr_scheduler_type != \"per_batch\":\n",
        "            return\n",
        "\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "        # –ë–µ—Ä–µ–º lr –¥–ª—è –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "        lr = float(self.optimizer.param_groups[0][\"lr\"])\n",
        "        self.log_scalars({\"train/learning_rate\": lr})\n",
        "\n",
        "    def post_val_stage(self, val_loss: float) -> None:\n",
        "        if self.lr_scheduler is None or self.lr_scheduler_type != \"per_epoch\":\n",
        "            return\n",
        "\n",
        "        if isinstance(self.lr_scheduler, ReduceLROnPlateau):\n",
        "            self.lr_scheduler.step(val_loss)\n",
        "        else:\n",
        "            self.lr_scheduler.step()\n",
        "\n",
        "        lr = float(self.optimizer.param_groups[0][\"lr\"])\n",
        "        self.log_scalars({\"validation/learning_rate\": lr}, step=self.global_step)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Ep9e_RNK8u"
      },
      "source": [
        "### –ù–µ –∑–∞–±—É–¥—å –ø–æ–º–µ–Ω—è—Ç—å Runtime Type –≤ –∫–æ–ª–∞–±–µ –Ω–∞ GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mSRkEUxP6CV"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data\n",
        "\n",
        "# –±–µ—Ä–µ–º —á–∞—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–π –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –±–æ–ª—å—à–µ–π –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –¥—Ä–æ–ø–∞—É—Ç–∞\n",
        "# –Ω–∞ –±–æ–ª—å—à–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ —Å–ª–æ–∂–Ω–µ–µ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è, –ø–æ—ç—Ç–æ–º—É –º—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –µ–≥–æ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –Ω–∞ –∑–∞–Ω—è—Ç–∏–∏\n",
        "# –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –Ω–µ –Ω–∞–¥–æ —Ç–∞–∫ –¥–µ–ª–∞—Ç—å!\n",
        "fmnist_train_subset = torch.utils.data.Subset(fmnist_train, range(0, len(fmnist_train), 400))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmxrXSfuC4Fm"
      },
      "source": [
        "### `dropout=0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rznsaUnoKwLX"
      },
      "outputs": [],
      "source": [
        "model = MLPModel(dropout_p=0.0)\n",
        "optimizer = Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    optimizer,\n",
        "    fmnist_train_subset,\n",
        "    fmnist_val,\n",
        "    config=TrainerConfig(log_dir=f\"{LOG_DIR}/dropout_p_0.0\"),\n",
        ")\n",
        "trainer.train(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "424LmK9-C8Hr"
      },
      "source": [
        "### `dropout=0.3`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znEBoVWLLHAc"
      },
      "outputs": [],
      "source": [
        "model = MLPModel(dropout_p=0.3)\n",
        "optimizer = Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    optimizer,\n",
        "    fmnist_train_subset,\n",
        "    fmnist_val,\n",
        "    config=TrainerConfig(log_dir=f\"{LOG_DIR}/dropout_p_0.3\"),\n",
        ")\n",
        "trainer.train(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MklVh_RFJlc3"
      },
      "source": [
        "### `dropout=0.3`, `label_smoothing=0.1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH-bbzX0Jlc3"
      },
      "outputs": [],
      "source": [
        "model = MLPModel(dropout_p=0.3, label_smoothing=0.1)\n",
        "optimizer = Adam(model.parameters(), lr=3e-3)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    optimizer,\n",
        "    fmnist_train_subset,\n",
        "    fmnist_val,\n",
        "    config=TrainerConfig(log_dir=f\"{LOG_DIR}/dropout_p_0.3_label_smoothing_0.1\"),\n",
        ")\n",
        "trainer.train(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-nuDo1bXVmX"
      },
      "source": [
        "### TensorBoard (–∫–∞–∫ —Å–º–æ—Ç—Ä–µ—Ç—å –ª–æ–≥–∏ –≤ Colab)\n",
        "\n",
        "1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å–∫–∞–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–∞–∑ (–≤ `runs/03_seminar` –ø–æ—è–≤—è—Ç—Å—è event-—Ñ–∞–π–ª—ã).\n",
        "2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ TensorBoard –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ:\n",
        "\n",
        "```python\n",
        "%tensorboard --logdir runs/03_seminar\n",
        "```\n",
        "\n",
        "–ï—Å–ª–∏ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, —É–¥–æ–±–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ –ø–æ–¥–ø–∞–ø–∫–∏:\n",
        "- `runs/03_seminar/dropout_p_0.0`\n",
        "- `runs/03_seminar/dropout_p_0.3`\n",
        "- `runs/03_seminar/CyclicLR`\n",
        "\n",
        "TensorBoard —Å–∞–º –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs/03_seminar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beTAq3Ghj7iN"
      },
      "source": [
        "# LR Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FihBOfi4oIxH"
      },
      "source": [
        "–î–≤–∞ —Ç–∏–ø–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π:\n",
        "\n",
        "- –ø–æ —ç–ø–æ—Ö–∞–º ([StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html), [ReduceLROnPlateau](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html), ...)\n",
        "```python\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "for epoch in range(epochs):\n",
        "    train(...)\n",
        "    validate(...)\n",
        "    scheduler.step()\n",
        "```\n",
        "\n",
        "\n",
        "- –ø–æ –±–∞—Ç—á–∞–º ([Cyclic](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CyclicLR.html), [1cycle](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR), ...)\n",
        "```python\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n",
        "for epoch in range(epochs):\n",
        "    # train(...)\n",
        "    for batch in data_loader:\n",
        "        train_batch(...)\n",
        "        scheduler.step()\n",
        "    # validate(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suqqquxtmtTJ"
      },
      "source": [
        "# WarmUp\n",
        "\n",
        "**–ü—Ä–æ–±–ª–µ–º–∞:** –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ —Å–µ—Ç–∫–∏ –º–æ–∂–µ—Ç —Å–∏–ª—å–Ω–æ —Ä–∞–∑–Ω–µ—Å—Ç–∏, –µ—Å–ª–∏ —Å—Ä–∞–∑—É –Ω–∞—á–∞—Ç—å –∏—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –±–æ–ª—å—à–∏—Ö –±–∞—Ç—á–∞—Ö.\n",
        "\n",
        "–ß—Ç–æ–±—ã —Å–µ—Ç—å –Ω–µ —Ä–∞—Å—Ö–æ–¥–∏–ª–∞—Å—å —Å—Ä–∞–∑—É, –º–æ–∂–Ω–æ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å lr ‚Äî —Ç–æ–≥–¥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –Ω–∞–∫–æ–ø—è—Ç –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –º–æ–º–µ–Ω—Ç–æ–≤ -- –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º–µ–Ω—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —à—É–º–Ω–æ–º —Å—ç–º–ø–ª–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "FFvx1wEIJlc4",
        "outputId": "c355a472-d0ef-4b21-e3f6-f88e5b8fd448"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "\n",
        "def plot_lr_schedule(optimizer, scheduler, num_steps: int, title: str, step_size=1) -> None:\n",
        "    lr_history = []\n",
        "    steps_history = []\n",
        "    for i in range(0, num_steps, step_size):\n",
        "        steps_history.append(i)\n",
        "        lr_history.append(float(optimizer.param_groups[0][\"lr\"]))\n",
        "        scheduler.step()\n",
        "\n",
        "    plt.plot(steps_history, lr_history)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"lr\")\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è warmup + cosine (—á–µ—Ä–µ–∑ LambdaLR)\n",
        "base_lr = 3e-4\n",
        "num_steps = 200\n",
        "warmup_steps = 20\n",
        "\n",
        "param = torch.nn.Parameter(torch.zeros(()))\n",
        "optimizer = torch.optim.Adam([param], lr=base_lr)\n",
        "\n",
        "# lr_factor(step): [0..1] –Ω–∞ warmup, –∑–∞—Ç–µ–º cosine –¥–æ 0\n",
        "\n",
        "def lr_factor(step: int) -> float:\n",
        "    if step < warmup_steps:\n",
        "        return float(step + 1) / float(warmup_steps)\n",
        "\n",
        "    progress = float(step - warmup_steps) / float(max(1, num_steps - warmup_steps))\n",
        "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_factor)\n",
        "\n",
        "step_optimizer = torch.optim.Adam([param], lr=base_lr)\n",
        "step_lr_scheduler = torch.optim.lr_scheduler.StepLR(step_optimizer, step_size=30, gamma=0.999)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plot_lr_schedule(optimizer, scheduler, num_steps=num_steps, title=\"Warmup + Cosine (LambdaLR)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFPnj92uJlc4"
      },
      "source": [
        "### –û–±—É—á–∏–º –º–æ–¥–µ–ª—å —Å —à–µ–¥—É–ª–µ—Ä–æ–º –∏ warmup'–æ–º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp_nrD0LJlc4"
      },
      "outputs": [],
      "source": [
        "model = MLPModel(dropout_p=0.3, label_smoothing=0.1)\n",
        "\n",
        "base_lr = 3e-3\n",
        "optimizer = Adam(model.parameters(), lr=base_lr)\n",
        "\n",
        "# TODO avoid hardcode, build scheduler in trainer\n",
        "num_steps = 59\n",
        "warmup_steps = 20\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
        "\n",
        "# lr_factor(step): [0..1] –Ω–∞ warmup, –∑–∞—Ç–µ–º cosine –¥–æ 0\n",
        "def lr_factor(step: int) -> float:\n",
        "    if step < warmup_steps:\n",
        "        return float(step + 1) / float(warmup_steps)\n",
        "\n",
        "    progress = float(step - warmup_steps) / float(max(1, num_steps - warmup_steps))\n",
        "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_factor)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    optimizer,\n",
        "    fmnist_train_subset,\n",
        "    fmnist_val,\n",
        "    config=TrainerConfig(\n",
        "        log_dir=f\"{LOG_DIR}/cosine_with_warmup\",\n",
        "        lr_scheduler_type=\"per_batch\",\n",
        "    ),\n",
        "    lr_scheduler=scheduler,\n",
        ")\n",
        "trainer.train(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il7lnP0JJlc4"
      },
      "source": [
        "# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYEZDhwqJlc4"
      },
      "source": [
        "–ë–æ–Ω—É—Å–Ω–∞—è –¥–æ–º–∞—à–∫–∞ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –∏–∑ —Ç–µ–º (–≥–æ–ª–æ—Å—É–µ–º):\n",
        "- Schedule-free\n",
        "- Muon\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44eDWWnrJlc4"
      },
      "source": [
        "### –¢—é–Ω–∏–Ω–≥ LR\n",
        "\n",
        "**–ü—Ä–æ–±–ª–µ–º–∞**: —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –Ω—É–∂–Ω–æ —Å –Ω—É–ª—è –ø–æ–¥–±–∏—Ä–∞—Ç—å lr –∏ –¥—Ä—É–≥–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã.\n",
        "\n",
        "**–†–µ—à–µ–Ω–∏–µ:** $\\mu P$ [–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è](https://github.com/microsoft/mup) –∏–ª–∏ (–≤—Ä–æ–¥–µ) Muon\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PwI7S6vJlc5"
      },
      "source": [
        "## ‚ö†Ô∏è Pytorch —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è SGD with momentum\n",
        "\n",
        "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: $\\theta_t = \\theta_{t-1} - \\eta \\cdot v_t$ (–≤ –æ–±–æ–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö). –†–∞–∑–ª–∏—á–∏–µ ‚Äî –≤ –ø—Ä–∞–≤–∏–ª–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –±—É—Ñ–µ—Ä–∞ $v_t$.\n",
        "\n",
        "#### –í–æ–∑–º–æ–∂–Ω–æ –≤—ã –æ–∂–∏–¥–∞–ª–∏, —á—Ç–æ\n",
        "$$v_t = (1 - \\mu) \\, g_t + \\mu \\, v_{t-1}$$\n",
        "($g_t$ ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞ —à–∞–≥–µ $t$, $\\mu$ ‚Äî momentum, —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤)\n",
        "\n",
        "```python\n",
        "self.param_momentum[p] = (1 - self.momentum) * p.grad + self.momentum * self.param_momentum[p]\n",
        "```\n",
        "\n",
        "#### –ù–æ pytorch implementation\n",
        "$$v_t = g_t + \\mu \\, v_{t-1}$$\n",
        "(–Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º $\\mu$)\n",
        "\n",
        "```python\n",
        "self.param_momentum[p] = p.grad + self.momentum * self.param_momentum[p]\n",
        "```\n",
        "\n",
        "\n",
        "#### ‚ùì –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ?\n",
        "\n",
        "–ö–æ–≥–¥–∞ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SGD w/ momentum, —É–º–Ω–æ–∂–∞–π—Ç–µ learning rate –Ω–∞ `1/(1-momentum)`, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LR –∏–∑ SGD.\n",
        "\n",
        "\n",
        "[StackOverflow](https://stackoverflow.com/questions/75394235/is-it-something-wrong-with-torch-optim-sgd-with-momentum)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087_CZIVJlc5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKyhMfTbJlc5"
      },
      "source": [
        "# –†–µ–∑—é–º–µ\n",
        "\n",
        "\n",
        "<video controls>\n",
        "    <source src=\"https://github.com/fintech-dl-hse/course/raw/refs/heads/main/seminars/03_optimization_regularization/static/OptimizerComparison.mp4\" type=\"video/mp4\">\n",
        "    Your browser does not support the video tag.\n",
        "</video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9QhJlQ6x5W0"
      },
      "source": [
        "# –ë–ª–∏—Ü\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRF791_KPU4b"
      },
      "source": [
        "### –ú–æ–∂–µ—Ç –ª–∏ –±—ã—Ç—å –ª–æ—Å—Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5UtxDFOyLY5"
      },
      "source": [
        "### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω lr warmup?\n",
        "\n",
        "<!---\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Å–µ—Ç–µ–π –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGb_NhwryK_r"
      },
      "source": [
        "### –ó–∞—á–µ–º –Ω—É–∂–µ–Ω lr scheduling?\n",
        "\n",
        "<!---\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è –º—ã —Ö–æ—Ç–∏–º –ø–æ–±—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–π—Ç–∏ –∫ –æ–±–ª–∞—Å—Ç–∏ —Å —Ç–æ—á–∫–æ–π –æ–ø—Ç–∏–º—É–º–∞. –ù–æ –ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –º—ã –∫ –Ω–µ–π –ø—Ä–∏–±–ª–∏–∑–∏–ª–∏—Å—å –º—ã –º–æ–∂–µ–º –∑–∞—Ö–æ—Ç–µ—Ç—å —É–º–µ–Ω—å—à–∏—Ç—å lr –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "\n",
        "--->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvxOj0kZ1n2p"
      },
      "source": [
        "### –ö–∞–∫ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å lr, –µ—Å–ª–∏ –º—ã —É–≤–µ–ª–∏—á–∏–ª–∏ batch_size –≤ 3 —Ä–∞–∑–∞?\n",
        "\n",
        "<!---\n",
        "\n",
        "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–∫—É—é –∂–µ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LR –Ω—É–∂–Ω–æ —Ç–æ–∂–µ —É–≤–µ–ª–∏—á–∏—Ç—å –≤ 3 —Ä–∞–∑–∞.*\n",
        "\n",
        "* –î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏, –±–∞—Ç—á —Å–∞–π–∑–∞\n",
        "\n",
        "\n",
        "PS –•–æ—Ç—è –≤–æ–æ–±—â–µ –≥–æ–≤–æ—Ä—è, —ç—Ç–æ –æ—á–µ–Ω—å —Å–ø–æ—Ä–Ω–æ. –ú–æ–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å –º–Ω–æ–≥–æ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö –∫–µ–π—Å–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–∞–∂–µ –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º –±–∞—Ç—á—Å–∞–π–∑–µ. –ü–æ—Ç–æ–º—É —á—Ç–æ —á–µ–º –º–µ–Ω—å—à–µ –±–∞—Ç—á, —Ç–µ–º –±—ã—Å—Ç—Ä–µ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ —Ç–µ–º –±–æ–ª—å—à–µ —à–∞–≥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º—ã —Å–º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å –∑–∞ –µ–¥–∏–Ω–∏—Ü—É –≤—Ä–µ–º–µ–Ω–∏.\n",
        "\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGzMW4beI3K"
      },
      "source": [
        "### –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è lr?\n",
        "\n",
        "<!---\n",
        "\n",
        "–° –ø–æ–º–æ—â—å—é LR Finder'–∞\n",
        "\n",
        "–°—Ç—Ä–æ–∏–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å Loss(learning_rate) –∏ –∏—â–µ–º —Ç–æ—á–∫—É –ø–µ—Ä–µ–≥–∏–±–∞. –î–∏–∞–ø–æ–∑–æ–Ω –Ω–µ–ø–ª–æ—Ö–∏—Ö lr –±—É–¥–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è –≤ —Ç–æ—á–∫–µ –ø–µ—Ä–µ–≥–∏–±–∞ (–≤–æ–∑–º–æ–∂–Ω–æ —á—É—Ç—å –ª–µ–≤–µ–µ), –∫–æ–≥–¥–∞ —Å–µ—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç —É—á–∏—Ç—å—Å—è, –∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è –¥–æ –º–æ–º–µ–Ω—Ç–∞, –∫–æ–≥–¥–∞ –ª–æ—Å—Å –Ω–∞—á–∏–Ω–∞–µ—Ç —à—É–º–µ—Ç—å, —Ñ–ª—É–∫—Ç—É–∏—Ä–æ–≤–∞—Ç—å, –∫–æ–ª–±–∞—Å–∏—Ç—å\n",
        "\n",
        "--->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqhKLlpSDXW2"
      },
      "source": [
        "### –ö–∞–∫ –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –≤ –Ω–µ–µ –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–π `nn.Dropout(p=1.0)`\n",
        "\n",
        "<!-- –ù–∏–∫–∞–∫, –ø–æ—Ç–æ–º—É —á—Ç–æ —Ç–∞–∫–æ–π —Å–ª–æ–π –ø—Ä–æ—Å—Ç–æ –∑–∞–Ω—É–ª–∏—Ç —Ç–µ–Ω–∑–æ—Ä –ø–æ–ª–Ω–æ—Å—Ç—å—é -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooLtwIV7AHcg"
      },
      "source": [
        "### –ó–∞—á–µ–º –≤–Ω—É—Ç—Ä–∏ `Dropout` –¥–µ–ª–∞–µ—Ç—Å—è —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ `1/(1-p)`? –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —ç—Ç–æ–≥–æ –Ω–µ —Å–¥–µ–ª–∞—Ç—å?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YwCCNQdEy4F"
      },
      "source": [
        "### –ö–∞–∫ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥—É–ª—è `nn.Dropout` –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –ø–µ—Ä–µ–∫–ª—é—á–∏–ª–∏ –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –≤—ã—á–∏—Å–ª–µ–Ω–∏—è (`model.eval()`)?\n",
        "\n",
        "<!-- –ò–∑ –¥–æ–∫–∏ —Ç–æ—Ä—á–∞: \"During evaluation the module simply computes an identity function.\" -- –ª—É—á—à–µ –∏ –Ω–µ —Å–∫–∞–∂–µ—à—å) https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNyafnSbKYhz"
      },
      "source": [
        "### –î–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω `nn.Dropout`?\n",
        "\n",
        "<!-- –°–ø–æ—Å–æ–± —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, —Å –¥—Ä–æ–ø–∞—É—Ç–æ–º –º–æ–¥–µ–ª–∏ —Å–ª–æ–∂–Ω–µ–µ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —É–ª—É—á—à–∞–µ—Ç—Å—è –æ–±–æ–±—â–∞—é—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å–µ—Ç–∏ -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIlKvmpj4xX6"
      },
      "source": [
        "### –ú—ã —Ö–æ—Ç–∏–º –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ `1M` –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é `SGD` –∏ —Å –ø–æ–º–æ—â—å—é `Adam`. –ö–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –æ–±—ä–µ–º –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hL-vn-n5HqP"
      },
      "source": [
        "### –ó–∞—á–µ–º `Adam` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–æ–º–µ–Ω—Ç–æ–≤?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JM_n9d6M3lK"
      },
      "source": [
        "### –ß–µ–º `Adam + weight decay` –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç `AdamW`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hs6yzAOXMdb"
      },
      "source": [
        "### –ù–∞—à–µ–ª –æ—Ç–∑—ã–≤ –Ω–∞ —è–Ω–¥–µ–∫—Å –º–∞—Ä–∫–µ—Ç–µ. –ü—Ä–æ –∫–∞–∫–æ–π —ç—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä?\n",
        "\n",
        "<!-- –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, –Ω–µ–ª—å–∑—è –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ —Å–∫–∞–∑–∞—Ç—å. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫ Adam, —Ç–∞–∫ –∏ SGD —Å –º–æ–º–µ–Ω—Ç–æ–º –∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã—Ö —Ö—Ä–∞–Ω–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf61exGPXPIz"
      },
      "source": [
        "![](https://github.com/fintech-dl-hse/course/raw/refs/heads/main/seminars/03_optimization_regularization/static/ya_market_optimizer_review.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0r6pClg29uq"
      },
      "source": [
        "# –î–æ–º–∞—à–∫–∏:\n",
        "\n",
        "* dropout\n",
        "* optimization\n",
        "* [–±–æ–Ω—É—Å–Ω–∞—è?] [WIP] muon\n",
        "* [–±–æ–Ω—É—Å–Ω–∞—è?] [WIP] scheduler free adam"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "audio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
