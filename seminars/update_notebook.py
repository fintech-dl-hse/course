#!/usr/bin/env python3
"""
–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º:
1. –í—Å–µ –±–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –≤ –∫–æ–Ω—Ü–µ
2. –£–¥–∞–ª–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
3. –î–æ–±–∞–≤–∏—Ç—å –≤–≤–µ–¥–µ–Ω–∏–µ –≤ PyTorch –≤ –Ω–∞—á–∞–ª–æ
"""

import json
from pathlib import Path

def load_notebook(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_notebook(notebook, path):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=1)

def create_markdown_cell(text):
    lines = text.strip().split('\n')
    source = [line + '\n' for line in lines[:-1]]
    if lines:
        source.append(lines[-1])
    return {
        "cell_type": "markdown",
        "source": source,
        "metadata": {}
    }

def create_code_cell(code):
    lines = code.strip().split('\n')
    source = [line + '\n' for line in lines[:-1]]
    if lines:
        source.append(lines[-1])
    return {
        "cell_type": "code",
        "execution_count": None,
        "source": source,
        "outputs": [],
        "metadata": {}
    }

def update_notebook():
    """Update notebook according to new requirements."""

    print("üìñ Loading notebook...")
    nb = load_notebook("01_seminar_mlp_autograd.ipynb")

    print("üî® Restructuring notebook...")

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    new_cells = []

    # ===== –í–í–ï–î–ï–ù–ò–ï =====
    print("  Adding introduction...")
    new_cells.append(create_markdown_cell("""# –°–µ–º–∏–Ω–∞—Ä 1: MLP –Ω–∞ PyTorch –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

## –ü–ª–∞–Ω —Å–µ–º–∏–Ω–∞—Ä–∞

### –ß–∞—Å—Ç—å I: PyTorch MLP
* –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch (–±–∞–∑–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã, broadcasting)
* –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (make_moons)
* –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ MLP –Ω–∞ PyTorch
* –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–±—É—á–µ–Ω–∏–µ
* –†–æ–ª—å –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π
* –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SVM
* –ë–∞—Ç—á–∏–Ω–≥ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

### –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation
* –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?
* Forward –∏ backward pass
* Chain rule –∏ backpropagation
* –ü—Ä–∏–º–µ—Ä—ã autograd –≤ PyTorch
* –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ autograd

### –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã
* –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞"""))

    new_cells.append(create_markdown_cell("---\n\n# –ß–∞—Å—Ç—å I: PyTorch MLP"))

    # ===== –ù–û–í–ê–Ø –°–ï–ö–¶–ò–Ø: –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch =====
    print("  Adding PyTorch basics section...")
    new_cells.append(create_markdown_cell("""## –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å PyTorch

PyTorch - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Meta (Facebook).

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
* –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π API (–ø–æ—Ö–æ–∂ –Ω–∞ NumPy)
* –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π computational graph
* –£–¥–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è GPU
* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ê–Ω–∞–ª–æ–≥–∏—è —Å NumPy

PyTorch tensors —Ä–∞–±–æ—Ç–∞—é—Ç –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ NumPy arrays:"""))

    new_cells.append(create_code_cell("""import torch
import numpy as np

# NumPy
np_array = np.array([1, 2, 3, 4, 5])
print("NumPy array:", np_array)
print("Shape:", np_array.shape)
print("Mean:", np_array.mean())

print()

# PyTorch (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ!)
torch_tensor = torch.tensor([1, 2, 3, 4, 5])
print("PyTorch tensor:", torch_tensor)
print("Shape:", torch_tensor.shape)
print("Mean:", torch_tensor.float().mean())  # PyTorch —Ç—Ä–µ–±—É–µ—Ç float –¥–ª—è mean()"""))

    new_cells.append(create_markdown_cell("""### –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏"""))

    new_cells.append(create_code_cell("""# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤
a = torch.zeros(3, 4)        # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –Ω—É–ª–µ–π
b = torch.ones(3, 4)         # –ú–∞—Ç—Ä–∏—Ü–∞ 3x4 –∏–∑ –µ–¥–∏–Ω–∏—Ü
c = torch.rand(3, 4)         # –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ [0, 1)
d = torch.randn(3, 4)        # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N(0, 1)

print("Zeros:\\n", a)
print("\\nOnes:\\n", b)
print("\\nRandom uniform:\\n", c)
print("\\nRandom normal:\\n", d)"""))

    new_cells.append(create_code_cell("""# –ê—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

print("x + y =", x + y)
print("x * y =", x * y)
print("x @ y =", x @ y)  # –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (dot product)"""))

    new_cells.append(create_markdown_cell("""### Broadcasting –≤ PyTorch

**Broadcasting** - –º–µ—Ö–∞–Ω–∏–∑–º, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤.

PyTorch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ "—Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç" —Ç–µ–Ω–∑–æ—Ä—ã –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞–ª–∏ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.

**–ü—Ä–∞–≤–∏–ª–∞ broadcasting:**
1. –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä—ã –∏–º–µ—é—Ç —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π, —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞ —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–π –¥–æ–ø–æ–ª–Ω—è–µ—Ç—Å—è –µ–¥–∏–Ω–∏—Ü–∞–º–∏ —Å–ª–µ–≤–∞
2. –†–∞–∑–º–µ—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏, –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–≤–Ω—ã –∏–ª–∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö —Ä–∞–≤–µ–Ω 1
3. –¢–µ–Ω–∑–æ—Ä—ã —Ä–∞—Å—à–∏—Ä—è—é—Ç—Å—è –ø–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º —Ä–∞–∑–º–µ—Ä–æ–º 1

–ü–æ–¥—Ä–æ–±–Ω–µ–µ: [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)"""))

    new_cells.append(create_code_cell("""# –ü—Ä–∏–º–µ—Ä 1: –í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä
x = torch.tensor([1.0, 2.0, 3.0])  # shape: (3,)
scalar = 10.0                       # shape: ()

result = x + scalar
print("–í–µ–∫—Ç–æ—Ä + —Å–∫–∞–ª—è—Ä:")
print(f"  {x.tolist()} + {scalar} = {result.tolist()}")
print(f"  Shapes: {x.shape} + () = {result.shape}")

print()

# –ü—Ä–∏–º–µ—Ä 2: –ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä
matrix = torch.tensor([[1.0, 2.0, 3.0],
                        [4.0, 5.0, 6.0]])  # shape: (2, 3)
vector = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,)

result = matrix + vector
print("–ú–∞—Ç—Ä–∏—Ü–∞ + –≤–µ–∫—Ç–æ—Ä:")
print("Matrix:\\n", matrix)
print("Vector:", vector)
print("Result:\\n", result)
print(f"Shapes: {matrix.shape} + {vector.shape} = {result.shape}")"""))

    new_cells.append(create_code_cell("""# –ü—Ä–∏–º–µ—Ä 3: Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã
a = torch.tensor([[1.0],
                  [2.0],
                  [3.0]])  # shape: (3, 1)

b = torch.tensor([10.0, 20.0, 30.0])  # shape: (3,) ‚Üí –±—É–¥–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ (1, 3)

result = a + b
print("Broadcasting –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
print("a (3, 1):\\n", a)
print("b (3,):", b)
print("Result (3, 3):\\n", result)
print(f"Shapes: {a.shape} + {b.shape} ‚Üí {result.shape}")"""))

    new_cells.append(create_markdown_cell("""### PyTorch vs NumPy: –∫–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è

| –ê—Å–ø–µ–∫—Ç | NumPy | PyTorch |
|--------|-------|---------|
| –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | `ndarray` | `Tensor` |
| GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.cuda()`, `.to('cuda')`) |
| Autograd | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (`.backward()`) |
| –°–æ–∑–¥–∞–Ω–∏–µ | `np.array([1,2,3])` | `torch.tensor([1,2,3])` |
| –°–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ | `np.random.rand(3,4)` | `torch.rand(3,4)` |
| Broadcasting | ‚úÖ –î–∞ | ‚úÖ –î–∞ (—Ç–µ –∂–µ –ø—Ä–∞–≤–∏–ª–∞) |

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PyTorch –≤–º–µ—Å—Ç–æ NumPy:**
* –ù—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (autograd!)
* –ù—É–∂–Ω—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU
* –†–∞–±–æ—Ç–∞–µ—Ç–µ —Å –≥–ª—É–±–æ–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º"""))

    # ===== –û–°–¢–ê–õ–¨–ù–ê–Ø –ß–ê–°–¢–¨ I =====
    print("  Adding rest of Part I...")

    # –ë–µ—Ä–µ–º —è—á–µ–π–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è)
    # –ù–∞—Ö–æ–¥–∏–º —è—á–µ–π–∫–∏ –¥–ª—è Part I (–æ—Ç "–î–∞–Ω–Ω—ã–µ" –¥–æ "–±–∞—Ç—á–∏–Ω–≥")
    in_part_1 = False
    for cell in nb['cells']:
        if cell['cell_type'] == 'markdown':
            source_text = ''.join(cell.get('source', []))

            # –ù–∞—á–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
            if '#  –î–∞–Ω–Ω—ã–µ' in source_text or '# –î–∞–Ω–Ω—ã–µ' in source_text:
                in_part_1 = True
                new_cells.append(cell)
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–∏—Ü I
            if '–ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –ß–∞—Å—Ç—å I' in source_text or '–±–ª–∏—Ü' in source_text.lower():
                in_part_1 = False
                continue

            # –ù–∞—á–∞–ª–æ Part II
            if '–ß–∞—Å—Ç—å II:' in source_text or '–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ' in source_text:
                in_part_1 = False
                # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º —ç—Ç—É —è—á–µ–π–∫—É, –¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ

        if in_part_1:
            new_cells.append(cell)

    # ===== –ü–ï–†–ï–•–û–î =====
    print("  Adding transition...")
    new_cells.append(create_markdown_cell("""---

# –ß–∞—Å—Ç—å II: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ?

–ù–∞ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ PyTorch –∫–∞–∫ "—á–µ—Ä–Ω—ã–π —è—â–∏–∫". –ú—ã –≤—ã–∑—ã–≤–∞–ª–∏ `loss.backward()` –∏ –º–∞–≥–∏—á–µ—Å–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.

–ù–æ –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è!"""))

    # ===== –ß–ê–°–¢–¨ II =====
    print("  Adding Part II...")

    # –ë–µ—Ä–µ–º —è—á–µ–π–∫–∏ Part II (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è)
    in_part_2 = False
    for cell in nb['cells']:
        if cell['cell_type'] == 'markdown':
            source_text = ''.join(cell.get('source', []))

            # –ù–∞—á–∞–ª–æ Part II
            if '–ó–∞—á–µ–º –º—ã –ø–∏–ª–∏–º –∞–≤—Ç–æ–≥—Ä–∞–¥' in source_text:
                in_part_2 = True
                new_cells.append(cell)
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–∏—Ü II
            if '–ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã –ß–∞—Å—Ç—å II' in source_text:
                in_part_2 = False
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
            if '–ß–∞—Å—Ç—å III' in source_text or '–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è' in source_text:
                in_part_2 = False
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–æ–Ω–∏ –±—É–¥—É—Ç –≤ –∫–æ–Ω—Ü–µ)
            if '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã' in source_text:
                in_part_2 = False
                continue

        if in_part_2:
            new_cells.append(cell)

    # ===== –ë–õ–ò–¶-–í–û–ü–†–û–°–´ (–≤—Å–µ –≤ –∫–æ–Ω—Ü–µ) =====
    print("  Adding quiz section at the end...")
    new_cells.append(create_markdown_cell("""---

# –ë–ª–∏—Ü-–≤–æ–ø—Ä–æ—Å—ã

## –ß–∞—Å—Ç—å I: PyTorch –∏ MLP

1. –í —á–µ–º –≥–ª–∞–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ PyTorch –æ—Ç NumPy?

2. –ß—Ç–æ —Ç–∞–∫–æ–µ broadcasting? –ü—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä.

3. –ö–∞–∫ –ª—É–Ω—ã –º–æ–∂–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è?

4. –ß–µ–º –Ω–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MLP –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç LinearSVC?

5. –ö–∞–∫ `learning_rate` –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è? –ß—Ç–æ –±—É–¥–µ—Ç —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º lr=1e-8? –° –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–º lr=1e3?

6. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—Å–µ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –∏–∑ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏?

7. –ß—Ç–æ —Ç–∞–∫–æ–µ –±–∞—Ç—á? –ü–æ—á–µ–º—É –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –±–∞—Ç—á—É—é—Ç—Å—è?

8. –ß–µ–º —Ç–µ–Ω–∑–æ—Ä –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç torch –ø–∞—Ä–∞–º–µ—Ç—Ä–∞?

## –ß–∞—Å—Ç—å II: Autograd –∏ Backpropagation

1. –ó–∞—á–µ–º –Ω—É–∂–Ω—ã —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö?

2. –ó–∞—á–µ–º –Ω—É–∂–µ–Ω autograd? –ü–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –≤—ã—á–∏—Å–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é?

3. –ö–æ–≥–¥–∞ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã - –≤–æ –≤—Ä–µ–º—è forward –∏–ª–∏ backward pass?

4. –ö–∞–∫–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–º –Ω—É–∂–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –∑–∞—á–µ–º?

5. –ö–∞–∫ computational graph, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≤–æ –≤—Ä–µ–º—è forward pass, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ backward pass?

6. –ö–∞–∫ —Å–ª–æ–∂–µ–Ω–∏–µ –∏ —É–º–Ω–æ–∂–µ–Ω–∏–µ –≤–ª–∏—è—é—Ç –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã?

7. –ß—Ç–æ —Ç–∞–∫–æ–µ closure (–∑–∞–º—ã–∫–∞–Ω–∏–µ) –≤ Python?

8. –ö–∞–∫–æ–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —à–∞–≥–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏?
   - a) forward ‚Üí backward ‚Üí zero_grad ‚Üí optimizer.step
   - b) zero_grad ‚Üí forward ‚Üí backward ‚Üí optimizer.step
   - c) backward ‚Üí forward ‚Üí zero_grad ‚Üí optimizer.step"""))

    # ===== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ê–¢–ï–†–ò–ê–õ–´ =====
    new_cells.append(create_markdown_cell("""---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

* [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
* [PyTorch Tutorials](https://pytorch.org/tutorials/)
* [PyTorch Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)
* [Backpropagation Calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8) - –æ—Ç–ª–∏—á–Ω–æ–µ –≤–∏–¥–µ–æ –æ—Ç 3Blue1Brown
* [micrograd](https://github.com/karpathy/micrograd) - –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π autograd engine –æ—Ç Andrej Karpathy"""))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    nb['cells'] = new_cells

    print(f"\nüíæ Saving updated notebook ({len(new_cells)} cells)...")
    save_notebook(nb, "01_seminar_mlp_autograd.ipynb")

    print("‚úÖ Done! Notebook updated.")
    print(f"\nüìä Statistics:")
    print(f"   Total cells: {len(new_cells)}")
    print(f"   Code cells: {len([c for c in new_cells if c['cell_type'] == 'code'])}")
    print(f"   Markdown cells: {len([c for c in new_cells if c['cell_type'] == 'markdown'])}")

if __name__ == "__main__":
    update_notebook()
